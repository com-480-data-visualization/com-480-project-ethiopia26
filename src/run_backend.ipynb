{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Torchlurk import Lurk\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from misc_funcs import clean_bw_imgs,sample_imagenet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At that stage, Download the tinyimagenet dataset on [this link](https://www.kaggle.com/ifigotin/imagenetmini-1000#n01440764_10470.JPEG) and place it in the directory data (s.t the path looks like `data/tinyimagenet/rest_of_path`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the dataset is downloaded, we need to get rid of a few bw images: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progression:5.80%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a63d685a2700>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclean_bw_imgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/tinyimagenet/train/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Cours/DataVis/com-480-project-ethiopia26/src/misc_funcs.py\u001b[0m in \u001b[0;36mclean_bw_imgs\u001b[0;34m(path_to_imgs_dirs)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mlist_bw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \"\"\"\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clean_bw_imgs(\"../data/tinyimagenet/train/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might want to work on a subset of tinyimagenet for computations reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_imagenet(\"../data/tinyimagenet/train/\",\"../data/exsmallimagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg16(pretrained=True)\n",
    "# same preprocess used as vgg16\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.CenterCrop(224), \n",
    "    transforms.ToTensor()\n",
    "    ,transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this cell if you want to create the information for the first time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#watch out: once you chose a folder name for the computed images and a json name, the json name will point to that folder name exclusively.\n",
    "lurker = Lurk(model,preprocess,save_comp_img_path='../results/06_05_20/'\n",
    "                              ,save_json_pathname='../saved_model/06_05_20.json'\n",
    "                              ,img_path=\"../data/50classes/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wish to load a precomputed json, just add the `load_path` attribute. Watch out, it needs to be coherent with the folder name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading done!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'subifold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-9c387c85f383>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m lurker = Lurk(model,preprocess,save_comp_img_path='../results/03_04_20/'\n\u001b[1;32m      2\u001b[0m                               \u001b[0;34m,\u001b[0m\u001b[0msave_json_pathname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'../saved_model/06_05_20.json'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                                load_path = '../saved_model/03_04_20.json')\n\u001b[0m",
      "\u001b[0;32m<ipython-input-76-0e4ef9da35d4>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, preprocess, save_comp_img_path, save_json_pathname, load_path, img_path)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCLASS2INDX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCLASS2INDX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m#initiate the number of counts for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_class_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCLASS2INDX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMGS_PATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minit_class_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msrc_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-76-0e4ef9da35d4>\u001b[0m in \u001b[0;36minit_class_counts\u001b[0;34m(self, class_to_idx, src_path, obj)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \"\"\"\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msubfold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0msubfold_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msubifold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfold_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mclasso\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubfold\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'subifold' is not defined"
     ]
    }
   ],
   "source": [
    "lurker = Lurk(model,preprocess,save_comp_img_path='../results/03_04_20/'\n",
    "                              ,save_json_pathname='../saved_model/06_05_20.json',\n",
    "                               load_path = '../saved_model/03_04_20.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current cursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving done!\n"
     ]
    }
   ],
   "source": [
    "lurker.compute_avgmax_imgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-43d4d1f4e076>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlurker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_avgmax_imgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlurker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_filter_actmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_indx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilter_indxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlurker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_filter_actmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_indx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilter_indxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlurker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Cours/DataVis/com-480-project-ethiopia26/src/Torchlurk.py\u001b[0m in \u001b[0;36mcompute_avgmax_imgs\u001b[0;34m(self, verbose)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                 \u001b[0;31m#datas: Batchsize x Numberfilter x Nout x Nout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m                 \u001b[0mdatas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlay_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlay_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    344\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    345\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 346\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lurker.compute_filter_actmax(layer_indx = 0,filter_indxes=[2,3])\n",
    "lurker.compute_filter_actmax(layer_indx=2,filter_indxes=[3,4])\n",
    "lurker.compute_grads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>n02119789</td>\n",
       "      <td>n02119789</td>\n",
       "      <td>1</td>\n",
       "      <td>kit_fox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n02100735</td>\n",
       "      <td>n02100735</td>\n",
       "      <td>2</td>\n",
       "      <td>English_setter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n02110185</td>\n",
       "      <td>n02110185</td>\n",
       "      <td>3</td>\n",
       "      <td>Siberian_husky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n02096294</td>\n",
       "      <td>n02096294</td>\n",
       "      <td>4</td>\n",
       "      <td>Australian_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n02102040</td>\n",
       "      <td>n02102040</td>\n",
       "      <td>5</td>\n",
       "      <td>English_springer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n03063599</td>\n",
       "      <td>n03063599</td>\n",
       "      <td>996</td>\n",
       "      <td>coffee_mug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n04116512</td>\n",
       "      <td>n04116512</td>\n",
       "      <td>997</td>\n",
       "      <td>rubber_eraser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n04325704</td>\n",
       "      <td>n04325704</td>\n",
       "      <td>998</td>\n",
       "      <td>stole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n07831146</td>\n",
       "      <td>n07831146</td>\n",
       "      <td>999</td>\n",
       "      <td>carbonara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n03255030</td>\n",
       "      <td>n03255030</td>\n",
       "      <td>1000</td>\n",
       "      <td>dumbbell</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           file_name  label               title\n",
       "file_name                                      \n",
       "n02119789  n02119789      1             kit_fox\n",
       "n02100735  n02100735      2      English_setter\n",
       "n02110185  n02110185      3      Siberian_husky\n",
       "n02096294  n02096294      4  Australian_terrier\n",
       "n02102040  n02102040      5    English_springer\n",
       "...              ...    ...                 ...\n",
       "n03063599  n03063599    996          coffee_mug\n",
       "n04116512  n04116512    997       rubber_eraser\n",
       "n04325704  n04325704    998               stole\n",
       "n07831146  n07831146    999           carbonara\n",
       "n03255030  n03255030   1000            dumbbell\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_infos = pd.read_csv(\"../data/labels.txt\",sep=\" \",header=None)\n",
    "label_infos.columns = ['file_name','label','title']\n",
    "label_infos.set_index('file_name',inplace=True,drop=False)\n",
    "label_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_infos50 = label_infos.loc[my_dataset.class_to_idx.keys()].copy()\n",
    "dico = my_dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_infos50.label = label_infos50.file_name.apply(lambda x:dico[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>n01440764</td>\n",
       "      <td>n01440764</td>\n",
       "      <td>0</td>\n",
       "      <td>tench</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n01443537</td>\n",
       "      <td>n01443537</td>\n",
       "      <td>1</td>\n",
       "      <td>goldfish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n01484850</td>\n",
       "      <td>n01484850</td>\n",
       "      <td>2</td>\n",
       "      <td>great_white_shark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n01491361</td>\n",
       "      <td>n01491361</td>\n",
       "      <td>3</td>\n",
       "      <td>tiger_shark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n01494475</td>\n",
       "      <td>n01494475</td>\n",
       "      <td>4</td>\n",
       "      <td>hammerhead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n01496331</td>\n",
       "      <td>n01496331</td>\n",
       "      <td>5</td>\n",
       "      <td>electric_ray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n01498041</td>\n",
       "      <td>n01498041</td>\n",
       "      <td>6</td>\n",
       "      <td>stingray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n01514668</td>\n",
       "      <td>n01514668</td>\n",
       "      <td>7</td>\n",
       "      <td>cock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n01514859</td>\n",
       "      <td>n01514859</td>\n",
       "      <td>8</td>\n",
       "      <td>hen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n01518878</td>\n",
       "      <td>n01518878</td>\n",
       "      <td>9</td>\n",
       "      <td>ostrich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n01530575</td>\n",
       "      <td>n01530575</td>\n",
       "      <td>10</td>\n",
       "      <td>brambling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n01531178</td>\n",
       "      <td>n01531178</td>\n",
       "      <td>11</td>\n",
       "      <td>goldfinch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n01532829</td>\n",
       "      <td>n01532829</td>\n",
       "      <td>12</td>\n",
       "      <td>house_finch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n01534433</td>\n",
       "      <td>n01534433</td>\n",
       "      <td>13</td>\n",
       "      <td>junco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n01537544</td>\n",
       "      <td>n01537544</td>\n",
       "      <td>14</td>\n",
       "      <td>indigo_bunting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n01558993</td>\n",
       "      <td>n01558993</td>\n",
       "      <td>15</td>\n",
       "      <td>robin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n01560419</td>\n",
       "      <td>n01560419</td>\n",
       "      <td>16</td>\n",
       "      <td>bulbul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n01580077</td>\n",
       "      <td>n01580077</td>\n",
       "      <td>17</td>\n",
       "      <td>jay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n01582220</td>\n",
       "      <td>n01582220</td>\n",
       "      <td>18</td>\n",
       "      <td>magpie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n01592084</td>\n",
       "      <td>n01592084</td>\n",
       "      <td>19</td>\n",
       "      <td>chickadee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n01601694</td>\n",
       "      <td>n01601694</td>\n",
       "      <td>20</td>\n",
       "      <td>water_ouzel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n01608432</td>\n",
       "      <td>n01608432</td>\n",
       "      <td>21</td>\n",
       "      <td>kite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n01614925</td>\n",
       "      <td>n01614925</td>\n",
       "      <td>22</td>\n",
       "      <td>bald_eagle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n01616318</td>\n",
       "      <td>n01616318</td>\n",
       "      <td>23</td>\n",
       "      <td>vulture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n01622779</td>\n",
       "      <td>n01622779</td>\n",
       "      <td>24</td>\n",
       "      <td>great_grey_owl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n01629819</td>\n",
       "      <td>n01629819</td>\n",
       "      <td>25</td>\n",
       "      <td>European_fire_salamander</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n01630670</td>\n",
       "      <td>n01630670</td>\n",
       "      <td>26</td>\n",
       "      <td>common_newt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n01631663</td>\n",
       "      <td>n01631663</td>\n",
       "      <td>27</td>\n",
       "      <td>eft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n01632458</td>\n",
       "      <td>n01632458</td>\n",
       "      <td>28</td>\n",
       "      <td>spotted_salamander</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n01632777</td>\n",
       "      <td>n01632777</td>\n",
       "      <td>29</td>\n",
       "      <td>axolotl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n01641577</td>\n",
       "      <td>n01641577</td>\n",
       "      <td>30</td>\n",
       "      <td>bullfrog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n01644373</td>\n",
       "      <td>n01644373</td>\n",
       "      <td>31</td>\n",
       "      <td>tree_frog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n01644900</td>\n",
       "      <td>n01644900</td>\n",
       "      <td>32</td>\n",
       "      <td>tailed_frog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n01664065</td>\n",
       "      <td>n01664065</td>\n",
       "      <td>33</td>\n",
       "      <td>loggerhead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n01665541</td>\n",
       "      <td>n01665541</td>\n",
       "      <td>34</td>\n",
       "      <td>leatherback_turtle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n01667114</td>\n",
       "      <td>n01667114</td>\n",
       "      <td>35</td>\n",
       "      <td>mud_turtle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n01667778</td>\n",
       "      <td>n01667778</td>\n",
       "      <td>36</td>\n",
       "      <td>terrapin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n01669191</td>\n",
       "      <td>n01669191</td>\n",
       "      <td>37</td>\n",
       "      <td>box_turtle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n01675722</td>\n",
       "      <td>n01675722</td>\n",
       "      <td>38</td>\n",
       "      <td>banded_gecko</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n01677366</td>\n",
       "      <td>n01677366</td>\n",
       "      <td>39</td>\n",
       "      <td>common_iguana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n01682714</td>\n",
       "      <td>n01682714</td>\n",
       "      <td>40</td>\n",
       "      <td>American_chameleon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n01685808</td>\n",
       "      <td>n01685808</td>\n",
       "      <td>41</td>\n",
       "      <td>whiptail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n01687978</td>\n",
       "      <td>n01687978</td>\n",
       "      <td>42</td>\n",
       "      <td>agama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n01688243</td>\n",
       "      <td>n01688243</td>\n",
       "      <td>43</td>\n",
       "      <td>frilled_lizard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n01689811</td>\n",
       "      <td>n01689811</td>\n",
       "      <td>44</td>\n",
       "      <td>alligator_lizard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n01692333</td>\n",
       "      <td>n01692333</td>\n",
       "      <td>45</td>\n",
       "      <td>Gila_monster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n01693334</td>\n",
       "      <td>n01693334</td>\n",
       "      <td>46</td>\n",
       "      <td>green_lizard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n01694178</td>\n",
       "      <td>n01694178</td>\n",
       "      <td>47</td>\n",
       "      <td>African_chameleon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n01695060</td>\n",
       "      <td>n01695060</td>\n",
       "      <td>48</td>\n",
       "      <td>Komodo_dragon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n01697457</td>\n",
       "      <td>n01697457</td>\n",
       "      <td>49</td>\n",
       "      <td>African_crocodile</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           file_name  label                     title\n",
       "file_name                                            \n",
       "n01440764  n01440764      0                     tench\n",
       "n01443537  n01443537      1                  goldfish\n",
       "n01484850  n01484850      2         great_white_shark\n",
       "n01491361  n01491361      3               tiger_shark\n",
       "n01494475  n01494475      4                hammerhead\n",
       "n01496331  n01496331      5              electric_ray\n",
       "n01498041  n01498041      6                  stingray\n",
       "n01514668  n01514668      7                      cock\n",
       "n01514859  n01514859      8                       hen\n",
       "n01518878  n01518878      9                   ostrich\n",
       "n01530575  n01530575     10                 brambling\n",
       "n01531178  n01531178     11                 goldfinch\n",
       "n01532829  n01532829     12               house_finch\n",
       "n01534433  n01534433     13                     junco\n",
       "n01537544  n01537544     14            indigo_bunting\n",
       "n01558993  n01558993     15                     robin\n",
       "n01560419  n01560419     16                    bulbul\n",
       "n01580077  n01580077     17                       jay\n",
       "n01582220  n01582220     18                    magpie\n",
       "n01592084  n01592084     19                 chickadee\n",
       "n01601694  n01601694     20               water_ouzel\n",
       "n01608432  n01608432     21                      kite\n",
       "n01614925  n01614925     22                bald_eagle\n",
       "n01616318  n01616318     23                   vulture\n",
       "n01622779  n01622779     24            great_grey_owl\n",
       "n01629819  n01629819     25  European_fire_salamander\n",
       "n01630670  n01630670     26               common_newt\n",
       "n01631663  n01631663     27                       eft\n",
       "n01632458  n01632458     28        spotted_salamander\n",
       "n01632777  n01632777     29                   axolotl\n",
       "n01641577  n01641577     30                  bullfrog\n",
       "n01644373  n01644373     31                 tree_frog\n",
       "n01644900  n01644900     32               tailed_frog\n",
       "n01664065  n01664065     33                loggerhead\n",
       "n01665541  n01665541     34        leatherback_turtle\n",
       "n01667114  n01667114     35                mud_turtle\n",
       "n01667778  n01667778     36                  terrapin\n",
       "n01669191  n01669191     37                box_turtle\n",
       "n01675722  n01675722     38              banded_gecko\n",
       "n01677366  n01677366     39             common_iguana\n",
       "n01682714  n01682714     40        American_chameleon\n",
       "n01685808  n01685808     41                  whiptail\n",
       "n01687978  n01687978     42                     agama\n",
       "n01688243  n01688243     43            frilled_lizard\n",
       "n01689811  n01689811     44          alligator_lizard\n",
       "n01692333  n01692333     45              Gila_monster\n",
       "n01693334  n01693334     46              green_lizard\n",
       "n01694178  n01694178     47         African_chameleon\n",
       "n01695060  n01695060     48             Komodo_dragon\n",
       "n01697457  n01697457     49         African_crocodile"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_infos50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_infos50.to_csv(\"../data/labels50.txt\",header=None,sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_infos50 = pd.DataFrame(columns=label_infos.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [file_name, label, title]\n",
       "Index: []"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_infos50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label      449\n",
      "title    tench\n",
      "Name: n01440764, dtype: object\n",
      "label         450\n",
      "title    goldfish\n",
      "Name: n01443537, dtype: object\n",
      "label                  442\n",
      "title    great_white_shark\n",
      "Name: n01484850, dtype: object\n",
      "label            443\n",
      "title    tiger_shark\n",
      "Name: n01491361, dtype: object\n",
      "label           444\n",
      "title    hammerhead\n",
      "Name: n01494475, dtype: object\n",
      "label             445\n",
      "title    electric_ray\n",
      "Name: n01496331, dtype: object\n",
      "label         446\n",
      "title    stingray\n",
      "Name: n01498041, dtype: object\n",
      "label     383\n",
      "title    cock\n",
      "Name: n01514668, dtype: object\n",
      "label    384\n",
      "title    hen\n",
      "Name: n01514859, dtype: object\n",
      "label        385\n",
      "title    ostrich\n",
      "Name: n01518878, dtype: object\n",
      "label          386\n",
      "title    brambling\n",
      "Name: n01530575, dtype: object\n",
      "label          387\n",
      "title    goldfinch\n",
      "Name: n01531178, dtype: object\n",
      "label            388\n",
      "title    house_finch\n",
      "Name: n01532829, dtype: object\n",
      "label      389\n",
      "title    junco\n",
      "Name: n01534433, dtype: object\n",
      "label               390\n",
      "title    indigo_bunting\n",
      "Name: n01537544, dtype: object\n",
      "label      391\n",
      "title    robin\n",
      "Name: n01558993, dtype: object\n",
      "label       392\n",
      "title    bulbul\n",
      "Name: n01560419, dtype: object\n",
      "label    393\n",
      "title    jay\n",
      "Name: n01580077, dtype: object\n",
      "label       394\n",
      "title    magpie\n",
      "Name: n01582220, dtype: object\n",
      "label          395\n",
      "title    chickadee\n",
      "Name: n01592084, dtype: object\n",
      "label            396\n",
      "title    water_ouzel\n",
      "Name: n01601694, dtype: object\n",
      "label     397\n",
      "title    kite\n",
      "Name: n01608432, dtype: object\n",
      "label           398\n",
      "title    bald_eagle\n",
      "Name: n01614925, dtype: object\n",
      "label        399\n",
      "title    vulture\n",
      "Name: n01616318, dtype: object\n",
      "label               400\n",
      "title    great_grey_owl\n",
      "Name: n01622779, dtype: object\n",
      "label                         494\n",
      "title    European_fire_salamander\n",
      "Name: n01629819, dtype: object\n",
      "label            495\n",
      "title    common_newt\n",
      "Name: n01630670, dtype: object\n",
      "label    496\n",
      "title    eft\n",
      "Name: n01631663, dtype: object\n",
      "label                   497\n",
      "title    spotted_salamander\n",
      "Name: n01632458, dtype: object\n",
      "label        498\n",
      "title    axolotl\n",
      "Name: n01632777, dtype: object\n",
      "label         499\n",
      "title    bullfrog\n",
      "Name: n01641577, dtype: object\n",
      "label          500\n",
      "title    tree_frog\n",
      "Name: n01644373, dtype: object\n",
      "label            501\n",
      "title    tailed_frog\n",
      "Name: n01644900, dtype: object\n",
      "label           458\n",
      "title    loggerhead\n",
      "Name: n01664065, dtype: object\n",
      "label                   459\n",
      "title    leatherback_turtle\n",
      "Name: n01665541, dtype: object\n",
      "label           460\n",
      "title    mud_turtle\n",
      "Name: n01667114, dtype: object\n",
      "label         461\n",
      "title    terrapin\n",
      "Name: n01667778, dtype: object\n",
      "label           462\n",
      "title    box_turtle\n",
      "Name: n01669191, dtype: object\n",
      "label             463\n",
      "title    banded_gecko\n",
      "Name: n01675722, dtype: object\n",
      "label              464\n",
      "title    common_iguana\n",
      "Name: n01677366, dtype: object\n",
      "label                   465\n",
      "title    American_chameleon\n",
      "Name: n01682714, dtype: object\n",
      "label         466\n",
      "title    whiptail\n",
      "Name: n01685808, dtype: object\n",
      "label      467\n",
      "title    agama\n",
      "Name: n01687978, dtype: object\n",
      "label               468\n",
      "title    frilled_lizard\n",
      "Name: n01688243, dtype: object\n",
      "label                 469\n",
      "title    alligator_lizard\n",
      "Name: n01689811, dtype: object\n",
      "label             470\n",
      "title    Gila_monster\n",
      "Name: n01692333, dtype: object\n",
      "label             471\n",
      "title    green_lizard\n",
      "Name: n01693334, dtype: object\n",
      "label                  472\n",
      "title    African_chameleon\n",
      "Name: n01694178, dtype: object\n",
      "label              473\n",
      "title    Komodo_dragon\n",
      "Name: n01695060, dtype: object\n",
      "label                  475\n",
      "title    African_crocodile\n",
      "Name: n01697457, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for key,value in my_dataset.class_to_idx.items():\n",
    "    print(label_infos.loc[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset = ImageFolderWithPaths(\"../data/50classes/\",transform=preprocess)\n",
    "data_loader = torch.utils.data.DataLoader(my_dataset, batch_size=1, shuffle=True)\n",
    "#for j,(datas,labels,paths) in enumerate(self.data_loader):\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torchlurk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision.transforms import ToTensor,ToPILImage\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.utils import save_image\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "\n",
    "from ImageFolderWithPaths import ImageFolderWithPaths\n",
    "from Projector import Projector\n",
    "\n",
    "#libraries\n",
    "sys.path.insert(1, '../lib/pytorch-cnn-visualizations/src/')\n",
    "from cnn_layer_visualization import CNNLayerVisualization\n",
    "from layer_activation_with_guided_backprop import GuidedBackprop\n",
    "from misc_functions import save_gradient_images\n",
    "from misc_funcs import create_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = lurker.model_info[0]['filters'][0]['histo_counts_max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 50 artists>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAALvUlEQVR4nO3db4hldR3H8c/H3S2jBFPHCv80RRJJpMZgwkbYIrK6kj0oKCp8UMwTAwVFtCdRENQTswc9GUoy+ivqlij9WUqxoKwZtVpbJYutRHFHTNQnxuqnB/dMO453955175n7vee+XzDMPeeevfP97T33M7/7PefccRIBAOo6btIFAACOjKAGgOIIagAojqAGgOIIagAobmsXD3rKKadkfn6+i4cGgF5aWVl5OsncsPs6Cer5+XktLy938dAA0Eu2/3m4+2h9AEBxBDUAFEdQA0BxBDUAFEdQA0BxBDUAFEdQA0BxBDUAFEdQA0BxnVyZ2IX56+9+1br9X901gUoAYHMxowaA4ghqACiOoAaA4ghqACiOoAaA4ghqACiOoAaA4ghqACiOoAaA4ghqACiOoAaA4ghqACiOoAaA4ghqACiOoAaA4ghqAChuav5wADAp/NEKTBozagAojqAGgOIIagAojqAGgOJaHUy0vV/S85JeknQwyUKXRQEADjmasz4+nOTpzioBAAxF6wMAimsb1JH0S9srtheHbWB70fay7eXV1dXxVQgAM65tUG9P8n5Jl0i60vaHNm6QZCnJQpKFubm5sRYJALOsVVAneaL5fkDSbknnd1kUAOCQkQcTbb9R0nFJnm9uXyzpy51XBnRk4yXhXA6O6tqc9fEWSbttr23/gyQ/77QqAMD/jQzqJP+QdM4m1AIAGIJPzzsGvIUGsBk4jxoAiiOoAaA4ghoAiiOoAaA4ghoAiiOoAaA4ghoAiiOoAaA4ghoAiiOoAaA4ghoAiiOoAaA4ghoAiiOoAaA4ghoAiiOoAaA4ghoAiiOoAaA4ghoAiiOoAaA4ghoAiiOoAaA4ghoAiiOoAaA4ghoAiiOoAaC41kFte4vtB23f1WVBAIBXOpoZ9VWS9nVVCABguFZBbft0SbskfavbcgAAG7WdUd8k6TpJL3dYCwBgiJFBbfsySQeSrIzYbtH2su3l1dXVsRUIALOuzYx6u6SP2N4v6UeSdtj+3saNkiwlWUiyMDc3N+YyAWB2bR21QZIbJN0gSbYvlHRtkk93XBdQ3vz1d79q3f6v7ppAJeg7zqMGgOJGzqjXS3KvpHs7qQQAMBQzagAojqAGgOIIagAojqAGgOIIagAojqAGgOKO6vQ8ALOBi3lqYUYNAMX1dkZ9uBkBMwUA04YZNQAUR1ADQHEENQAU19se9STRBwcwTsyoAaA4ghoAipv61kfXbQbaGAAmjRk1ABRHUANAcQQ1ABQ39T1qYNpxHASjENTAlCHYZw+tDwAojqAGgOIIagAojh410KD3O3k8B8MR1MAMIxinA60PACiOoAaA4ka2PmwfL+k+Sa9vtr8tyRe7LgyHN663q0d6nI338XYY06ZPbZ02PeoXJe1I8oLtbZJ+a/tnSX7fcW0AALUI6iSR9EKzuK35SlcF9em3IACMQ6uzPmxvkbQi6V2Svpnk/iHbLEpalKQzzzxznDXiGPHLbzrxvGFNq6BO8pKkc22fKGm37fcm2bthmyVJS5K0sLDQ2Yx7llR8oVasCei7ozqPOsmztu+VtFPS3hGbTxUCqLZpen6mqVZMh5Gn59mea2bSsv0GSRdJeqTrwgAAA21m1G+TdEvTpz5O0q1J7uq2LADYXJXfCbU56+PPks7bhFqAXqscBKiNz/rAVCP82uH/aboR1CiFQJlOPG/d4rM+AKA4ghoAiqP1UQBvGwEcCUENoDMVJyEVaxqFoN5E07iDAJg8ghrAVJuFCRBB3SOzsMOiH9hXjw5BjbHghQd0h6AGMBVm+c/DEdQAWuOd02QQ1OgUL2zg2HFlIgAUR1ADQHEENQAUR48aAI6gwnEWZtQAUBxBDQDFEdQAUBw9avRShb4iMC7MqAGgOIIaAIojqAGgOHrUAPAabOZxEGbUAFAcM2qgR2b5M5v7bGRQ2z5D0nclvVXSy5KWknyj68LQb5w+B7TXZkZ9UNI1SR6wfYKkFdt7kvy149oAAGrRo07yZJIHmtvPS9on6bSuCwMADBzVwUTb85LOk3T/kPsWbS/bXl5dXR1PdQCA9kFt+02Sbpd0dZLnNt6fZCnJQpKFubm5cdYIADOtVVDb3qZBSH8/yR3dlgQAWG9kUNu2pG9L2pfkxu5LAgCs12ZGvV3SZyTtsP1Q83Vpx3UBABojT89L8ltJ3oRaAABDcAk5ABRHUANAcQQ1ABRHUANAcQQ1ABRHUANAcQQ1ABRHUANAcQQ1ABRHUANAcQQ1ABRHUANAcQQ1ABRHUANAcQQ1ABRHUANAcQQ1ABRHUANAcQQ1ABRHUANAcQQ1ABRHUANAcQQ1ABRHUANAcQQ1ABRHUANAcQQ1ABQ3Mqht32z7gO29m1EQAOCV2syovyNpZ8d1AAAOY2RQJ7lP0jObUAsAYIix9ahtL9petr28uro6rocFgJk3tqBOspRkIcnC3NzcuB4WAGYeZ30AQHEENQAU1+b0vB9K+p2kd9t+3PZnuy8LALBm66gNknxyMwoBAAxH6wMAiiOoAaA4ghoAiiOoAaA4ghoAiiOoAaA4ghoAiiOoAaA4ghoAiiOoAaA4ghoAiiOoAaA4ghoAiiOoAaA4ghoAiiOoAaA4ghoAiiOoAaA4ghoAiiOoAaA4ghoAiiOoAaA4ghoAiiOoAaA4ghoAiiOoAaA4ghoAiiOoAaC4VkFte6ftR20/Zvv6rosCABwyMqhtb5H0TUmXSDpb0idtn911YQCAgTYz6vMlPZbkH0n+K+lHki7vtiwAwBonOfIG9sck7UzyuWb5M5I+kOTzG7ZblLTYLL5b0qPHWNspkp4+xseYNox5dsziuBnzkb09ydywO7a2+Mcesu5V6Z5kSdJSy4JG/1B7OcnCuB5vGjDm2TGL42bMr12b1sfjks5Yt3y6pCeO9QcDANppE9R/lHSW7XfYfp2kT0i6s9uyAABrRrY+khy0/XlJv5C0RdLNSR7uvLIxtlGmCGOeHbM4bsb8Go08mAgAmCyuTASA4ghqACiuZFDPwiXrtm+2fcD23nXrTrK9x/bfmu9vnmSN42b7DNv32N5n+2HbVzXreztu28fb/oPtPzVj/lKz/h2272/G/OPmQH2v2N5i+0HbdzXLvR6z7f22/2L7IdvLzbqx7NvlgnqGLln/jqSdG9ZdL+lXSc6S9KtmuU8OSromyXskXSDpyua57fO4X5S0I8k5ks6VtNP2BZK+JunrzZj/I+mzE6yxK1dJ2rdueRbG/OEk5647d3os+3a5oNaMXLKe5D5Jz2xYfbmkW5rbt0j66KYW1bEkTyZ5oLn9vAYv4tPU43Fn4IVmcVvzFUk7JN3WrO/VmCXJ9umSdkn6VrNs9XzMhzGWfbtiUJ8m6d/rlh9v1s2CtyR5UhqEmqRTJ1xPZ2zPSzpP0v3q+bibFsBDkg5I2iPp75KeTXKw2aSP+/hNkq6T9HKzfLL6P+ZI+qXtleYjNaQx7dttLiHfbK0uWcf0sv0mSbdLujrJc4PJVn8leUnSubZPlLRb0nuGbba5VXXH9mWSDiRZsX3h2uohm/ZmzI3tSZ6wfaqkPbYfGdcDV5xRz/Il60/ZfpskNd8PTLiesbO9TYOQ/n6SO5rVvR+3JCV5VtK9GvTnT7S9NlHq2z6+XdJHbO/XoHW5Q4MZdp/HrCRPNN8PaPAL+XyNad+uGNSzfMn6nZKuaG5fIemnE6xl7Jo+5bcl7Uty47q7ejtu23PNTFq23yDpIg168/dI+lizWa/GnOSGJKcnmdfg9fvrJJ9Sj8ds+422T1i7LeliSXs1pn275JWJti/V4Dfw2iXrX5lwSWNn+4eSLtTgYxCfkvRFST+RdKukMyX9S9LHk2w84Di1bH9Q0m8k/UWHepdf0KBP3ctx236fBgeRtmgwMbo1yZdtv1OD2eZJkh6U9OkkL06u0m40rY9rk1zW5zE3Y9vdLG6V9IMkX7F9ssawb5cMagDAIRVbHwCAdQhqACiOoAaA4ghqACiOoAaA4ghqACiOoAaA4v4HpMM8iTGC4OsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(temp.keys(),temp.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 3.0275797353071323,\n",
       " 1: 5.704389840364456,\n",
       " 2: 3.4428354276193156,\n",
       " 3: 3.62728121686489,\n",
       " 4: 3.641517531227421,\n",
       " 5: 2.949599999647874,\n",
       " 6: 3.4478156125103987,\n",
       " 7: 4.841821117401123,\n",
       " 8: 3.527176117897034,\n",
       " 9: 2.674733595414595,\n",
       " 10: 2.7130753369558427,\n",
       " 11: 2.9628082766677393,\n",
       " 12: 3.068583874141469,\n",
       " 13: 2.6094443276524544,\n",
       " 14: 3.008675898824419,\n",
       " 15: 3.065946536404746,\n",
       " 16: 3.0700256614124073,\n",
       " 17: 2.9758569536537958,\n",
       " 18: 2.576060212891677,\n",
       " 19: 2.49889536337419,\n",
       " 20: 2.09042069988866,\n",
       " 21: 2.814309484147011,\n",
       " 22: 2.952640834976645,\n",
       " 23: 2.8222126324971515,\n",
       " 24: 2.2741087462220873,\n",
       " 25: 4.916948327651391,\n",
       " 26: 3.196870964506398,\n",
       " 27: 5.23678123432657,\n",
       " 28: 3.9462363066211825,\n",
       " 29: 2.953754875124717,\n",
       " 30: 2.86098082418795,\n",
       " 31: 3.3277220044817244,\n",
       " 32: 3.010376475952767,\n",
       " 33: 3.2998422036568322,\n",
       " 34: 2.1258731935475326,\n",
       " 35: 2.842860703284924,\n",
       " 36: 3.14968400577019,\n",
       " 37: 3.688986506727007,\n",
       " 38: 2.5284329135462924,\n",
       " 39: 2.79762544631958,\n",
       " 40: 2.703365809989698,\n",
       " 41: 2.610209487951719,\n",
       " 42: 3.1972756032590515,\n",
       " 43: 2.5604150518774986,\n",
       " 44: 2.625797671576341,\n",
       " 45: 3.0852365684509278,\n",
       " 46: 2.6951778857938704,\n",
       " 47: 2.8912853452894423,\n",
       " 48: 2.400273665137913,\n",
       " 49: 2.1834066659212112}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(obj):\n",
    "    \"\"\"\n",
    "    plot the histogram of a filter\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lurk():\n",
    "    def __init__(self,model,preprocess,save_comp_img_path,save_json_pathname,load_path=None,img_path = \"../data/exsmallimagenet/\"):\n",
    "        self.model = model\n",
    "        self.preprocess = preprocess\n",
    "        # allow to run reduced computations\n",
    "        self.SINGLE_LAYER = True\n",
    "        #number of layers we compute shit for\n",
    "        self.N_LAYERS = 0\n",
    "        #number of filters we compute images for\n",
    "        self.N_REDUCE = 22\n",
    "        #path to the numb image\n",
    "        self.NUMB_PATH = \"../data/tinyimagenet/numb.png\"\n",
    "        # how many top pictures we keep\n",
    "        self.TOP_AVG_SIGN = 4\n",
    "        #number of favourites images per filter\n",
    "        self.N_FAV = 4\n",
    "        # number of max spikes images per filter\n",
    "        self.N_FAV_MAX = 3\n",
    "        #where to save/load the saved models\n",
    "        self.ORIGIN_PATH = save_comp_img_path\n",
    "        #where to access the data\n",
    "        self.DATA_PATH = \"../data/\"\n",
    "        #where to access the tinyimagenet dataset\n",
    "        self.TINY_PATH = os.path.join(self.DATA_PATH,\"tinyimagenet/\")\n",
    "        #which folder to get the data from\n",
    "        #self.IMGS_PATH = os.path.join(self.DATA_PATH,\"exsmallimagenet\")\n",
    "        self.IMGS_PATH = img_path\n",
    "\n",
    "        #where to save the json\n",
    "        self.SAVE_PATHNAME_JSON = save_json_pathname\n",
    "        \n",
    "        self.my_dataset = ImageFolderWithPaths(self.IMGS_PATH,transform=self.preprocess)\n",
    "        self.CLASS2INDX = self.my_dataset.class_to_idx\n",
    "        if load_path is not None:\n",
    "            self.model_info = self.load_from_json(load_path)\n",
    "        else:\n",
    "            self.model_info = self.build_model()\n",
    "        create_folders(self.ORIGIN_PATH,[\"avg_grads\",\"max_grads\",\"cropped\",\"cropped_grad\",\"max_activ\"],self.model_info)\n",
    "        \n",
    "        \n",
    "        self.data_loader = torch.utils.data.DataLoader(self.my_dataset, batch_size=1, shuffle=True)\n",
    "        self.class_counts = dict(zip(self.CLASS2INDX.values(),[0] *len(self.CLASS2INDX)))\n",
    "        #initiate the number of counts for \n",
    "        self.init_class_counts(self.CLASS2INDX, self.IMGS_PATH,self.class_counts)\n",
    "        \n",
    "    def init_class_counts(self,class_to_idx,src_path,obj):\n",
    "        \"\"\"\n",
    "        create the dictionary which counts the number of images per classes in the dataset\n",
    "        \"\"\"\n",
    "        for subfold in os.listdir(src_path):\n",
    "            subfold_path = os.path.join(src_path,subfold)\n",
    "            count = len([name for name in os.listdir(subfold_path)])\n",
    "            classo = class_to_idx[subfold]\n",
    "            obj[classo] += count\n",
    "        \n",
    "    def save_to_json(self):\n",
    "        model_info2 = deepcopy(self.model_info)\n",
    "        for lay_info in model_info2:\n",
    "            if (isinstance(lay_info['lay'],nn.Conv2d)):\n",
    "                del lay_info['deproj']\n",
    "            del lay_info['lay']\n",
    "        with open(self.SAVE_PATHNAME_JSON, 'w') as fout:\n",
    "            json.dump(model_info2, fout, indent = 2)\n",
    "        print(\"saving done!\") \n",
    "        \n",
    "    def load_from_json(self,load_path):\n",
    "        #TODO: ensure that the imgpaths in the loaded file do exist\n",
    "        layers = []\n",
    "        with open(load_path, 'r') as fin:\n",
    "            model_info = json.load(fin)\n",
    "        for lay_info,layer in zip(model_info,self.model.features):\n",
    "            lay_info['lay'] = layer\n",
    "            if (isinstance(layer,(nn.Conv2d,nn.MaxPool2d))):\n",
    "                layers.append(layer)\n",
    "            if (isinstance(layer,nn.Conv2d)):\n",
    "                lay_info['deproj'] = Projector(deepcopy(layers),224)\n",
    "        print(\"Loading done!\") \n",
    "        return model_info\n",
    "    \n",
    "    def build_model(self):\n",
    "        model_info = []\n",
    "        layers = []\n",
    "        #construct the data structure\n",
    "        for layer in list(self.model.features.named_children()):\n",
    "            lay_info = {'id':layer[0],\n",
    "                      'lay':layer[1],\n",
    "                      'name':str(layer[1]).split('(')[0] + \"_\" + str(layer[0]) \n",
    "                    }\n",
    "            if (isinstance(layer[1],(nn.Conv2d,nn.MaxPool2d))):\n",
    "                layers.append(layer[1])\n",
    "            if (isinstance(lay_info['lay'],nn.Conv2d)):     \n",
    "                n_input = lay_info['lay'].in_channels\n",
    "                n_output = lay_info['lay'].out_channels\n",
    "                lay_info['n_input'] = n_input\n",
    "                lay_info['n_output'] = n_output\n",
    "                lay_info['deproj'] = Projector(deepcopy(layers),224)\n",
    "                lay_info[\"filters\"] = []\n",
    "                for i in range(n_output):\n",
    "                    lay_info[\"filters\"].append({\n",
    "                        \"id\":i,\n",
    "                        \"spikes\":[0 for i in range(self.N_FAV)],\n",
    "                        \"fav_imgs\":[self.NUMB_PATH for i in range(self.N_FAV)],\n",
    "                        \"grad_path_avg\":[self.NUMB_PATH for i in range(self.N_FAV)],\n",
    "                        \"max_spikes\":[0 for i in range(self.N_FAV_MAX)],\n",
    "                        \"max_slices\":[[[0,0],[0,0]]for i in range(self.N_FAV_MAX)],\n",
    "                        \"max_imgs\":[self.NUMB_PATH for i in range(self.N_FAV_MAX)],\n",
    "                        \"grad_path_max\":[self.NUMB_PATH for i in range(self.N_FAV_MAX)],\n",
    "                        \"actmax_im\":self.NUMB_PATH,\n",
    "                        \"histo_counts_max\":dict(zip(self.CLASS2INDX.values(),[0] *len(self.CLASS2INDX))),\n",
    "                        \"histo_counts_avg\":dict(zip(self.CLASS2INDX.values(),[0] *len(self.CLASS2INDX)))\n",
    "                    })\n",
    "            elif (type(lay_info['lay']) == nn.Linear):\n",
    "                    n_input = lay_info['lay'].in_features\n",
    "                    n_output = lay_info['lay'].out_features\n",
    "                    lay_info['n_output'] = n_output\n",
    "                    #lay_info[\"filters\"] = [empty_filter.copy() for i in range(n_output)]\n",
    "            model_info.append(lay_info)\n",
    "        return model_info\n",
    "    def get_filt_string(self,dir_type,layer_name,filter_id):\n",
    "        \"\"\"\n",
    "        return the path to the appropriate folder\n",
    "        \"\"\"\n",
    "        return os.path.join(self.ORIGIN_PATH,dir_type,layer_name,str(filter_id))\n",
    "    \n",
    "    def extract_name(self,img_path,ext='.jpg'):\n",
    "        \"\"\"\n",
    "        extract the name of the imgpath and add the extension\n",
    "        \"\"\"\n",
    "        jpg_name = img_path.split(\"/\")[-1]\n",
    "        img_name = jpg_name.split(\".\")[0] + ext\n",
    "        return img_name\n",
    "    #Watch out which path you give for the IMGS_PATH\n",
    "\n",
    "    def sort_filters_spikes(self):\n",
    "        \"\"\"\n",
    "        sorts the spikes and respective paths of the filters inplace\n",
    "        \"\"\"\n",
    "        for lay_info in self.model_info:\n",
    "            if (isinstance(lay_info['lay'],nn.Conv2d)):\n",
    "                for filtr in lay_info['filters']:\n",
    "                    max_indx = np.argsort(filtr[\"max_spikes\"])[::-1]\n",
    "                    filtr[\"max_spikes\"] = np.array(filtr[\"max_spikes\"])[max_indx].tolist()\n",
    "                    filtr[\"max_imgs\"] = np.array(filtr[\"max_imgs\"])[max_indx].tolist()\n",
    "                    filtr[\"max_slices\"] = np.array(filtr[\"max_slices\"])[max_indx].tolist()\n",
    "\n",
    "                    avg_indx = np.argsort(filtr[\"spikes\"])[::-1]\n",
    "                    filtr[\"spikes\"] = np.array(filtr[\"spikes\"])[avg_indx].tolist()\n",
    "                    filtr[\"fav_imgs\"] = np.array(filtr[\"fav_imgs\"])[avg_indx].tolist()\n",
    "\n",
    "    def reset_histos(self):\n",
    "        \"\"\"\n",
    "        reset the counts for the histograms counts\n",
    "        \"\"\"\n",
    "        for lay_info in self.model_info:\n",
    "            if (not isinstance(lay_info['lay'],nn.Conv2d)):\n",
    "                continue\n",
    "            for filt in lay_info['filters']:\n",
    "                filt['histo_counts_max'] = dict(zip(self.CLASS2INDX.values(),[0] *len(self.CLASS2INDX)))\n",
    "                filt['histo_counts_avg'] = dict(zip(self.CLASS2INDX.values(),[0] *len(self.CLASS2INDX)))\n",
    "    def normalize_histos(self):\n",
    "        \"\"\"\n",
    "        average the counts of the histograms wrt to the number of samples in the classes of the dataset\n",
    "        \"\"\"\n",
    "        for lay_info in self.model_info:\n",
    "            if (not isinstance(lay_info['lay'],nn.Conv2d)):\n",
    "                continue\n",
    "            for filt in lay_info['filters']:\n",
    "                for key in filt['histo_counts_max'].keys():\n",
    "                    filt['histo_counts_max'][key] /= self.class_counts[key]\n",
    "                for key in filt['histo_counts_avg'].keys():\n",
    "                    filt['histo_counts_avg'][key] /= self.class_counts[key]\n",
    "    def compute_avgmax_imgs(self,verbose = False):\n",
    "        \"\"\"\n",
    "        compute the average and max images for all the layers of the model_info such that each filter of each layer knows what are\n",
    "        its favourite images (write down the link to the avg/max images in the json)\n",
    "        \"\"\"\n",
    "        self.reset_histos()\n",
    "        for j,(datas,labels,paths) in enumerate(self.data_loader):\n",
    "            print(\"Progression update favimgs:{:.2f} %\".format(j/len(self.data_loader) * 100))\n",
    "            for i,lay_info in enumerate(self.model_info):\n",
    "                clear_output(wait=True)\n",
    "                if verbose:\n",
    "                    print(\"AvgMax update:{}/{}:{:.2f} %..\".format(i,len(self.model_info),100*j/ len(data_loader)))\n",
    "\n",
    "                #datas: Batchsize x Numberfilter x Nout x Nout\n",
    "                datas = lay_info['lay'](datas)\n",
    "                if (not isinstance(lay_info['lay'],nn.Conv2d) ):\n",
    "                    continue\n",
    "                if (i >self.N_LAYERS and self.SINGLE_LAYER):\n",
    "                    break\n",
    "\n",
    "                batch_size = datas.size(0)\n",
    "                filter_nb = datas.size(1)\n",
    "                width = datas.size(3)\n",
    "\n",
    "                #set_trace()\n",
    "                #spikes: Batchsize x Filternumber\n",
    "                max_spikes,max_pos = datas.view([batch_size,filter_nb,-1]).max(dim = 2)\n",
    "                max_rows = max_pos / width\n",
    "                max_cols = max_pos % width\n",
    "\n",
    "                avg_spikes = datas.view([batch_size,filter_nb,-1]).mean(dim = 2)\n",
    "                self.update_filters_maxim(lay_info,max_spikes,paths,max_rows,max_cols,labels)\n",
    "                self.update_filters_favim(lay_info,avg_spikes,paths,labels)\n",
    "                #save the whole model\n",
    "        self.normalize_histos()\n",
    "        self.sort_filters_spikes()\n",
    "        self.save_cropped()\n",
    "        self.save_to_json()\n",
    "\n",
    "    def update_filters_maxim(self,lay_info,batch_spikes,paths,max_rows,max_cols,labels):\n",
    "        #as many spikes in batch_spikes as there are samples in batch\n",
    "        for spikes,path,label,rows,cols in zip(batch_spikes,paths,labels,max_rows,max_cols):\n",
    "            #at this stage there are as many spike in spikes as there are filters\n",
    "            for k,(filt,spike,row,col) in enumerate(zip(lay_info[\"filters\"],spikes.detach().numpy(),rows,cols)):\n",
    "                #compute the histogram with maximal values\n",
    "                filt[\"histo_counts_max\"][label.item()] += float(spike)\n",
    "                #compute the minimum spike for the filter\n",
    "                min_indx = np.argmin(filt[\"max_spikes\"])\n",
    "                min_spike = min(filt[\"max_spikes\"])\n",
    "                \n",
    "                if (spike > min_spike and not (path in filt[\"max_imgs\"])):\n",
    "                    ((x1,x2),(y1,y2)) = lay_info[\"deproj\"].chain(((row.item(),row.item()),(col.item(),col.item())))\n",
    "                    assert(isinstance(x1,int) and isinstance(x2,int) and isinstance(y1,int) and isinstance(y2,int))\n",
    "                    filt[\"max_slices\"][min_indx] = ((x1,x2),(y1,y2))\n",
    "                    filt[\"max_imgs\"][min_indx] = path\n",
    "                    filt[\"max_spikes\"][min_indx] = float(spike)\n",
    "                    \n",
    "    def update_filters_favim(self,lay_info,batch_spikes,paths,labels):\n",
    "        #as many spikes in batch_spikes as there are samples in batch\n",
    "        for spikes,path,label in zip(batch_spikes,paths,labels):\n",
    "            #at this stage there are as many spike in spikes as there are filters\n",
    "            for k,(filt,spike) in enumerate(zip(lay_info[\"filters\"],spikes.detach().numpy())):\n",
    "                #compute the histogram with avg values\n",
    "                filt[\"histo_counts_avg\"][label.item()] += float(spike)\n",
    "                #compute the minimum spike for the filter\n",
    "                min_indx = np.argmin(filt[\"spikes\"])\n",
    "                min_spike = min(filt[\"spikes\"])\n",
    "                if (spike > min_spike and not (path in filt[\"fav_imgs\"])):\n",
    "                    filt[\"fav_imgs\"][min_indx] = path\n",
    "                    filt[\"spikes\"][min_indx] = float(spike)\n",
    "                \n",
    "\n",
    "    def save_cropped(self,grad = False,verbose=False):\n",
    "        \"\"\"\n",
    "        iterate on the model_info to save a cropped version of the images\n",
    "        Args:\n",
    "            grad(Bool): whether to save the gradients versions\n",
    "        \"\"\"\n",
    "        if grad:\n",
    "            filtrlist = \"grad_path_max\" \n",
    "            folder = \"cropped_grad\"\n",
    "        else:\n",
    "            filtrlist = \"max_imgs\"\n",
    "            folder = \"cropped\"\n",
    "\n",
    "        for i,lay_info in enumerate(self.model_info):\n",
    "            clear_output(wait=True)\n",
    "            if verbose:\n",
    "                print(\"Progression:{} %\".format(i/len(model_info)*100))\n",
    "            if (not isinstance(lay_info['lay'],nn.Conv2d)):\n",
    "                continue\n",
    "            for filtr in lay_info['filters']:\n",
    "                for path,slices in zip(filtr[filtrlist],filtr['max_slices']):\n",
    "                    if (path == self.NUMB_PATH):\n",
    "                        continue\n",
    "                    cropped = ToTensor()(Image.open(path))\n",
    "                    ((x1,x2),(y1,y2)) = slices\n",
    "                    cropped = cropped[:,x1:x2+1,y1:y2+1]\n",
    "                    crop_path = self.get_filt_string(folder,lay_info['name'],filtr['id'])\n",
    "                    file_name = path.split('/')[-1].lower()\n",
    "                    file_path = os.path.join(crop_path,file_name)\n",
    "                    ToPILImage()(cropped).save(file_path) \n",
    "            \n",
    "    def compute_filter_actmax(self,layer_indx,indexes = None):\n",
    "        \"\"\"\n",
    "        compute  and save the filter maximal activation as an image. Compute it only for filters for which\n",
    "        it has not been computed yet: you need to delete the existing image if you wish for a refresh.\n",
    "        \"\"\"\n",
    "        lay_info = self.model_info[layer_indx]\n",
    "        if indexes is None:\n",
    "            indexes = range(lay_info[\"lay\"].out_channels)\n",
    "        layer_name = lay_info[\"name\"]\n",
    "        pre_existing = []\n",
    "        for filt in lay_info[\"filters\"]:\n",
    "            name = \"{}_{}_max_activ.jpg\".format(lay_info['name'],filt['id'])\n",
    "            filt_path = self.get_filt_string(\"max_activ\",lay_info[\"name\"],filt[\"id\"])\n",
    "            filt_path = os.path.join(filt_path,name)\n",
    "            try:\n",
    "                f = open(filt_path)\n",
    "                filt[\"actmax_im\"] = filt_path\n",
    "                pre_existing.append(filt[\"id\"])\n",
    "                f.close()\n",
    "            except FileNotFoundError:\n",
    "                pass\n",
    "\n",
    "        indexes = [i for i in indexes if i not in pre_existing]\n",
    "\n",
    "        for filt_indx in indexes:\n",
    "            filt = lay_info['filters'][filt_indx]\n",
    "            visualizer = CNNLayerVisualization(model.features, \n",
    "                                               selected_layer=int(lay_info['id']), \n",
    "                                               selected_filter=filt_indx)\n",
    "            act_max_img = visualizer.visualise_layer_with_hooks()\n",
    "            filt_path = self.get_filt_string(\"max_activ\",lay_info['name'],filt['id'])\n",
    "            name = \"{}_{}_max_activ.jpg\".format(lay_info['name'],filt['id'])\n",
    "            filt_path = os.path.join(filt_path,name)\n",
    "            #save the image\n",
    "            ToPILImage()(act_max_img).save(filt_path)\n",
    "            filt[\"actmax_im\"] = filt_path\n",
    "        print(\"Actmax done!\")\n",
    "        \n",
    "    def compute_grads(self,verbose = False,compute_avg = True,compute_max = True):\n",
    "        \"\"\"\n",
    "        compute the gradients for the fav images of all filters of all layers for the model_info\n",
    "        Args:\n",
    "            gbp (GuidedBackprop): fitted on the model\n",
    "            model_info (dic): as described above\n",
    "            origin_path (str): path where to store the folders containing the gradient images\n",
    "        \"\"\"\n",
    "        gbp = GuidedBackprop(self.model)\n",
    "        for i,lay_info in enumerate(self.model_info):\n",
    "            if (i > self.N_LAYERS and self.SINGLE_LAYER):\n",
    "                break\n",
    "            if (isinstance(lay_info['lay'],nn.Conv2d)):\n",
    "                for j,filt in enumerate(lay_info['filters']):\n",
    "                    clear_output(wait=True)\n",
    "                    print(\"Grads Progression:layer{}/{} {}%\".format(i,len(self.model_info),j/len(lay_info['filters'])*100))\n",
    "                    if compute_avg:\n",
    "                        path = self.get_filt_string(\"avg_grads\",lay_info['name'],filt[\"id\"])\n",
    "                        self.compute_grads_filt(gbp,filt,path,lay_info['id'],\"fav_imgs\")\n",
    "                    if compute_max:\n",
    "                        path = self.get_filt_string(\"max_grads\",lay_info['name'],filt[\"id\"])\n",
    "                        self.compute_grads_filt(gbp,filt,path,lay_info['id'],\"max_imgs\")\n",
    "                        self.save_cropped(grad= True)\n",
    "        self.save_to_json()\n",
    "\n",
    "    def compute_grads_filt(self,gbp,filt,path,lay_id,img_type):\n",
    "        \"\"\"\n",
    "        compute the gradients wrt to the favourite images of a filter filt.\n",
    "        Args:\n",
    "            gbp (GuidedBackprop): fitted on the model\n",
    "            filt (dic): filter from a layer\n",
    "            path (str): path to the folder where to store the gradient images\n",
    "            img_type (str): either \"fav_imgs\" or \"max_imgs\"\n",
    "        \"\"\"\n",
    "        grad_strindx = \"grad_path_avg\" if img_type == \"fav_imgs\" else \"grad_path_max\"\n",
    "\n",
    "        for i,img_path in enumerate(filt[img_type]):\n",
    "            if (img_path == self.NUMB_PATH):\n",
    "                continue   \n",
    "\n",
    "            #name of the image\n",
    "            img_name = self.extract_name(img_path,\"_grad.jpg\")\n",
    "            #joined path and imagename\n",
    "            grad_path = os.path.join(path,img_name)\n",
    "\n",
    "            try:\n",
    "                f = open(grad_path)\n",
    "                filt[grad_strindx][i] = grad_path\n",
    "                f.close()\n",
    "                continue\n",
    "            except FileNotFoundError:\n",
    "                pass\n",
    "\n",
    "            image = Image.open(img_path)\n",
    "            image = self.preprocess(image).unsqueeze(0)\n",
    "            image.requires_grad = True\n",
    "            class_name = img_path.split(\"/\")[-1].split(\"_\")[0]\n",
    "            gradient = gbp.generate_gradients(image,self.CLASS2INDX[class_name],lay_id,filt['id'])\n",
    "            #normalization of the gradient\n",
    "            gradient = gradient - gradient.min()\n",
    "            gradient /= gradient.max()\n",
    "            im = ToPILImage()(gradient[0])\n",
    "            im.save(grad_path)\n",
    "            filt[grad_strindx][i] = grad_path\n",
    "        \n",
    "\n",
    "model = models.vgg16(pretrained=True)\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.CenterCrop(224), \n",
    "    transforms.ToTensor()\n",
    "    ,transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ML] *",
   "language": "python",
   "name": "conda-env-ML-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
