{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "#%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from IPython.core.debugger import set_trace\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor,ToPILImage\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from torchvision.utils import save_image\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from flashtorch.activmax import GradientAscent\n",
    "import flashtorch\n",
    "from flashtorch.activmax import GradientAscent\n",
    "from flashtorch.utils import standardize_and_clip,format_for_plotting\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.nn as nn\n",
    "from os.path import join\n",
    "from pathlib import Path\n",
    "from shutil import copyfile\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "from ImageFolderWithPaths import ImageFolderWithPaths\n",
    "\n",
    "from Projector import Projector\n",
    "\n",
    "import sys\n",
    "import os\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "sys.path.insert(1, '../lib/pytorch-cnn-visualizations/src/')\n",
    "from cnn_layer_visualization import CNNLayerVisualization\n",
    "from layer_activation_with_guided_backprop import GuidedBackprop\n",
    "from misc_functions import save_gradient_images\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from misc_funcs import create_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lurk():\n",
    "    def __init__(self,model,preprocess,save_comp_img_path,save_json_pathname,load_path=None):\n",
    "        self.model = model\n",
    "        self.preprocess = preprocess\n",
    "        # allow to run reduced computations\n",
    "        self.SINGLE_LAYER = True\n",
    "        #number of layers we compute shit for\n",
    "        self.N_LAYERS = 0\n",
    "        #number of filters we compute images for\n",
    "        self.N_REDUCE = 22\n",
    "        #path to the numb image\n",
    "        self.NUMB_PATH = \"../data/tinyimagenet/numb.png\"\n",
    "        # how many top pictures we keep\n",
    "        self.TOP_AVG_SIGN = 4\n",
    "        #number of favourites images per filter\n",
    "        self.N_FAV = 4\n",
    "        # number of max spikes images per filter\n",
    "        self.N_FAV_MAX = 3\n",
    "        #where to save/load the saved models\n",
    "        self.ORIGIN_PATH = save_comp_img_path\n",
    "        #where to access the data\n",
    "        self.DATA_PATH = \"../data/\"\n",
    "        #where to access the tinyimagenet dataset\n",
    "        self.TINY_PATH = os.path.join(self.DATA_PATH,\"tinyimagenet/\")\n",
    "        #which folder to get the data from\n",
    "        self.IMGS_PATH = os.path.join(self.DATA_PATH,\"exsmallimagenet\")\n",
    "        #where to save the json\n",
    "        self.SAVE_PATHNAME_JSON = save_json_pathname\n",
    "        \n",
    "        if load_path is not None:\n",
    "            self.model_info = self.load_from_json(load_path)\n",
    "        else:\n",
    "            self.model_info = self.build_model()\n",
    "        create_folders(self.ORIGIN_PATH,[\"avg_grads\",\"max_grads\",\"cropped\",\"cropped_grad\",\"max_activ\"],self.model_info)\n",
    "        \n",
    "        self.my_dataset = ImageFolderWithPaths(self.IMGS_PATH,transform=self.preprocess)\n",
    "        self.CLASS2INDX = self.my_dataset.class_to_idx\n",
    "        self.data_loader = torch.utils.data.DataLoader(self.my_dataset, batch_size=1, shuffle=True)\n",
    "    \n",
    "    def save_to_json(self):\n",
    "        model_info2 = deepcopy(self.model_info)\n",
    "        for lay_info in model_info2:\n",
    "            if (isinstance(lay_info['lay'],nn.Conv2d)):\n",
    "                del lay_info['deproj']\n",
    "            del lay_info['lay']\n",
    "        with open(self.SAVE_PATHNAME_JSON, 'w') as fout:\n",
    "            json.dump(model_info2, fout, indent = 2)\n",
    "        print(\"saving done!\") \n",
    "        \n",
    "    def load_from_json(self,load_path):\n",
    "        #TODO: ensure that the imgpaths in the loaded file do exist\n",
    "        layers = []\n",
    "        with open(load_path, 'r') as fin:\n",
    "            model_info = json.load(fin)\n",
    "        for lay_info,layer in zip(model_info,self.model.features):\n",
    "            lay_info['lay'] = layer\n",
    "            if (isinstance(layer,(nn.Conv2d,nn.MaxPool2d))):\n",
    "                layers.append(layer)\n",
    "            if (isinstance(layer,nn.Conv2d)):\n",
    "                lay_info['deproj'] = Projector(deepcopy(layers),224)\n",
    "        print(\"Loading done!\") \n",
    "        return model_info\n",
    "    \n",
    "    def build_model(self):\n",
    "        model_info = []\n",
    "        layers = []\n",
    "        #construct the data structure\n",
    "        for layer in list(self.model.features.named_children()):\n",
    "            lay_info = {'id':layer[0],\n",
    "                      'lay':layer[1],\n",
    "                      'name':str(layer[1]).split('(')[0] + \"_\" + str(layer[0]) \n",
    "                    }\n",
    "            if (isinstance(layer[1],(nn.Conv2d,nn.MaxPool2d))):\n",
    "                layers.append(layer[1])\n",
    "            if (isinstance(lay_info['lay'],nn.Conv2d)):     \n",
    "                n_input = lay_info['lay'].in_channels\n",
    "                n_output = lay_info['lay'].out_channels\n",
    "                lay_info['n_input'] = n_input\n",
    "                lay_info['n_output'] = n_output\n",
    "                lay_info['deproj'] = Projector(deepcopy(layers),224)\n",
    "                lay_info[\"filters\"] = []\n",
    "                for i in range(n_output):\n",
    "                    lay_info[\"filters\"].append({\n",
    "                        \"id\":i,\n",
    "                        \"spikes\":[0 for i in range(self.N_FAV)],\n",
    "                        \"fav_imgs\":[self.NUMB_PATH for i in range(self.N_FAV)],\n",
    "                        \"grad_path_avg\":[self.NUMB_PATH for i in range(self.N_FAV)],\n",
    "                        \"max_spikes\":[0 for i in range(self.N_FAV_MAX)],\n",
    "                        \"max_slices\":[[[0,0],[0,0]]for i in range(self.N_FAV_MAX)],\n",
    "                        \"max_imgs\":[self.NUMB_PATH for i in range(self.N_FAV_MAX)],\n",
    "                        \"grad_path_max\":[self.NUMB_PATH for i in range(self.N_FAV_MAX)],\n",
    "                        \"actmax_im\":self.NUMB_PATH\n",
    "                    })\n",
    "            elif (type(lay_info['lay']) == nn.Linear):\n",
    "                    n_input = lay_info['lay'].in_features\n",
    "                    n_output = lay_info['lay'].out_features\n",
    "                    lay_info['n_output'] = n_output\n",
    "                    #lay_info[\"filters\"] = [empty_filter.copy() for i in range(n_output)]\n",
    "            model_info.append(lay_info)\n",
    "        return model_info\n",
    "    \n",
    "    def get_filt_string(self,dir_type,layer_name,filter_id):\n",
    "        \"\"\"\n",
    "        return the path to the appropriate folder\n",
    "        \"\"\"\n",
    "        return os.path.join(self.ORIGIN_PATH,dir_type,layer_name,str(filter_id))\n",
    "    \n",
    "    def extract_name(self,img_path,ext='.jpg'):\n",
    "        \"\"\"\n",
    "        extract the name of the imgpath and add the extension\n",
    "        \"\"\"\n",
    "        jpg_name = img_path.split(\"/\")[-1]\n",
    "        img_name = jpg_name.split(\".\")[0] + ext\n",
    "        return img_name\n",
    "    #Watch out which path you give for the IMGS_PATH\n",
    "\n",
    "    def sort_filters_spikes(self):\n",
    "        \"\"\"\n",
    "        sorts the spikes and respective paths of the filters inplace\n",
    "        \"\"\"\n",
    "        for lay_info in self.model_info:\n",
    "            if (isinstance(lay_info['lay'],nn.Conv2d)):\n",
    "                for filtr in lay_info['filters']:\n",
    "                    max_indx = np.argsort(filtr[\"max_spikes\"])[::-1]\n",
    "                    filtr[\"max_spikes\"] = np.array(filtr[\"max_spikes\"])[max_indx].tolist()\n",
    "                    filtr[\"max_imgs\"] = np.array(filtr[\"max_imgs\"])[max_indx].tolist()\n",
    "                    filtr[\"max_slices\"] = np.array(filtr[\"max_slices\"])[max_indx].tolist()\n",
    "\n",
    "                    avg_indx = np.argsort(filtr[\"spikes\"])[::-1]\n",
    "                    filtr[\"spikes\"] = np.array(filtr[\"spikes\"])[avg_indx].tolist()\n",
    "                    filtr[\"fav_imgs\"] = np.array(filtr[\"fav_imgs\"])[avg_indx].tolist()\n",
    "\n",
    "    def update_favims_model(self,verbose = False):\n",
    "        \"\"\"\n",
    "        update all the layers of the model_info such that each filter of each layer knows what are\n",
    "        its favourite images (write it down in json)\n",
    "        \"\"\"\n",
    "        for j,(datas,labels,paths) in enumerate(self.data_loader):\n",
    "            print(\"Progression update favimgs:{:.2f} %\".format(j/len(self.data_loader) * 100))\n",
    "            for i,lay_info in enumerate(self.model_info):\n",
    "                clear_output(wait=True)\n",
    "                if verbose:\n",
    "                    print(\"AvgMax update:{}/{}:{:.2f} %..\".format(i,len(self.model_info),100*j/ len(data_loader)))\n",
    "\n",
    "                #datas: Batchsize x Numberfilter x Nout x Nout\n",
    "                datas = lay_info['lay'](datas)\n",
    "                if (not isinstance(lay_info['lay'],nn.Conv2d) ):\n",
    "                    continue\n",
    "                if (i >self.N_LAYERS and self.SINGLE_LAYER):\n",
    "                    break\n",
    "\n",
    "                batch_size = datas.size(0)\n",
    "                filter_nb = datas.size(1)\n",
    "                width = datas.size(3)\n",
    "\n",
    "                #set_trace()\n",
    "                #spikes: Batchsize x Filternumber\n",
    "                max_spikes,max_pos = datas.view([batch_size,filter_nb,-1]).max(dim = 2)\n",
    "                max_rows = max_pos / width\n",
    "                max_cols = max_pos % width\n",
    "\n",
    "                avg_spikes = datas.view([batch_size,filter_nb,-1]).mean(dim = 2)\n",
    "\n",
    "                self.update_filters_maxim(lay_info,max_spikes,paths,max_rows,max_cols)\n",
    "                self.update_filters_favim(lay_info,avg_spikes,paths,\"avg\")\n",
    "                #save the whole model\n",
    "        self.sort_filters_spikes()\n",
    "        self.save_cropped()\n",
    "        self.save_to_json()\n",
    "\n",
    "    def update_filters_maxim(self,lay_info,batch_spikes,paths,max_rows,max_cols):\n",
    "        #as many spikes in batch_spikes as there are samples in batch\n",
    "        for spikes,path,rows,cols in zip(batch_spikes,paths,max_rows,max_cols):\n",
    "            #at this stage there are as many spike in spikes as there are filters\n",
    "            for k,(filt,spike,row,col) in enumerate(zip(lay_info[\"filters\"],spikes.detach().numpy(),rows,cols)):\n",
    "                #compute the minimum spike for the filter\n",
    "                min_indx = np.argmin(filt[\"max_spikes\"])\n",
    "                min_spike = min(filt[\"max_spikes\"])\n",
    "\n",
    "                if (spike > min_spike and not (path in filt[\"max_imgs\"])):\n",
    "\n",
    "                    ((x1,x2),(y1,y2)) = lay_info[\"deproj\"].chain(((row.item(),row.item()),(col.item(),col.item())))\n",
    "                    assert(isinstance(x1,int) and isinstance(x2,int) and isinstance(y1,int) and isinstance(y2,int))\n",
    "                    filt[\"max_slices\"][min_indx] = ((x1,x2),(y1,y2))\n",
    "                    filt[\"max_imgs\"][min_indx] = path\n",
    "                    filt[\"max_spikes\"][min_indx] = float(spike)\n",
    "\n",
    "    def update_filters_favim(self,lay_info,batch_spikes,paths,func_type):\n",
    "        #as many spikes in batch_spikes as there are samples in batch\n",
    "        for spikes,path in zip(batch_spikes,paths):\n",
    "            #at this stage there are as many spike in spikes as there are filters\n",
    "            for k,(filt,spike) in enumerate(zip(lay_info[\"filters\"],spikes.detach().numpy())):\n",
    "                #compute the minimum spike for the filter\n",
    "                min_indx = np.argmin(filt[\"spikes\"])\n",
    "                min_spike = min(filt[\"spikes\"])\n",
    "                if (spike > min_spike and not (path in filt[\"fav_imgs\"])):\n",
    "                    filt[\"fav_imgs\"][min_indx] = path\n",
    "                    filt[\"spikes\"][min_indx] = float(spike)\n",
    "\n",
    "    def save_cropped(self,grad = False,verbose=False):\n",
    "        \"\"\"\n",
    "        iterate on the model_info to save a cropped version of the images\n",
    "        Args:\n",
    "            grad(Bool): whether to save the gradients versions\n",
    "        \"\"\"\n",
    "        if grad:\n",
    "            filtrlist = \"grad_path_max\" \n",
    "            folder = \"cropped_grad\"\n",
    "        else:\n",
    "            filtrlist = \"max_imgs\"\n",
    "            folder = \"cropped\"\n",
    "\n",
    "        for i,lay_info in enumerate(self.model_info):\n",
    "            clear_output(wait=True)\n",
    "            if verbose:\n",
    "                print(\"Progression:{} %\".format(i/len(model_info)*100))\n",
    "            if (not isinstance(lay_info['lay'],nn.Conv2d)):\n",
    "                continue\n",
    "            for filtr in lay_info['filters']:\n",
    "                for path,slices in zip(filtr[filtrlist],filtr['max_slices']):\n",
    "                    if (path == self.NUMB_PATH):\n",
    "                        continue\n",
    "                    cropped = ToTensor()(Image.open(path))\n",
    "                    ((x1,x2),(y1,y2)) = slices\n",
    "                    cropped = cropped[:,x1:x2+1,y1:y2+1]\n",
    "                    crop_path = self.get_filt_string(folder,lay_info['name'],filtr['id'])\n",
    "                    file_name = path.split('/')[-1].lower()\n",
    "                    file_path = os.path.join(crop_path,file_name)\n",
    "                    ToPILImage()(cropped).save(file_path) \n",
    "            \n",
    "    def compute_filter_actmax(self,layer_indx,indexes = None):\n",
    "        \"\"\"\n",
    "        compute  and save the filter maximal activation as an image. Compute it only for filters for which\n",
    "        it has not been computed yet: delte the existing image for a refresh.\n",
    "        \"\"\"\n",
    "        lay_info = self.model_info[layer_indx]\n",
    "        if indexes is None:\n",
    "            indexes = range(lay_info[\"lay\"].out_channels)\n",
    "        layer_name = lay_info[\"name\"]\n",
    "        pre_existing = []\n",
    "        for filt in lay_info[\"filters\"]:\n",
    "            name = \"{}_{}_max_activ.jpg\".format(lay_info['name'],filt['id'])\n",
    "            filt_path = self.get_filt_string(\"max_activ\",lay_info[\"name\"],filt[\"id\"])\n",
    "            filt_path = os.path.join(filt_path,name)\n",
    "            try:\n",
    "                f = open(filt_path)\n",
    "                filt[\"actmax_im\"] = filt_path\n",
    "                pre_existing.append(filt[\"id\"])\n",
    "                f.close()\n",
    "            except FileNotFoundError:\n",
    "                pass\n",
    "\n",
    "        indexes = [i for i in indexes if i not in pre_existing]\n",
    "\n",
    "        for filt_indx in indexes:\n",
    "            filt = lay_info['filters'][filt_indx]\n",
    "            visualizer = CNNLayerVisualization(model.features, \n",
    "                                               selected_layer=int(lay_info['id']), \n",
    "                                               selected_filter=filt_indx)\n",
    "            act_max_img = visualizer.visualise_layer_with_hooks()\n",
    "            filt_path = self.get_filt_string(\"max_activ\",lay_info['name'],filt['id'])\n",
    "            name = \"{}_{}_max_activ.jpg\".format(lay_info['name'],filt['id'])\n",
    "            filt_path = os.path.join(filt_path,name)\n",
    "            #save the image\n",
    "            ToPILImage()(act_max_img).save(filt_path)\n",
    "            filt[\"actmax_im\"] = filt_path\n",
    "        print(\"Actmax done!\")\n",
    "        \n",
    "    def compute_grads(self,verbose = False,compute_avg = True,compute_max = True):\n",
    "        \"\"\"\n",
    "        compute the gradients for the fav images of all filters of all layers for the model_info\n",
    "        Args:\n",
    "            gbp (GuidedBackprop): fitted on the model\n",
    "            model_info (dic): as described above\n",
    "            origin_path (str): path where to store the folders containing the gradient images\n",
    "        \"\"\"\n",
    "        gbp = GuidedBackprop(self.model)\n",
    "        for i,lay_info in enumerate(self.model_info):\n",
    "            if (i > self.N_LAYERS and self.SINGLE_LAYER):\n",
    "                break\n",
    "            if (isinstance(lay_info['lay'],nn.Conv2d)):\n",
    "                for j,filt in enumerate(lay_info['filters']):\n",
    "                    clear_output(wait=True)\n",
    "                    print(\"Grads Progression:layer{}/{} {}%\".format(i,len(self.model_info),j/len(lay_info['filters'])*100))\n",
    "                    if compute_avg:\n",
    "                        path = self.get_filt_string(\"avg_grads\",lay_info['name'],filt[\"id\"])\n",
    "                        self.compute_grads_filt(gbp,filt,path,lay_info['id'],\"fav_imgs\")\n",
    "                    if compute_max:\n",
    "                        path = self.get_filt_string(\"max_grads\",lay_info['name'],filt[\"id\"])\n",
    "                        self.compute_grads_filt(gbp,filt,path,lay_info['id'],\"max_imgs\")\n",
    "                        self.save_cropped(grad= True)\n",
    "        self.save_to_json()\n",
    "\n",
    "    def compute_grads_filt(self,gbp,filt,path,lay_id,img_type):\n",
    "        \"\"\"\n",
    "        compute the gradients wrt to the favourite images of a filter filt.\n",
    "        Args:\n",
    "            gbp (GuidedBackprop): fitted on the model\n",
    "            filt (dic): filter from a layer\n",
    "            path (str): path to the folder where to store the gradient images\n",
    "            img_type (str): either \"fav_imgs\" or \"max_imgs\"\n",
    "        \"\"\"\n",
    "        grad_strindx = \"grad_path_avg\" if img_type == \"fav_imgs\" else \"grad_path_max\"\n",
    "\n",
    "        for i,img_path in enumerate(filt[img_type]):\n",
    "            if (img_path == self.NUMB_PATH):\n",
    "                continue   \n",
    "\n",
    "            #name of the image\n",
    "            img_name = self.extract_name(img_path,\"_grad.jpg\")\n",
    "            #joined path and imagename\n",
    "            grad_path = os.path.join(path,img_name)\n",
    "\n",
    "            try:\n",
    "                f = open(grad_path)\n",
    "                filt[grad_strindx][i] = grad_path\n",
    "                f.close()\n",
    "                continue\n",
    "            except FileNotFoundError:\n",
    "                pass\n",
    "\n",
    "            image = Image.open(img_path)\n",
    "            image = self.preprocess(image).unsqueeze(0)\n",
    "            image.requires_grad = True\n",
    "            class_name = img_path.split(\"/\")[-1].split(\"_\")[0]\n",
    "            gradient = gbp.generate_gradients(image,self.CLASS2INDX[class_name],lay_id,filt['id'])\n",
    "            #normalization of the gradient\n",
    "            gradient = gradient - gradient.min()\n",
    "            gradient /= gradient.max()\n",
    "            im = ToPILImage()(gradient[0])\n",
    "            im.save(grad_path)\n",
    "            filt[grad_strindx][i] = grad_path\n",
    "        \n",
    "\n",
    "model = models.vgg16(pretrained=True)\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.CenterCrop(224), \n",
    "    transforms.ToTensor()\n",
    "    ,transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving done!\n"
     ]
    }
   ],
   "source": [
    "lurker = Lurk(model,preprocess,save_comp_img_path='../results/03_02_20_1200/'\n",
    "                              ,save_json_pathname='../saved_model/03_02_20_1200.json')\n",
    "lurker.update_favims_model()\n",
    "lurker.compute_filter_actmax(0,[2,3])\n",
    "lurker.compute_filter_actmax(2,[3,4])\n",
    "lurker.compute_grads()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
