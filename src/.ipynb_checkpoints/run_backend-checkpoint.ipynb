{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1,\"../models/PyTorch_CIFAR10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cifar10_models import vgg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Torchlurk import Lurk\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from misc_funcs import clean_bw_imgs,sample_imagenet,plot_hist,crop_imgs\n",
    "import jdc\n",
    "from matplotlib.pyplot import imshow\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision.transforms import ToTensor,ToPILImage\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.utils import save_image\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from collections import OrderedDict\n",
    "import pathlib\n",
    "import dill\n",
    "\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "\n",
    "from ImageFolderWithPaths import ImageFolderWithPaths\n",
    "from Projector import Projector\n",
    "\n",
    "#libraries\n",
    "sys.path.insert(1, '../lib/pytorch-cnn-visualizations/src/')\n",
    "from cnn_layer_visualization import CNNLayerVisualization\n",
    "from layer_activation_with_guided_backprop import GuidedBackprop\n",
    "from misc_functions import save_gradient_images\n",
    "from misc_funcs import create_folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cifar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_cif = transforms.Compose([transforms.RandomCrop(32, padding=4),\n",
    "                                              transforms.RandomHorizontalFlip(),\n",
    "                                              transforms.ToTensor(),\n",
    "                                              transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "#preprocess_cif = transforms.Compose([transforms.RandomCrop(32, padding=4)\n",
    "model_cif = vgg.vgg11_bn(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (6): ReLU(inplace=True)\n",
       "  (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (10): ReLU(inplace=True)\n",
       "  (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (13): ReLU(inplace=True)\n",
       "  (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (17): ReLU(inplace=True)\n",
       "  (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (20): ReLU(inplace=True)\n",
       "  (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (24): ReLU(inplace=True)\n",
       "  (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (27): ReLU(inplace=True)\n",
       "  (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar_dataset = torchvision.datasets.CIFAR10(\"../data/CIFAR10\", train=True, transform=None, target_transform=None, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar_dataset = torchvision.datasets.CIFAR10(\"../data/CIFAR10\", train=True, transform=None, target_transform=None, download=True)\n",
    "data_loader = torch.utils.data.DataLoader(cifar_dataset,\n",
    "                                          batch_size=1,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progression:20.53 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-247-8af87c623a13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlab2title\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcifar_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_to_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage_lab\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcifar_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Progression:{:.2f} %\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcifar_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mclass_title\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlab2title\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_lab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mclear_output\u001b[0;34m(wait)\u001b[0m\n\u001b[1;32m   1425\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteractiveshell\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInteractiveShell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1426\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mInteractiveShell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1427\u001b[0;31m         \u001b[0mInteractiveShell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay_pub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1428\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\033[2K\\r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/ipykernel/zmqshell.py\u001b[0m in \u001b[0;36mclear_output\u001b[0;34m(self, wait)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[1;32m    156\u001b[0m         \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flush_streams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         self.session.send(\n\u001b[1;32m    159\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu'clear_output'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/ipykernel/zmqshell.py\u001b[0m in \u001b[0;36m_flush_streams\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_flush_streams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;34m\"\"\"flush IO Streams prior to display\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0;31m# request flush on the background thread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flush\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m             \u001b[0;31m# wait for flush to actually get through, if we can.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             \u001b[0;31m# waiting across threads during import can cause deadlocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;31m# wake event thread (message content is ignored)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[1;32m    398\u001b[0m                                  copy_threshold=self.copy_threshold)\n\u001b[1;32m    399\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSocket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_parts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def convert_to_jpg_dirs(target_dir=\"../data/CIFAR10imgs\",cifar_dataset):\n",
    "    cifar_dir = Path(target_dir)\n",
    "    cifar_dir.mkdir(parents=False,exist_ok=True)\n",
    "\n",
    "    lab2title = {j:i for i,j in cifar_dataset.class_to_idx.items()}\n",
    "    for i,image_lab in enumerate(cifar_dataset):\n",
    "        clear_output(wait=True)\n",
    "        print(\"Progression:{:.2f} %\".format(i/len(cifar_dataset)*100))\n",
    "        class_title = lab2title[image_lab[1]]\n",
    "        class_dir  = cifar_dir.joinpath(class_title)\n",
    "        class_dir.mkdir(parents=False,exist_ok=True)\n",
    "        smple_path = class_dir.joinpath(class_dir.stem + \"_\" + str(i)+\".jpg\")\n",
    "        image_lab[0].save(str(smple_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_cifar = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "dataset_cifar = ImageFolderWithPaths(\"../data/CIFAR10imgs\",transform=preprocess_cifar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a,b,c in dataset_cifar:\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.CenterCrop(224), \n",
    "    transforms.ToTensor()\n",
    "])\n",
    "im = Image.open(\"../data/imagenet-mini/train/n01440764/n01440764_12063.JPEG\")\n",
    "k = preprocess(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cifar_train_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-207-1483d180972f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcifar_train_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'cifar_train_set' is not defined"
     ]
    }
   ],
   "source": [
    "train_input = torch.from_numpy(cifar_train_set.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImageNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At that stage, Download the tinyimagenet dataset on [this link](https://www.kaggle.com/ifigotin/imagenetmini-1000#n01440764_10470.JPEG) and place it in the directory data (s.t the path looks like `data/tinyimagenet/rest_of_path`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the dataset is downloaded, we need to get rid of a few bw images: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progression:100.00%\n",
      "Cropped terminated successfully!\n"
     ]
    }
   ],
   "source": [
    "crop_imgs(\"../data/imagenet-mini/train/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progression:100.00%\n",
      "BW files found:\n",
      "../data/imagenet-mini/train/n03920288/n03920288_3315.JPEG\n",
      "../data/imagenet-mini/train/n03920288/n03920288_3629.JPEG\n",
      "../data/imagenet-mini/train/n03942813/n03942813_1800.JPEG\n",
      "../data/imagenet-mini/train/n02791270/n02791270_16505.JPEG\n",
      "../data/imagenet-mini/train/n02791270/n02791270_23048.JPEG\n",
      "../data/imagenet-mini/train/n02950826/n02950826_11905.JPEG\n",
      "../data/imagenet-mini/train/n02950826/n02950826_13787.JPEG\n",
      "../data/imagenet-mini/train/n02894605/n02894605_26115.JPEG\n",
      "../data/imagenet-mini/train/n03782006/n03782006_37777.JPEG\n",
      "../data/imagenet-mini/train/n04041544/n04041544_1401.JPEG\n",
      "../data/imagenet-mini/train/n02403003/n02403003_656.JPEG\n",
      "../data/imagenet-mini/train/n02109047/n02109047_1579.JPEG\n",
      "../data/imagenet-mini/train/n02109047/n02109047_6125.JPEG\n",
      "../data/imagenet-mini/train/n02787622/n02787622_5870.JPEG\n",
      "../data/imagenet-mini/train/n02787622/n02787622_9908.JPEG\n",
      "../data/imagenet-mini/train/n02102480/n02102480_6584.JPEG\n",
      "../data/imagenet-mini/train/n03063689/n03063689_5020.JPEG\n",
      "../data/imagenet-mini/train/n03063689/n03063689_4678.JPEG\n",
      "../data/imagenet-mini/train/n03063689/n03063689_14711.JPEG\n",
      "../data/imagenet-mini/train/n03063689/n03063689_15384.JPEG\n",
      "../data/imagenet-mini/train/n02110958/n02110958_15441.JPEG\n",
      "../data/imagenet-mini/train/n02124075/n02124075_12703.JPEG\n",
      "../data/imagenet-mini/train/n03271574/n03271574_14752.JPEG\n",
      "../data/imagenet-mini/train/n03271574/n03271574_9789.JPEG\n",
      "../data/imagenet-mini/train/n04067472/n04067472_17256.JPEG\n",
      "../data/imagenet-mini/train/n04067472/n04067472_2454.JPEG\n",
      "../data/imagenet-mini/train/n04099969/n04099969_2722.JPEG\n",
      "../data/imagenet-mini/train/n04099969/n04099969_330.JPEG\n",
      "../data/imagenet-mini/train/n04099969/n04099969_10503.JPEG\n",
      "../data/imagenet-mini/train/n04099969/n04099969_7966.JPEG\n",
      "../data/imagenet-mini/train/n02097298/n02097298_12964.JPEG\n",
      "../data/imagenet-mini/train/n03532672/n03532672_38571.JPEG\n",
      "../data/imagenet-mini/train/n03532672/n03532672_48344.JPEG\n",
      "../data/imagenet-mini/train/n03532672/n03532672_28536.JPEG\n",
      "../data/imagenet-mini/train/n01440764/n01440764_15560.JPEG\n",
      "../data/imagenet-mini/train/n01704323/n01704323_1431.JPEG\n",
      "../data/imagenet-mini/train/n01704323/n01704323_7030.JPEG\n",
      "../data/imagenet-mini/train/n01704323/n01704323_8354.JPEG\n",
      "../data/imagenet-mini/train/n01704323/n01704323_1968.JPEG\n",
      "../data/imagenet-mini/train/n03141823/n03141823_3933.JPEG\n",
      "../data/imagenet-mini/train/n02443484/n02443484_1796.JPEG\n",
      "../data/imagenet-mini/train/n02096585/n02096585_10795.JPEG\n",
      "../data/imagenet-mini/train/n02096585/n02096585_6466.JPEG\n",
      "../data/imagenet-mini/train/n02096585/n02096585_10516.JPEG\n",
      "../data/imagenet-mini/train/n02974003/n02974003_9231.JPEG\n",
      "../data/imagenet-mini/train/n03347037/n03347037_17993.JPEG\n",
      "../data/imagenet-mini/train/n02236044/n02236044_4695.JPEG\n",
      "../data/imagenet-mini/train/n02113712/n02113712_4748.JPEG\n",
      "../data/imagenet-mini/train/n02500267/n02500267_7635.JPEG\n",
      "../data/imagenet-mini/train/n03874293/n03874293_12186.JPEG\n",
      "../data/imagenet-mini/train/n03133878/n03133878_3882.JPEG\n",
      "../data/imagenet-mini/train/n03133878/n03133878_1222.JPEG\n",
      "../data/imagenet-mini/train/n03786901/n03786901_10914.JPEG\n",
      "../data/imagenet-mini/train/n04040759/n04040759_38253.JPEG\n",
      "../data/imagenet-mini/train/n04040759/n04040759_12579.JPEG\n",
      "../data/imagenet-mini/train/n03250847/n03250847_13526.JPEG\n",
      "../data/imagenet-mini/train/n03250847/n03250847_16601.JPEG\n",
      "../data/imagenet-mini/train/n03498962/n03498962_9124.JPEG\n",
      "../data/imagenet-mini/train/n03759954/n03759954_19880.JPEG\n",
      "../data/imagenet-mini/train/n02676566/n02676566_9407.JPEG\n",
      "../data/imagenet-mini/train/n03697007/n03697007_171.JPEG\n",
      "../data/imagenet-mini/train/n03388183/n03388183_13836.JPEG\n",
      "../data/imagenet-mini/train/n03950228/n03950228_11028.JPEG\n",
      "../data/imagenet-mini/train/n03950228/n03950228_11161.JPEG\n",
      "../data/imagenet-mini/train/n15075141/n15075141_10244.JPEG\n",
      "../data/imagenet-mini/train/n15075141/n15075141_3267.JPEG\n",
      "../data/imagenet-mini/train/n04366367/n04366367_3874.JPEG\n",
      "../data/imagenet-mini/train/n04366367/n04366367_11770.JPEG\n",
      "../data/imagenet-mini/train/n04366367/n04366367_34620.JPEG\n",
      "../data/imagenet-mini/train/n03832673/n03832673_220.JPEG\n",
      "../data/imagenet-mini/train/n03832673/n03832673_19442.JPEG\n",
      "../data/imagenet-mini/train/n03832673/n03832673_5334.JPEG\n",
      "../data/imagenet-mini/train/n03642806/n03642806_9700.JPEG\n",
      "../data/imagenet-mini/train/n03642806/n03642806_3515.JPEG\n",
      "../data/imagenet-mini/train/n02814860/n02814860_17864.JPEG\n",
      "../data/imagenet-mini/train/n02988304/n02988304_8210.JPEG\n",
      "../data/imagenet-mini/train/n02112137/n02112137_279.JPEG\n",
      "../data/imagenet-mini/train/n03887697/n03887697_4952.JPEG\n",
      "../data/imagenet-mini/train/n02965783/n02965783_4887.JPEG\n",
      "../data/imagenet-mini/train/n02823428/n02823428_3803.JPEG\n",
      "../data/imagenet-mini/train/n03255030/n03255030_11039.JPEG\n",
      "../data/imagenet-mini/train/n03255030/n03255030_8885.JPEG\n",
      "../data/imagenet-mini/train/n03255030/n03255030_9247.JPEG\n",
      "../data/imagenet-mini/train/n03255030/n03255030_11118.JPEG\n",
      "../data/imagenet-mini/train/n03933933/n03933933_6303.JPEG\n",
      "../data/imagenet-mini/train/n03933933/n03933933_24509.JPEG\n",
      "../data/imagenet-mini/train/n04428191/n04428191_43456.JPEG\n",
      "../data/imagenet-mini/train/n04428191/n04428191_2240.JPEG\n",
      "../data/imagenet-mini/train/n04428191/n04428191_6483.JPEG\n",
      "../data/imagenet-mini/train/n02091244/n02091244_8124.JPEG\n",
      "../data/imagenet-mini/train/n02808440/n02808440_55396.JPEG\n",
      "../data/imagenet-mini/train/n02808440/n02808440_47134.JPEG\n",
      "../data/imagenet-mini/train/n02966687/n02966687_3742.JPEG\n",
      "../data/imagenet-mini/train/n02091831/n02091831_3598.JPEG\n",
      "../data/imagenet-mini/train/n03976467/n03976467_3522.JPEG\n",
      "../data/imagenet-mini/train/n03976467/n03976467_16598.JPEG\n",
      "../data/imagenet-mini/train/n03976467/n03976467_20470.JPEG\n",
      "../data/imagenet-mini/train/n04347754/n04347754_32095.JPEG\n",
      "../data/imagenet-mini/train/n04347754/n04347754_3334.JPEG\n",
      "../data/imagenet-mini/train/n03404251/n03404251_9354.JPEG\n",
      "../data/imagenet-mini/train/n03733281/n03733281_23036.JPEG\n",
      "../data/imagenet-mini/train/n04074963/n04074963_19650.JPEG\n",
      "../data/imagenet-mini/train/n04074963/n04074963_6499.JPEG\n",
      "../data/imagenet-mini/train/n03916031/n03916031_41551.JPEG\n",
      "../data/imagenet-mini/train/n04392985/n04392985_2489.JPEG\n",
      "../data/imagenet-mini/train/n04392985/n04392985_4047.JPEG\n",
      "../data/imagenet-mini/train/n03998194/n03998194_6751.JPEG\n",
      "../data/imagenet-mini/train/n04515003/n04515003_32327.JPEG\n",
      "../data/imagenet-mini/train/n04515003/n04515003_10380.JPEG\n",
      "../data/imagenet-mini/train/n02071294/n02071294_6873.JPEG\n",
      "../data/imagenet-mini/train/n03794056/n03794056_13949.JPEG\n",
      "../data/imagenet-mini/train/n03794056/n03794056_10172.JPEG\n",
      "../data/imagenet-mini/train/n03794056/n03794056_10490.JPEG\n",
      "../data/imagenet-mini/train/n04507155/n04507155_14941.JPEG\n",
      "../data/imagenet-mini/train/n04090263/n04090263_15504.JPEG\n",
      "../data/imagenet-mini/train/n02002556/n02002556_5205.JPEG\n",
      "../data/imagenet-mini/train/n02088238/n02088238_1485.JPEG\n",
      "../data/imagenet-mini/train/n02092002/n02092002_12862.JPEG\n",
      "../data/imagenet-mini/train/n02883205/n02883205_60864.JPEG\n",
      "../data/imagenet-mini/train/n02883205/n02883205_2488.JPEG\n",
      "../data/imagenet-mini/train/n02883205/n02883205_16367.JPEG\n",
      "../data/imagenet-mini/train/n02883205/n02883205_16443.JPEG\n",
      "../data/imagenet-mini/train/n02883205/n02883205_23760.JPEG\n",
      "../data/imagenet-mini/train/n02795169/n02795169_11492.JPEG\n",
      "../data/imagenet-mini/train/n02795169/n02795169_7453.JPEG\n",
      "../data/imagenet-mini/train/n03773504/n03773504_23078.JPEG\n",
      "../data/imagenet-mini/train/n03773504/n03773504_25680.JPEG\n",
      "../data/imagenet-mini/train/n04482393/n04482393_3891.JPEG\n",
      "../data/imagenet-mini/train/n02930766/n02930766_20313.JPEG\n",
      "../data/imagenet-mini/train/n04296562/n04296562_18979.JPEG\n",
      "../data/imagenet-mini/train/n02108915/n02108915_6894.JPEG\n",
      "../data/imagenet-mini/train/n03085013/n03085013_5430.JPEG\n",
      "../data/imagenet-mini/train/n03085013/n03085013_20901.JPEG\n",
      "../data/imagenet-mini/train/n03085013/n03085013_22945.JPEG\n",
      "../data/imagenet-mini/train/n03085013/n03085013_12140.JPEG\n",
      "../data/imagenet-mini/train/n03085013/n03085013_21506.JPEG\n",
      "../data/imagenet-mini/train/n03085013/n03085013_23775.JPEG\n",
      "../data/imagenet-mini/train/n04591157/n04591157_576.JPEG\n",
      "../data/imagenet-mini/train/n02328150/n02328150_1797.JPEG\n",
      "../data/imagenet-mini/train/n02791124/n02791124_1928.JPEG\n",
      "../data/imagenet-mini/train/n02791124/n02791124_6387.JPEG\n",
      "../data/imagenet-mini/train/n04238763/n04238763_22437.JPEG\n",
      "../data/imagenet-mini/train/n03763968/n03763968_6975.JPEG\n",
      "../data/imagenet-mini/train/n03062245/n03062245_4527.JPEG\n",
      "../data/imagenet-mini/train/n04141076/n04141076_43949.JPEG\n",
      "../data/imagenet-mini/train/n04141076/n04141076_75558.JPEG\n",
      "../data/imagenet-mini/train/n04141076/n04141076_71154.JPEG\n",
      "../data/imagenet-mini/train/n04141076/n04141076_73894.JPEG\n",
      "../data/imagenet-mini/train/n04447861/n04447861_3339.JPEG\n",
      "../data/imagenet-mini/train/n03376595/n03376595_6525.JPEG\n",
      "../data/imagenet-mini/train/n04023962/n04023962_9274.JPEG\n",
      "../data/imagenet-mini/train/n04023962/n04023962_37636.JPEG\n",
      "../data/imagenet-mini/train/n04023962/n04023962_50943.JPEG\n",
      "../data/imagenet-mini/train/n03793489/n03793489_10431.JPEG\n",
      "../data/imagenet-mini/train/n04070727/n04070727_39231.JPEG\n",
      "../data/imagenet-mini/train/n04070727/n04070727_60011.JPEG\n",
      "../data/imagenet-mini/train/n02120505/n02120505_15958.JPEG\n",
      "../data/imagenet-mini/train/n02483362/n02483362_6436.JPEG\n",
      "../data/imagenet-mini/train/n04442312/n04442312_14092.JPEG\n",
      "../data/imagenet-mini/train/n04442312/n04442312_11526.JPEG\n",
      "../data/imagenet-mini/train/n03065424/n03065424_17272.JPEG\n",
      "../data/imagenet-mini/train/n03065424/n03065424_68951.JPEG\n",
      "../data/imagenet-mini/train/n03924679/n03924679_10873.JPEG\n",
      "../data/imagenet-mini/train/n02892767/n02892767_4201.JPEG\n",
      "../data/imagenet-mini/train/n02107312/n02107312_2048.JPEG\n",
      "../data/imagenet-mini/train/n04590129/n04590129_22609.JPEG\n",
      "../data/imagenet-mini/train/n04590129/n04590129_12864.JPEG\n",
      "../data/imagenet-mini/train/n04590129/n04590129_8578.JPEG\n",
      "../data/imagenet-mini/train/n04590129/n04590129_37963.JPEG\n",
      "../data/imagenet-mini/train/n07753592/n07753592_9565.JPEG\n",
      "../data/imagenet-mini/train/n02107142/n02107142_52349.JPEG\n",
      "../data/imagenet-mini/train/n02110627/n02110627_22516.JPEG\n",
      "../data/imagenet-mini/train/n02088466/n02088466_12216.JPEG\n",
      "../data/imagenet-mini/train/n02088466/n02088466_11132.JPEG\n",
      "../data/imagenet-mini/train/n03721384/n03721384_1709.JPEG\n",
      "../data/imagenet-mini/train/n03220513/n03220513_4782.JPEG\n",
      "../data/imagenet-mini/train/n02837789/n02837789_21447.JPEG\n",
      "../data/imagenet-mini/train/n02837789/n02837789_23422.JPEG\n",
      "../data/imagenet-mini/train/n02111500/n02111500_7146.JPEG\n",
      "../data/imagenet-mini/train/n02793495/n02793495_9539.JPEG\n",
      "../data/imagenet-mini/train/n02793495/n02793495_4609.JPEG\n",
      "../data/imagenet-mini/train/n03891251/n03891251_2898.JPEG\n",
      "../data/imagenet-mini/train/n03891251/n03891251_3947.JPEG\n",
      "../data/imagenet-mini/train/n03891251/n03891251_5637.JPEG\n",
      "../data/imagenet-mini/train/n03891251/n03891251_3383.JPEG\n",
      "../data/imagenet-mini/train/n04286575/n04286575_4871.JPEG\n",
      "../data/imagenet-mini/train/n02992529/n02992529_21092.JPEG\n",
      "../data/imagenet-mini/train/n02992529/n02992529_60654.JPEG\n",
      "../data/imagenet-mini/train/n02992529/n02992529_3308.JPEG\n",
      "../data/imagenet-mini/train/n04486054/n04486054_8908.JPEG\n",
      "../data/imagenet-mini/train/n03372029/n03372029_44161.JPEG\n",
      "../data/imagenet-mini/train/n03372029/n03372029_41945.JPEG\n",
      "../data/imagenet-mini/train/n04037443/n04037443_8697.JPEG\n",
      "../data/imagenet-mini/train/n04037443/n04037443_22059.JPEG\n",
      "../data/imagenet-mini/train/n03838899/n03838899_16491.JPEG\n",
      "../data/imagenet-mini/train/n03838899/n03838899_31104.JPEG\n",
      "../data/imagenet-mini/train/n04606251/n04606251_32516.JPEG\n",
      "../data/imagenet-mini/train/n03457902/n03457902_6713.JPEG\n",
      "../data/imagenet-mini/train/n07930864/n07930864_10538.JPEG\n",
      "../data/imagenet-mini/train/n07930864/n07930864_30821.JPEG\n",
      "../data/imagenet-mini/train/n03954731/n03954731_15587.JPEG\n",
      "../data/imagenet-mini/train/n01930112/n01930112_9652.JPEG\n",
      "../data/imagenet-mini/train/n01930112/n01930112_4440.JPEG\n",
      "../data/imagenet-mini/train/n01930112/n01930112_13988.JPEG\n",
      "../data/imagenet-mini/train/n01930112/n01930112_7379.JPEG\n",
      "../data/imagenet-mini/train/n01930112/n01930112_14916.JPEG\n",
      "../data/imagenet-mini/train/n04208210/n04208210_28386.JPEG\n",
      "../data/imagenet-mini/train/n04258138/n04258138_5172.JPEG\n",
      "../data/imagenet-mini/train/n04332243/n04332243_31816.JPEG\n",
      "../data/imagenet-mini/train/n02105056/n02105056_3683.JPEG\n",
      "../data/imagenet-mini/train/n02105056/n02105056_11069.JPEG\n",
      "../data/imagenet-mini/train/n02105056/n02105056_289.JPEG\n",
      "../data/imagenet-mini/train/n02692877/n02692877_32831.JPEG\n",
      "../data/imagenet-mini/train/n02692877/n02692877_18298.JPEG\n",
      "../data/imagenet-mini/train/n02692877/n02692877_5920.JPEG\n",
      "../data/imagenet-mini/train/n02692877/n02692877_5858.JPEG\n",
      "../data/imagenet-mini/train/n02692877/n02692877_6627.JPEG\n",
      "../data/imagenet-mini/train/n02692877/n02692877_6368.JPEG\n",
      "../data/imagenet-mini/train/n02692877/n02692877_3502.JPEG\n",
      "../data/imagenet-mini/train/n02692877/n02692877_3725.JPEG\n",
      "../data/imagenet-mini/train/n02692877/n02692877_25356.JPEG\n",
      "../data/imagenet-mini/train/n02093754/n02093754_6541.JPEG\n",
      "../data/imagenet-mini/train/n01491361/n01491361_5388.JPEG\n",
      "../data/imagenet-mini/train/n01491361/n01491361_4245.JPEG\n",
      "../data/imagenet-mini/train/n03538406/n03538406_3638.JPEG\n",
      "../data/imagenet-mini/train/n04467665/n04467665_7988.JPEG\n",
      "../data/imagenet-mini/train/n04553703/n04553703_18609.JPEG\n",
      "../data/imagenet-mini/train/n04553703/n04553703_34716.JPEG\n",
      "../data/imagenet-mini/train/n01795545/n01795545_13257.JPEG\n",
      "../data/imagenet-mini/train/n04612504/n04612504_364.JPEG\n",
      "../data/imagenet-mini/train/n03595614/n03595614_7821.JPEG\n",
      "../data/imagenet-mini/train/n03657121/n03657121_18041.JPEG\n",
      "../data/imagenet-mini/train/n03657121/n03657121_470.JPEG\n",
      "../data/imagenet-mini/train/n03657121/n03657121_7288.JPEG\n",
      "../data/imagenet-mini/train/n03657121/n03657121_41088.JPEG\n",
      "../data/imagenet-mini/train/n04081281/n04081281_4577.JPEG\n",
      "../data/imagenet-mini/train/n02095889/n02095889_9201.JPEG\n",
      "../data/imagenet-mini/train/n02095889/n02095889_5132.JPEG\n",
      "../data/imagenet-mini/train/n03895866/n03895866_127963.JPEG\n",
      "../data/imagenet-mini/train/n03895866/n03895866_94175.JPEG\n",
      "../data/imagenet-mini/train/n03895866/n03895866_137050.JPEG\n",
      "../data/imagenet-mini/train/n03110669/n03110669_162283.JPEG\n",
      "../data/imagenet-mini/train/n03110669/n03110669_85296.JPEG\n",
      "../data/imagenet-mini/train/n03110669/n03110669_72318.JPEG\n",
      "../data/imagenet-mini/train/n03110669/n03110669_112169.JPEG\n",
      "../data/imagenet-mini/train/n04153751/n04153751_3405.JPEG\n",
      "../data/imagenet-mini/train/n04153751/n04153751_10444.JPEG\n",
      "../data/imagenet-mini/train/n02669723/n02669723_2185.JPEG\n",
      "../data/imagenet-mini/train/n09428293/n09428293_46398.JPEG\n",
      "../data/imagenet-mini/train/n04532670/n04532670_15008.JPEG\n",
      "../data/imagenet-mini/train/n04532670/n04532670_10007.JPEG\n",
      "../data/imagenet-mini/train/n04532670/n04532670_32887.JPEG\n",
      "../data/imagenet-mini/train/n04532670/n04532670_18431.JPEG\n",
      "../data/imagenet-mini/train/n03908714/n03908714_105.JPEG\n",
      "../data/imagenet-mini/train/n03908714/n03908714_4058.JPEG\n",
      "../data/imagenet-mini/train/n03908714/n03908714_1861.JPEG\n",
      "../data/imagenet-mini/train/n03908714/n03908714_3926.JPEG\n",
      "../data/imagenet-mini/train/n03908714/n03908714_637.JPEG\n",
      "../data/imagenet-mini/train/n03443371/n03443371_11660.JPEG\n",
      "../data/imagenet-mini/train/n03961711/n03961711_1738.JPEG\n",
      "../data/imagenet-mini/train/n03891332/n03891332_483.JPEG\n",
      "../data/imagenet-mini/train/n03891332/n03891332_4026.JPEG\n",
      "../data/imagenet-mini/train/n03673027/n03673027_22831.JPEG\n",
      "../data/imagenet-mini/train/n02951585/n02951585_17058.JPEG\n",
      "../data/imagenet-mini/train/n02951585/n02951585_91.JPEG\n",
      "../data/imagenet-mini/train/n02110341/n02110341_14123.JPEG\n",
      "../data/imagenet-mini/train/n04330267/n04330267_16564.JPEG\n",
      "../data/imagenet-mini/train/n04330267/n04330267_18079.JPEG\n",
      "../data/imagenet-mini/train/n02092339/n02092339_6110.JPEG\n",
      "../data/imagenet-mini/train/n02092339/n02092339_5116.JPEG\n",
      "../data/imagenet-mini/train/n02092339/n02092339_6429.JPEG\n",
      "../data/imagenet-mini/train/n03476991/n03476991_29558.JPEG\n",
      "../data/imagenet-mini/train/n03476991/n03476991_27682.JPEG\n",
      "../data/imagenet-mini/train/n03452741/n03452741_11213.JPEG\n",
      "../data/imagenet-mini/train/n04204238/n04204238_7491.JPEG\n",
      "../data/imagenet-mini/train/n03874599/n03874599_2951.JPEG\n",
      "../data/imagenet-mini/train/n02097047/n02097047_2545.JPEG\n",
      "../data/imagenet-mini/train/n03180011/n03180011_10259.JPEG\n",
      "../data/imagenet-mini/train/n04465501/n04465501_1377.JPEG\n",
      "../data/imagenet-mini/train/n04465501/n04465501_3331.JPEG\n",
      "../data/imagenet-mini/train/n03884397/n03884397_8436.JPEG\n",
      "../data/imagenet-mini/train/n03884397/n03884397_5419.JPEG\n",
      "../data/imagenet-mini/train/n03630383/n03630383_3798.JPEG\n",
      "../data/imagenet-mini/train/n02093647/n02093647_8044.JPEG\n",
      "../data/imagenet-mini/train/n03394916/n03394916_7045.JPEG\n",
      "../data/imagenet-mini/train/n04589890/n04589890_2205.JPEG\n",
      "../data/imagenet-mini/train/n04589890/n04589890_9771.JPEG\n",
      "../data/imagenet-mini/train/n03124043/n03124043_2249.JPEG\n",
      "../data/imagenet-mini/train/n03017168/n03017168_18051.JPEG\n",
      "../data/imagenet-mini/train/n03017168/n03017168_38025.JPEG\n",
      "../data/imagenet-mini/train/n03017168/n03017168_33511.JPEG\n",
      "../data/imagenet-mini/train/n02408429/n02408429_11593.JPEG\n",
      "../data/imagenet-mini/train/n02859443/n02859443_18078.JPEG\n",
      "../data/imagenet-mini/train/n02085620/n02085620_4629.JPEG\n",
      "../data/imagenet-mini/train/n02085620/n02085620_4210.JPEG\n",
      "../data/imagenet-mini/train/n02085620/n02085620_1194.JPEG\n",
      "../data/imagenet-mini/train/n02112706/n02112706_2856.JPEG\n",
      "../data/imagenet-mini/train/n04370456/n04370456_11533.JPEG\n",
      "../data/imagenet-mini/train/n02979186/n02979186_1587.JPEG\n",
      "../data/imagenet-mini/train/n03445777/n03445777_8971.JPEG\n",
      "../data/imagenet-mini/train/n03445777/n03445777_5325.JPEG\n",
      "../data/imagenet-mini/train/n01990800/n01990800_16602.JPEG\n",
      "../data/imagenet-mini/train/n04548280/n04548280_5424.JPEG\n",
      "../data/imagenet-mini/train/n02128925/n02128925_3789.JPEG\n",
      "../data/imagenet-mini/train/n03958227/n03958227_4724.JPEG\n",
      "../data/imagenet-mini/train/n03109150/n03109150_5636.JPEG\n",
      "../data/imagenet-mini/train/n03109150/n03109150_25112.JPEG\n",
      "../data/imagenet-mini/train/n07802026/n07802026_152.JPEG\n",
      "../data/imagenet-mini/train/n07802026/n07802026_20020.JPEG\n",
      "../data/imagenet-mini/train/n07802026/n07802026_17453.JPEG\n",
      "../data/imagenet-mini/train/n04005630/n04005630_95489.JPEG\n",
      "../data/imagenet-mini/train/n03804744/n03804744_10763.JPEG\n",
      "../data/imagenet-mini/train/n02089078/n02089078_2638.JPEG\n",
      "../data/imagenet-mini/train/n02481823/n02481823_14519.JPEG\n",
      "../data/imagenet-mini/train/n02481823/n02481823_3990.JPEG\n",
      "../data/imagenet-mini/train/n02481823/n02481823_1191.JPEG\n",
      "../data/imagenet-mini/train/n02481823/n02481823_17637.JPEG\n",
      "../data/imagenet-mini/train/n04259630/n04259630_11609.JPEG\n",
      "../data/imagenet-mini/train/n02794156/n02794156_19363.JPEG\n",
      "../data/imagenet-mini/train/n02794156/n02794156_10156.JPEG\n",
      "../data/imagenet-mini/train/n02794156/n02794156_1916.JPEG\n",
      "../data/imagenet-mini/train/n04147183/n04147183_13979.JPEG\n",
      "../data/imagenet-mini/train/n02916936/n02916936_9535.JPEG\n",
      "../data/imagenet-mini/train/n02916936/n02916936_1445.JPEG\n",
      "../data/imagenet-mini/train/n03868863/n03868863_4734.JPEG\n",
      "../data/imagenet-mini/train/n03868863/n03868863_132.JPEG\n",
      "../data/imagenet-mini/train/n03868863/n03868863_6703.JPEG\n",
      "../data/imagenet-mini/train/n04204347/n04204347_7406.JPEG\n",
      "../data/imagenet-mini/train/n01514859/n01514859_9725.JPEG\n",
      "../data/imagenet-mini/train/n04443257/n04443257_41924.JPEG\n",
      "../data/imagenet-mini/train/n04443257/n04443257_20359.JPEG\n",
      "../data/imagenet-mini/train/n04009552/n04009552_2159.JPEG\n",
      "../data/imagenet-mini/train/n03873416/n03873416_4377.JPEG\n",
      "../data/imagenet-mini/train/n03272562/n03272562_7870.JPEG\n",
      "../data/imagenet-mini/train/n03127925/n03127925_3988.JPEG\n",
      "../data/imagenet-mini/train/n02105641/n02105641_3786.JPEG\n",
      "../data/imagenet-mini/train/n02111889/n02111889_3691.JPEG\n",
      "../data/imagenet-mini/train/n02708093/n02708093_304.JPEG\n",
      "../data/imagenet-mini/train/n02708093/n02708093_3206.JPEG\n",
      "../data/imagenet-mini/train/n04254680/n04254680_7339.JPEG\n",
      "../data/imagenet-mini/train/n03743016/n03743016_14769.JPEG\n",
      "../data/imagenet-mini/train/n03743016/n03743016_4320.JPEG\n",
      "../data/imagenet-mini/train/n04562935/n04562935_6426.JPEG\n",
      "../data/imagenet-mini/train/n04118776/n04118776_68075.JPEG\n",
      "../data/imagenet-mini/train/n04118776/n04118776_3546.JPEG\n",
      "../data/imagenet-mini/train/n02091134/n02091134_1526.JPEG\n",
      "../data/imagenet-mini/train/n04458633/n04458633_3571.JPEG\n",
      "../data/imagenet-mini/train/n04458633/n04458633_4746.JPEG\n",
      "../data/imagenet-mini/train/n03344393/n03344393_6191.JPEG\n",
      "../data/imagenet-mini/train/n02999410/n02999410_10081.JPEG\n",
      "../data/imagenet-mini/train/n02999410/n02999410_19414.JPEG\n",
      "../data/imagenet-mini/train/n02999410/n02999410_8597.JPEG\n",
      "../data/imagenet-mini/train/n02999410/n02999410_17559.JPEG\n",
      "../data/imagenet-mini/train/n02105505/n02105505_2467.JPEG\n",
      "../data/imagenet-mini/train/n02105505/n02105505_5898.JPEG\n",
      "../data/imagenet-mini/train/n04525305/n04525305_4072.JPEG\n",
      "../data/imagenet-mini/train/n03467068/n03467068_8691.JPEG\n",
      "../data/imagenet-mini/train/n03467068/n03467068_10035.JPEG\n",
      "../data/imagenet-mini/train/n03467068/n03467068_8800.JPEG\n",
      "../data/imagenet-mini/train/n04008634/n04008634_25354.JPEG\n",
      "../data/imagenet-mini/train/n04008634/n04008634_18231.JPEG\n",
      "../data/imagenet-mini/train/n04069434/n04069434_21934.JPEG\n",
      "../data/imagenet-mini/train/n04069434/n04069434_4001.JPEG\n",
      "../data/imagenet-mini/train/n04069434/n04069434_11503.JPEG\n",
      "../data/imagenet-mini/train/n02488291/n02488291_1558.JPEG\n",
      "../data/imagenet-mini/train/n02488291/n02488291_1510.JPEG\n",
      "../data/imagenet-mini/train/n04263257/n04263257_1946.JPEG\n",
      "../data/imagenet-mini/train/n03888605/n03888605_36989.JPEG\n",
      "../data/imagenet-mini/train/n04505470/n04505470_5154.JPEG\n",
      "../data/imagenet-mini/train/n04505470/n04505470_2769.JPEG\n",
      "../data/imagenet-mini/train/n03992509/n03992509_1708.JPEG\n",
      "../data/imagenet-mini/train/n03992509/n03992509_14593.JPEG\n",
      "../data/imagenet-mini/train/n03992509/n03992509_8228.JPEG\n",
      "../data/imagenet-mini/train/n03992509/n03992509_874.JPEG\n",
      "../data/imagenet-mini/train/n03658185/n03658185_4260.JPEG\n",
      "../data/imagenet-mini/train/n02860847/n02860847_6819.JPEG\n",
      "../data/imagenet-mini/train/n02860847/n02860847_29748.JPEG\n",
      "../data/imagenet-mini/train/n02099267/n02099267_512.JPEG\n",
      "../data/imagenet-mini/train/n03982430/n03982430_27117.JPEG\n",
      "../data/imagenet-mini/train/n04317175/n04317175_6652.JPEG\n",
      "../data/imagenet-mini/train/n04536866/n04536866_3282.JPEG\n",
      "../data/imagenet-mini/train/n04536866/n04536866_20544.JPEG\n",
      "../data/imagenet-mini/train/n04536866/n04536866_3629.JPEG\n",
      "../data/imagenet-mini/train/n04536866/n04536866_12210.JPEG\n",
      "../data/imagenet-mini/train/n04536866/n04536866_12630.JPEG\n",
      "../data/imagenet-mini/train/n02749479/n02749479_89.JPEG\n",
      "../data/imagenet-mini/train/n02749479/n02749479_29157.JPEG\n",
      "../data/imagenet-mini/train/n02749479/n02749479_4779.JPEG\n",
      "../data/imagenet-mini/train/n02749479/n02749479_932.JPEG\n",
      "../data/imagenet-mini/train/n03075370/n03075370_2458.JPEG\n",
      "../data/imagenet-mini/train/n03075370/n03075370_9413.JPEG\n",
      "../data/imagenet-mini/train/n03483316/n03483316_11347.JPEG\n",
      "../data/imagenet-mini/train/n03483316/n03483316_21775.JPEG\n",
      "../data/imagenet-mini/train/n04131690/n04131690_8589.JPEG\n",
      "../data/imagenet-mini/train/n02879718/n02879718_30188.JPEG\n",
      "../data/imagenet-mini/train/n03000134/n03000134_4747.JPEG\n",
      "../data/imagenet-mini/train/n03000134/n03000134_2546.JPEG\n",
      "../data/imagenet-mini/train/n03000134/n03000134_1753.JPEG\n",
      "../data/imagenet-mini/train/n03000134/n03000134_14.JPEG\n",
      "../data/imagenet-mini/train/n02895154/n02895154_9919.JPEG\n",
      "../data/imagenet-mini/train/n03902125/n03902125_21133.JPEG\n",
      "../data/imagenet-mini/train/n02093859/n02093859_4345.JPEG\n",
      "../data/imagenet-mini/train/n04200800/n04200800_38142.JPEG\n",
      "../data/imagenet-mini/train/n03661043/n03661043_7787.JPEG\n",
      "../data/imagenet-mini/train/n04209239/n04209239_11024.JPEG\n",
      "../data/imagenet-mini/train/n04209239/n04209239_8143.JPEG\n",
      "../data/imagenet-mini/train/n03424325/n03424325_23753.JPEG\n",
      "../data/imagenet-mini/train/n03424325/n03424325_5687.JPEG\n",
      "../data/imagenet-mini/train/n03602883/n03602883_11170.JPEG\n",
      "../data/imagenet-mini/train/n02091467/n02091467_4823.JPEG\n",
      "../data/imagenet-mini/train/n02091467/n02091467_12614.JPEG\n",
      "../data/imagenet-mini/train/n04127249/n04127249_2853.JPEG\n",
      "../data/imagenet-mini/train/n03495258/n03495258_9193.JPEG\n",
      "../data/imagenet-mini/train/n03495258/n03495258_16828.JPEG\n",
      "../data/imagenet-mini/train/n03495258/n03495258_25470.JPEG\n",
      "../data/imagenet-mini/train/n03970156/n03970156_28533.JPEG\n",
      "../data/imagenet-mini/train/n02391049/n02391049_1508.JPEG\n",
      "../data/imagenet-mini/train/n03930313/n03930313_474.JPEG\n",
      "../data/imagenet-mini/train/n02085936/n02085936_14974.JPEG\n",
      "../data/imagenet-mini/train/n03777754/n03777754_2785.JPEG\n",
      "../data/imagenet-mini/train/n02978881/n02978881_607.JPEG\n",
      "../data/imagenet-mini/train/n02978881/n02978881_43638.JPEG\n",
      "../data/imagenet-mini/train/n02978881/n02978881_12420.JPEG\n",
      "../data/imagenet-mini/train/n02978881/n02978881_12824.JPEG\n",
      "../data/imagenet-mini/train/n01494475/n01494475_4148.JPEG\n",
      "../data/imagenet-mini/train/n03825788/n03825788_6706.JPEG\n",
      "../data/imagenet-mini/train/n03494278/n03494278_38369.JPEG\n",
      "../data/imagenet-mini/train/n03494278/n03494278_34652.JPEG\n",
      "../data/imagenet-mini/train/n03633091/n03633091_12244.JPEG\n",
      "../data/imagenet-mini/train/n04509417/n04509417_4949.JPEG\n",
      "../data/imagenet-mini/train/n04509417/n04509417_6017.JPEG\n",
      "../data/imagenet-mini/train/n07920052/n07920052_599.JPEG\n",
      "../data/imagenet-mini/train/n01737021/n01737021_429.JPEG\n",
      "../data/imagenet-mini/train/n03599486/n03599486_13087.JPEG\n",
      "../data/imagenet-mini/train/n04554684/n04554684_4076.JPEG\n",
      "../data/imagenet-mini/train/n02939185/n02939185_21836.JPEG\n",
      "../data/imagenet-mini/train/n02104029/n02104029_7622.JPEG\n",
      "../data/imagenet-mini/train/n04328186/n04328186_48308.JPEG\n",
      "../data/imagenet-mini/train/n04328186/n04328186_4766.JPEG\n",
      "../data/imagenet-mini/train/n04328186/n04328186_8361.JPEG\n",
      "../data/imagenet-mini/train/n03692522/n03692522_12000.JPEG\n",
      "../data/imagenet-mini/train/n03692522/n03692522_4410.JPEG\n",
      "../data/imagenet-mini/train/n03692522/n03692522_11536.JPEG\n",
      "../data/imagenet-mini/train/n04019541/n04019541_8604.JPEG\n",
      "../data/imagenet-mini/train/n04356056/n04356056_60202.JPEG\n",
      "../data/imagenet-mini/train/n04356056/n04356056_2540.JPEG\n",
      "../data/imagenet-mini/train/n06785654/n06785654_3588.JPEG\n",
      "../data/imagenet-mini/train/n06785654/n06785654_11253.JPEG\n",
      "../data/imagenet-mini/train/n06785654/n06785654_12009.JPEG\n",
      "../data/imagenet-mini/train/n06785654/n06785654_3680.JPEG\n",
      "../data/imagenet-mini/train/n06785654/n06785654_3346.JPEG\n",
      "../data/imagenet-mini/train/n06785654/n06785654_2319.JPEG\n",
      "../data/imagenet-mini/train/n04336792/n04336792_19464.JPEG\n",
      "../data/imagenet-mini/train/n04336792/n04336792_42773.JPEG\n",
      "../data/imagenet-mini/train/n04336792/n04336792_18677.JPEG\n",
      "../data/imagenet-mini/train/n04162706/n04162706_46463.JPEG\n",
      "../data/imagenet-mini/train/n04162706/n04162706_18311.JPEG\n",
      "../data/imagenet-mini/train/n04162706/n04162706_10402.JPEG\n",
      "../data/imagenet-mini/train/n03903868/n03903868_50629.JPEG\n",
      "../data/imagenet-mini/train/n04141975/n04141975_35800.JPEG\n",
      "../data/imagenet-mini/train/n04141975/n04141975_15.JPEG\n",
      "../data/imagenet-mini/train/n04141975/n04141975_11858.JPEG\n",
      "../data/imagenet-mini/train/n04141975/n04141975_34852.JPEG\n",
      "../data/imagenet-mini/train/n04154565/n04154565_25237.JPEG\n",
      "../data/imagenet-mini/train/n04423845/n04423845_3482.JPEG\n",
      "../data/imagenet-mini/train/n04423845/n04423845_10470.JPEG\n",
      "../data/imagenet-mini/train/n04487081/n04487081_11484.JPEG\n",
      "../data/imagenet-mini/train/n04560804/n04560804_10316.JPEG\n",
      "../data/imagenet-mini/train/n04560804/n04560804_13629.JPEG\n",
      "../data/imagenet-mini/train/n04560804/n04560804_4935.JPEG\n",
      "../data/imagenet-mini/train/n04039381/n04039381_19558.JPEG\n",
      "../data/imagenet-mini/train/n02113624/n02113624_6418.JPEG\n",
      "../data/imagenet-mini/train/n02687172/n02687172_34236.JPEG\n",
      "../data/imagenet-mini/train/n02992211/n02992211_26518.JPEG\n",
      "../data/imagenet-mini/train/n02992211/n02992211_37588.JPEG\n",
      "../data/imagenet-mini/train/n02992211/n02992211_30118.JPEG\n",
      "../data/imagenet-mini/train/n02992211/n02992211_33045.JPEG\n",
      "../data/imagenet-mini/train/n02992211/n02992211_34104.JPEG\n",
      "../data/imagenet-mini/train/n02992211/n02992211_33025.JPEG\n",
      "../data/imagenet-mini/train/n02992211/n02992211_37010.JPEG\n",
      "../data/imagenet-mini/train/n03929660/n03929660_969.JPEG\n",
      "../data/imagenet-mini/train/n03929660/n03929660_20053.JPEG\n",
      "../data/imagenet-mini/train/n03929660/n03929660_2693.JPEG\n",
      "../data/imagenet-mini/train/n03929660/n03929660_56931.JPEG\n",
      "../data/imagenet-mini/train/n03929660/n03929660_13396.JPEG\n",
      "../data/imagenet-mini/train/n03297495/n03297495_628.JPEG\n",
      "../data/imagenet-mini/train/n04417672/n04417672_13599.JPEG\n",
      "../data/imagenet-mini/train/n03777568/n03777568_1037.JPEG\n",
      "../data/imagenet-mini/train/n03777568/n03777568_17270.JPEG\n",
      "../data/imagenet-mini/train/n04461696/n04461696_2394.JPEG\n",
      "../data/imagenet-mini/train/n04326547/n04326547_12133.JPEG\n",
      "../data/imagenet-mini/train/n02013706/n02013706_4625.JPEG\n",
      "../data/imagenet-mini/train/n04501370/n04501370_11469.JPEG\n",
      "../data/imagenet-mini/train/n03929855/n03929855_6199.JPEG\n",
      "../data/imagenet-mini/train/n02086240/n02086240_3799.JPEG\n",
      "../data/imagenet-mini/train/n02480855/n02480855_252.JPEG\n",
      "../data/imagenet-mini/train/n02480855/n02480855_17876.JPEG\n",
      "../data/imagenet-mini/train/n02480855/n02480855_15738.JPEG\n",
      "../data/imagenet-mini/train/n03379051/n03379051_7286.JPEG\n",
      "../data/imagenet-mini/train/n02977058/n02977058_22084.JPEG\n",
      "../data/imagenet-mini/train/n01773157/n01773157_9579.JPEG\n",
      "../data/imagenet-mini/train/n02088632/n02088632_4771.JPEG\n",
      "../data/imagenet-mini/train/n03709823/n03709823_1562.JPEG\n",
      "../data/imagenet-mini/train/n03530642/n03530642_46236.JPEG\n",
      "../data/imagenet-mini/train/n04579432/n04579432_18779.JPEG\n",
      "../data/imagenet-mini/train/n03976657/n03976657_8585.JPEG\n",
      "../data/imagenet-mini/train/n03841143/n03841143_2841.JPEG\n",
      "../data/imagenet-mini/train/n03995372/n03995372_14826.JPEG\n",
      "../data/imagenet-mini/train/n03995372/n03995372_3603.JPEG\n",
      "../data/imagenet-mini/train/n03325584/n03325584_10730.JPEG\n",
      "../data/imagenet-mini/train/n03216828/n03216828_28729.JPEG\n",
      "../data/imagenet-mini/train/n03216828/n03216828_60705.JPEG\n",
      "../data/imagenet-mini/train/n03216828/n03216828_984.JPEG\n",
      "../data/imagenet-mini/train/n03063599/n03063599_4132.JPEG\n",
      "../data/imagenet-mini/train/n04179913/n04179913_11903.JPEG\n",
      "../data/imagenet-mini/train/n04044716/n04044716_1626.JPEG\n",
      "../data/imagenet-mini/train/n04044716/n04044716_6855.JPEG\n",
      "../data/imagenet-mini/train/n02091032/n02091032_12363.JPEG\n",
      "../data/imagenet-mini/train/n03384352/n03384352_8614.JPEG\n",
      "../data/imagenet-mini/train/n03388549/n03388549_5594.JPEG\n",
      "../data/imagenet-mini/train/n04372370/n04372370_25321.JPEG\n",
      "../data/imagenet-mini/train/n04372370/n04372370_21436.JPEG\n",
      "../data/imagenet-mini/train/n04372370/n04372370_42250.JPEG\n",
      "../data/imagenet-mini/train/n03857828/n03857828_28253.JPEG\n",
      "../data/imagenet-mini/train/n03857828/n03857828_7955.JPEG\n",
      "../data/imagenet-mini/train/n04380533/n04380533_17646.JPEG\n",
      "../data/imagenet-mini/train/n04380533/n04380533_5780.JPEG\n",
      "../data/imagenet-mini/train/n04485082/n04485082_2236.JPEG\n",
      "../data/imagenet-mini/train/n04485082/n04485082_60909.JPEG\n",
      "../data/imagenet-mini/train/n04485082/n04485082_14560.JPEG\n",
      "../data/imagenet-mini/train/n03627232/n03627232_5560.JPEG\n",
      "../data/imagenet-mini/train/n04251144/n04251144_20993.JPEG\n",
      "../data/imagenet-mini/train/n04523525/n04523525_2111.JPEG\n",
      "BW cleaning terminated.\n"
     ]
    }
   ],
   "source": [
    "clean_bw_imgs(\"../data/imagenet-mini/train/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might want to work on a subset of tinyimagenet for computations reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progression:90.00%\n",
      "Sampling terminated.\n"
     ]
    }
   ],
   "source": [
    "sample_imagenet(\"../data/imagenet-mini/train/\",\"../data/imagenet10classes\",num_dir=10,img_num_per_dir=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg16(pretrained=True)\n",
    "# same preprocess used as vgg16\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.CenterCrop(224), \n",
    "    transforms.ToTensor()\n",
    "    ,transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#watch out: once you chose a folder name for the computed images and a json name, the json name will point to that folder name exclusively.\n",
    "lurker = Lurk(model,preprocess,labels_path=\"../data/labels.txt\"\n",
    "                              ,save_gen_imgs_dir='../results/trash/'\n",
    "                              ,save_json_path='../saved_model/trash.json'\n",
    "                              ,imgs_src_dir=\"../data/imagenet10classes/images/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this cell if you want to create the information for the first time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dill saving done!\n",
      "Loading done!\n"
     ]
    }
   ],
   "source": [
    "lurker.save_to_dill(\"../trash.pickle\")\n",
    "\n",
    "lurker = Lurk.load_from_dill(\"../trash.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wish to load a precomputed json, just add the `load_path` attribute. Watch out, it needs to be coherent with the folder name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading done!\n"
     ]
    }
   ],
   "source": [
    "lurker3 = Lurk(model,preprocess,labels_path=\"../data/labels.txt\",\n",
    "               save_gen_imgs_dir='../results/trash/'\n",
    "                              ,save_json_path='../saved_model/06_05_20.json'\n",
    "                              ,imgs_src_dir=\"../data/imagenet10classes/images\",\n",
    "                              load_json_path='../saved_model/trash.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json saving done!\n"
     ]
    }
   ],
   "source": [
    "lurker.compute_avgmax_imgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lurker.plot_hist(0,0,\"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('bustard', 5.937810182571411),\n",
       "             ('wire-haired_fox_terrier', 5.15470290184021),\n",
       "             ('leafhopper', 4.718497276306152),\n",
       "             ('lacewing', 7.0146729946136475),\n",
       "             ('dam', 3.7950114011764526),\n",
       "             ('recreational_vehicle', 4.328025460243225),\n",
       "             ('tub', 4.84566855430603),\n",
       "             ('wig', 10.366637706756592),\n",
       "             ('comic_book', 8.4020357131958),\n",
       "             ('acorn', 5.408631086349487)])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lurker.model_info[0]['filters'][0]['histo_counts_max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lurker.compute_viz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualization done!\n"
     ]
    }
   ],
   "source": [
    "lurker.compute_layer_viz(layer_indx = 0,filter_indexes=[6,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json saving done!\n"
     ]
    }
   ],
   "source": [
    "lurker.compute_grads()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torchlurk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'labels_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-172-c40e95af6bfb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m lurker = Lurk(model,preprocess,save_gen_imgs_dir='../results/06_05_20/'\n\u001b[1;32m      3\u001b[0m                               \u001b[0;34m,\u001b[0m\u001b[0msave_json_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'../saved_model/06_05_20.json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                               ,imgs_src_dir=\"../data/50classes/\")\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'labels_path'"
     ]
    }
   ],
   "source": [
    "#watch out: once you chose a folder name for the computed images and a json name, the json name will point to that folder name exclusively.\n",
    "lurker = Lurk(model,preprocess,save_gen_imgs_dir='../results/06_05_20/'\n",
    "                              ,save_json_path='../saved_model/06_05_20.json'\n",
    "                              ,imgs_src_dir=\"../data/50classes/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current cursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#watch out: once you chose a folder name for the computed images and a json name, the json name will point to that folder name exclusively.\n",
    "lurker = Lurk(model,preprocess,labels_path=\"../data/labels.txt\"\n",
    "                              ,save_gen_imgs_dir='../results/trash/'\n",
    "                              ,save_json_path='../saved_model/trash.json'\n",
    "                              ,imgs_src_dir=\"../data/imagenet10classes/images/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>n02018795</td>\n",
       "      <td>n02018795</td>\n",
       "      <td>0</td>\n",
       "      <td>bustard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n02095314</td>\n",
       "      <td>n02095314</td>\n",
       "      <td>1</td>\n",
       "      <td>wire-haired_fox_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n02259212</td>\n",
       "      <td>n02259212</td>\n",
       "      <td>2</td>\n",
       "      <td>leafhopper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n02264363</td>\n",
       "      <td>n02264363</td>\n",
       "      <td>3</td>\n",
       "      <td>lacewing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n03160309</td>\n",
       "      <td>n03160309</td>\n",
       "      <td>4</td>\n",
       "      <td>dam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n04065272</td>\n",
       "      <td>n04065272</td>\n",
       "      <td>5</td>\n",
       "      <td>recreational_vehicle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n04493381</td>\n",
       "      <td>n04493381</td>\n",
       "      <td>6</td>\n",
       "      <td>tub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n04584207</td>\n",
       "      <td>n04584207</td>\n",
       "      <td>7</td>\n",
       "      <td>wig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n06596364</td>\n",
       "      <td>n06596364</td>\n",
       "      <td>8</td>\n",
       "      <td>comic_book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n12267677</td>\n",
       "      <td>n12267677</td>\n",
       "      <td>9</td>\n",
       "      <td>acorn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           file_name  label                    title\n",
       "file_name                                           \n",
       "n02018795  n02018795      0                  bustard\n",
       "n02095314  n02095314      1  wire-haired_fox_terrier\n",
       "n02259212  n02259212      2               leafhopper\n",
       "n02264363  n02264363      3                 lacewing\n",
       "n03160309  n03160309      4                      dam\n",
       "n04065272  n04065272      5     recreational_vehicle\n",
       "n04493381  n04493381      6                      tub\n",
       "n04584207  n04584207      7                      wig\n",
       "n06596364  n06596364      8               comic_book\n",
       "n12267677  n12267677      9                    acorn"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lurker.recreate_labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- Representation of a Lurk\n",
    "- iteration over the conv_layinfos\n",
    "- instanciation with cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>n02018795</td>\n",
       "      <td>n02018795</td>\n",
       "      <td>0</td>\n",
       "      <td>bustard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n02095314</td>\n",
       "      <td>n02095314</td>\n",
       "      <td>1</td>\n",
       "      <td>wire-haired_fox_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n02259212</td>\n",
       "      <td>n02259212</td>\n",
       "      <td>2</td>\n",
       "      <td>leafhopper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n02264363</td>\n",
       "      <td>n02264363</td>\n",
       "      <td>3</td>\n",
       "      <td>lacewing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n03160309</td>\n",
       "      <td>n03160309</td>\n",
       "      <td>4</td>\n",
       "      <td>dam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n04065272</td>\n",
       "      <td>n04065272</td>\n",
       "      <td>5</td>\n",
       "      <td>recreational_vehicle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n04493381</td>\n",
       "      <td>n04493381</td>\n",
       "      <td>6</td>\n",
       "      <td>tub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n04584207</td>\n",
       "      <td>n04584207</td>\n",
       "      <td>7</td>\n",
       "      <td>wig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n06596364</td>\n",
       "      <td>n06596364</td>\n",
       "      <td>8</td>\n",
       "      <td>comic_book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n12267677</td>\n",
       "      <td>n12267677</td>\n",
       "      <td>9</td>\n",
       "      <td>acorn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           file_name  label                    title\n",
       "file_name                                           \n",
       "n02018795  n02018795      0                  bustard\n",
       "n02095314  n02095314      1  wire-haired_fox_terrier\n",
       "n02259212  n02259212      2               leafhopper\n",
       "n02264363  n02264363      3                 lacewing\n",
       "n03160309  n03160309      4                      dam\n",
       "n04065272  n04065272      5     recreational_vehicle\n",
       "n04493381  n04493381      6                      tub\n",
       "n04584207  n04584207      7                      wig\n",
       "n06596364  n06596364      8               comic_book\n",
       "n12267677  n12267677      9                    acorn"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lurker.recreate_labels(\"../data/labels.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess.transforms[0].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im = Image.open(\"../data/\")\n",
    "preprocess(im).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lurk():\n",
    "    def __init__(self,model,preprocess,labels_path,\n",
    "                 save_gen_imgs_dir,save_json_path,imgs_src_dir,\n",
    "                 n_top_avg=3,n_top_max=3,load_json_path=None):\n",
    "        \"\"\"\n",
    "        Lurker class: one lurker can be instanciated per trained pytorch network. Several methods allow to generate various types of data\n",
    "        concerning the network and can be visualized thanks to the bash command TOCOMPLETE\n",
    "        Parameters\n",
    "        ----------\n",
    "        model : torch.model\n",
    "            the trained model\n",
    "        preprocess : torchvision.transforms.transforms.Compose\n",
    "            the preprocessing used when training the model\n",
    "        labels_path : string\n",
    "            path to the file associating the class titles (ex: penguin) to their dirname (ex:n02018795) and their label (ex:724)\n",
    "        save_gen_imgs_dir : str\n",
    "            directory where to save the generated images: some subdirectories will be created inside\n",
    "        save_json_path : string\n",
    "            path to the json object to create which will stock information for subsequent visualization. Must have an \".json\" extension\n",
    "        imgs_src_dir : string\n",
    "            directory to the train set of the model\n",
    "        n_top_avg : int\n",
    "            how many average images to keep in the top average filter activations\n",
    "        n_top_max : int\n",
    "            how many average images to keep in the top maximum filter activations\n",
    "        load_json_path : string\n",
    "            path to a previously computed json file: NB the other arguments need to be similar as during this first run. If set to a value,\n",
    "            the lurker will load the previously computed informations, if set to None, will start a new lurker from scratch\n",
    "            \n",
    "        \"\"\"\n",
    "        ##################### TODO: get rid of dev#####################\n",
    "        # allow to run reduced computations\n",
    "        self.DEVELOPMENT = True\n",
    "        #number of layers we compute stuff for in development mode\n",
    "        self.N_LAYERS_DEV = 1\n",
    "        #number of filters we compute stuff for in development mode\n",
    "        self.N_FILTERS_DEV = 1\n",
    "        ###############################################################\n",
    "        \n",
    "        #model to compute a lurker for\n",
    "        self.model = model\n",
    "        #preprocessing used when training the model\n",
    "        self.preprocess = preprocess\n",
    "        #path to the labels\n",
    "        self.LABELS_PATH = labels_path\n",
    "        #directory where to save the generated images\n",
    "        self.GEN_IMGS_DIR = save_gen_imgs_dir\n",
    "        \n",
    "        #directory where to load the training images\n",
    "        self.IMGS_DIR = imgs_src_dir\n",
    "        \n",
    "        #where to save the json\n",
    "        self.JSON_PATH_WRITE = save_json_path\n",
    "        #number of avg spikes images per filter\n",
    "        self.N_TOP_AVG = n_top_avg\n",
    "        # number of max spikes images per filter\n",
    "        self.N_TOP_MAX = n_top_max\n",
    "        \n",
    "        #path to the numb image\n",
    "        self.NUMB_PATH = \"../data/numb.png\"\n",
    "        \n",
    "        self.dataset = ImageFolderWithPaths(self.IMGS_DIR,transform=self.preprocess)\n",
    "        self.data_loader = torch.utils.data.dataloader(self.dataset, batch_size=1, shuffle=true)\n",
    "\n",
    "        # each class has 3 kinds of representation: (1)class titles (ex: \"penguin\") (2) dirname (ex:\"n02018795\") (3) label (ex:724)\n",
    "        # CLASS2LAB and LAB2TITLE allow to convert the info from one type to the other\n",
    "        self.CLASS2LAB = self.dataset.class_to_idx\n",
    "        labels_infos = self.recreate_labels()\n",
    "        self.LAB2TITLE = labels_infos.set_index('label')['title'].to_dict()\n",
    "        \n",
    "        assert(set(self.LAB2TITLE.keys())==(set(self.CLASS2LAB.values())))\n",
    "        assert(len(self.LAB2TITLE) == len(self.CLASS2LAB))\n",
    "        \n",
    "        if load_json_path is not None:\n",
    "            # loading information from a previously computed json file\n",
    "            self.load_from_json(load_json_path)\n",
    "        else:\n",
    "            # building the information from scratch\n",
    "            self.__build_model_info()\n",
    "        \n",
    "        create_folders(self.GEN_IMGS_DIR,[\"avg_act_grads\",\"max_act_grads\",\"max_act_cropped\",\"max_act_grads_cropped\",\"filt_viz\"],self.model_info)\n",
    "        \n",
    "        \n",
    "        self.title_counts = dict(zip(self.LAB1TITLE.values(),[0] *len(self.LAB2TITLE)))\n",
    "        #initiate the number of counts for the classes\n",
    "        self.__init_class_counts(self.LAB2TITLE, self.IMGS_DIR,self.title_counts)\n",
    "    \n",
    "    \n",
    "    ################################ Building/Loading ################################\n",
    "    \n",
    "    def __build_model_info(self):\n",
    "        \"\"\"\n",
    "        build the model_info from scratch\n",
    "        \"\"\"\n",
    "        model_info = []\n",
    "        layers = []\n",
    "        #construct the data structure\n",
    "        for layer in list(self.model.features.named_children()):\n",
    "            lay_info = {'id':layer[0],\n",
    "                      'lay':layer[1],\n",
    "                      'name':str(layer[1]).split('(')[0] + \"_\" + str(layer[0]) \n",
    "                    }\n",
    "            if (isinstance(layer[1],(nn.Conv2d,nn.MaxPool2d))):\n",
    "                layers.append(layer[1])\n",
    "            if (isinstance(lay_info['lay'],nn.Conv2d)):     \n",
    "                n_input = lay_info['lay'].in_channels\n",
    "                n_output = lay_info['lay'].out_channels\n",
    "                lay_info['n_input'] = n_input\n",
    "                lay_info['n_output'] = n_output\n",
    "                lay_info['deproj'] = Projector(deepcopy(layers),224)\n",
    "                lay_info[\"filters\"] = []\n",
    "                for i in range(n_output):\n",
    "                    lay_info[\"filters\"].append({\n",
    "                        \"id\":i,\n",
    "                        \"avg_spikes\":[0 for i in range(self.N_TOP_AVG)],\n",
    "                        \"avg_imgs\":[self.NUMB_PATH for i in range(self.N_TOP_AVG)],\n",
    "                        \"avg_imgs_grad\":[self.NUMB_PATH for i in range(self.N_TOP_AVG)],\n",
    "                        \"max_spikes\":[0 for i in range(self.N_TOP_MAX)],\n",
    "                        \"max_slices\":[[[0,0],[0,0]]for i in range(self.N_TOP_MAX)],\n",
    "                        \"max_imgs\":[self.NUMB_PATH for i in range(self.N_TOP_MAX)],\n",
    "                        \"max_imgs_grad\":[self.NUMB_PATH for i in range(self.N_TOP_MAX)],\n",
    "                        \"actmax_img\":self.NUMB_PATH,\n",
    "                        \"histo_counts_max\":OrderedDict(zip(self.LAB2TITLE.values(),[0] *len(self.LAB2TITLE))),\n",
    "                        \"histo_counts_avg\":OrderedDict(zip(self.LAB2TITLE.values(),[0] *len(self.LAB2TITLE)))\n",
    "                    })\n",
    "            elif (type(lay_info['lay']) == nn.Linear):\n",
    "                    n_input = lay_info['lay'].in_features\n",
    "                    n_output = lay_info['lay'].out_features\n",
    "                    lay_info['n_output'] = n_output\n",
    "                    #lay_info[\"filters\"] = [empty_filter.copy() for i in range(n_output)]\n",
    "            model_info.append(lay_info)\n",
    "            self.model_info = model_info\n",
    "            self.conv_layinfos = [lay_info for lay_info in self.model_info if isinstance(lay_info,nn.Conv2d)]\n",
    "            \n",
    "    def __init_class_counts(self,indx_to_title,src_path,obj):\n",
    "        \"\"\"\n",
    "        create the dictionary which counts the number of images per classes in the dataset\n",
    "        \"\"\"\n",
    "        for subfold in os.listdir(src_path):\n",
    "            subfold_path = os.path.join(src_path,subfold)\n",
    "            count = len([name for name in os.listdir(subfold_path)])\n",
    "            title = indx_to_title[self.CLASS2LAB[subfold]]\n",
    "            obj[title] += count\n",
    "        \n",
    "    def recreate_labels(self,output_path=None):\n",
    "        \"\"\"\n",
    "        recreate the label files wrt to a specific dataset with potentially less classes than the original one. \n",
    "        Useful for smaller computations\n",
    "        \"\"\"\n",
    "        if output_path is None:\n",
    "            output_path = str(Path(self.IMGS_DIR).parent.joinpath('labels2.txt'))\n",
    "        infos = pd.read_csv(self.LABELS_PATH,sep=\" \",header=None)\n",
    "        infos.columns = ['dir_name','label','title']\n",
    "        infos.set_index('dir_name',inplace=True,drop=False)\n",
    "        new_infos= infos.loc[self.dataset.class_to_idx.keys()].copy()\n",
    "        new_infos.label = new_infos.dir_name.map(self.dataset.class_to_idx)\n",
    "        new_infos.drop(columns=['dir_name']).to_csv(output_path,header=None,sep=\" \")\n",
    "        return new_infos\n",
    "        \n",
    "    def save_to_json(self):\n",
    "        model_info2 = deepcopy(self.model_info)\n",
    "        for lay_info in model_info2:\n",
    "            if (isinstance(lay_info['lay'],nn.Conv2d)):\n",
    "                del lay_info['deproj']\n",
    "            del lay_info['lay']\n",
    "        with open(self.JSON_PATH_WRITE, 'w') as fout:\n",
    "            json.dump(model_info2, fout, indent = 2)\n",
    "        print(\"json saving done!\")\n",
    "        \n",
    "    def save_to_dill(self,path):\n",
    "        torch.save(self,path, pickle_module=dill)\n",
    "        print(\"dill saving done!\")\n",
    "        \n",
    "    def load_from_json(self,load_path):\n",
    "        layers = []\n",
    "        with open(load_path, 'r') as fin:\n",
    "            model_info = json.load(fin)\n",
    "        for lay_info,layer in zip(model_info,self.model.features):\n",
    "            lay_info['lay'] = layer\n",
    "            if (isinstance(layer,(nn.Conv2d,nn.MaxPool2d))):\n",
    "                layers.append(layer)\n",
    "            if (isinstance(layer,nn.Conv2d)):\n",
    "                lay_info['deproj'] = Projector(deepcopy(layers),224)\n",
    "        self.model_info = model_info\n",
    "        self.conv_layinfos = [lay_info for lay_info in self.model_info if isinstance(lay_info,nn.Conv2d)]\n",
    "        self.__check_imgs_exist()\n",
    "        print(\"Loading done!\") \n",
    "    \n",
    "    @staticmethod\n",
    "    def load_from_dill(load_path,overwrite=False,alternate_json_path=None):\n",
    "        \"\"\"\n",
    "        load the lurker from a dill (pickle-like) file\n",
    "        Args:\n",
    "            load_path(str): path to the dill file\n",
    "            overwrite(Bool): whether to overwrite the JSON the lurker reads from\n",
    "            alternate_path(str): only valid if overwrite is set to False: specific path to the write json\n",
    "        \"\"\"\n",
    "        assert(not (overwrite and alternate_json_path is not None))\n",
    "        lurker = torch.load(load_path, pickle_module=dill)\n",
    "        if not overwrite:\n",
    "            if alternate_json_path is None:\n",
    "                path = Path(lurker.JSON_PATH_WRITE)\n",
    "                name = path.stem + \"_copy\"\n",
    "                lurker.JSON_PATH_WRITE = str(path.with_name(name).with_suffix(\".json\"))\n",
    "            else:\n",
    "                path = Path(alternate_json_path)\n",
    "                assert(path.is_file() and path.suffix == \".json\")\n",
    "                lurker.JSON_PATH_WRITE = alternate_json_path\n",
    "        lurker.__check_imgs_exist()\n",
    "        print(\"Loading done!\") \n",
    "        return lurker    \n",
    "    \n",
    "    def __check_imgs_exist(self): \n",
    "        \"\"\"\n",
    "        check that all the images in the json file indeed exist and are at the right position\n",
    "        \"\"\"\n",
    "        try:\n",
    "            type_keys = [\"avg_imgs\",\"avg_imgs_grad\",\"max_imgs\",\"max_imgs_grad\"]\n",
    "            for lay_info in self.conv_layinfos:\n",
    "                for filtr in lay_info['filters']:\n",
    "                    for key in type_keys:\n",
    "                        for el in filtr[key]:\n",
    "                            Path(el).resolve(strict=True)\n",
    "                    Path(filtr[\"actmax_img\"]).resolve(strict=True)\n",
    "        except FileNotFoundError as e:\n",
    "            print(\"Non coherent path in the loaded object:{}\".format(e.filename))\n",
    "            \n",
    "    def plot_hist(self,layer_indx,filt_indx,hist_type=\"max\"):\n",
    "        \"\"\"\n",
    "        layer_indx(int): index of the layer\n",
    "        filt_indx(int): index of the filter\n",
    "        hist_type(str): either \"max\" or \"avg\": which hist to plot\n",
    "        \"\"\"\n",
    "        assert(hist_type == \"max\" or hist_type == \"avg\")\n",
    "        lay_info = self.model_info[layer_indx]\n",
    "        assert(isinstance(lay_info['lay'],nn.Conv2d))\n",
    "        filt = lay_info['filters'][filt_indx]\n",
    "        obj = filt['histo_counts_max'] if hist_type == \"max\" else filt['histo_counts_avg']\n",
    "        fig,ax = plt.subplots(1,1,figsize=(10,20))\n",
    "        ax.barh(list(obj.keys())[::-1],list(obj.values())[::-1])\n",
    "\n",
    "\n",
    "            \n",
    "    def __get_filt_path(self,dir_type,layer_name,filter_id):\n",
    "        \"\"\"\n",
    "        return the path to the appropriate folder\n",
    "        \"\"\"\n",
    "        return os.path.join(self.GEN_IMGS_DIR,dir_type,layer_name,str(filter_id))\n",
    "    \n",
    "    def __extract_name(self,img_path,ext='.jpg'):\n",
    "        \"\"\"\n",
    "        extract the name of the imgpath and add the extension\n",
    "        ex:\n",
    "        >>> __extract_name(\"path/to/file.txt\")\n",
    "        return: file.jpg\n",
    "        \"\"\"\n",
    "        jpg_name = img_path.split(\"/\")[-1]\n",
    "        img_name = jpg_name.split(\".\")[0] + ext\n",
    "        return img_name\n",
    "    #Watch out which path you give for the IMGS_PATH\n",
    "\n",
    "    def __sort_filters_spikes(self):\n",
    "        \"\"\"\n",
    "        sorts the spikes and respective paths of the filters inplace\n",
    "        \"\"\"\n",
    "        for lay_info in self.conv_layinfos:\n",
    "            for filtr in lay_info['filters']:\n",
    "                max_indx = np.argsort(filtr[\"max_spikes\"])[::-1]\n",
    "                filtr[\"max_spikes\"] = np.array(filtr[\"max_spikes\"])[max_indx].tolist()\n",
    "                filtr[\"max_imgs\"] = np.array(filtr[\"max_imgs\"])[max_indx].tolist()\n",
    "                filtr[\"max_slices\"] = np.array(filtr[\"max_slices\"])[max_indx].tolist()\n",
    "\n",
    "                avg_indx = np.argsort(filtr[\"avg_spikes\"])[::-1]\n",
    "                filtr[\"avg_spikes\"] = np.array(filtr[\"avg_spikes\"])[avg_indx].tolist()\n",
    "                filtr[\"avg_imgs\"] = np.array(filtr[\"avg_imgs\"])[avg_indx].tolist()\n",
    "\n",
    "    def __reset_histos(self):\n",
    "        \"\"\"\n",
    "        reset the counts for the histograms counts\n",
    "        \"\"\"\n",
    "        for lay_info in self.conv_layinfos:\n",
    "            for filt in lay_info['filters']:\n",
    "                filt['histo_counts_max'] = dict(zip(self.LAB2TITLE.values(),[0] *len(self.LAB2TITLE)))\n",
    "                filt['histo_counts_avg'] = dict(zip(self.LAB2TITLE.values(),[0] *len(self.LAB2TITLE)))\n",
    "    def __normalize_histos(self):\n",
    "        \"\"\"\n",
    "        average the counts of the histograms wrt to the number of samples in the classes of the dataset\n",
    "        \"\"\"\n",
    "        for lay_info in self.conv_layinfos:\n",
    "            for filt in lay_info['filters']:\n",
    "                for key in filt['histo_counts_max'].keys():\n",
    "                    filt['histo_counts_max'][key] /= self.title_counts[key]\n",
    "                for key in filt['histo_counts_avg'].keys():\n",
    "                    filt['histo_counts_avg'][key] /= self.title_counts[key]\n",
    "                filt['histo_counts_max'] = OrderedDict(sorted(filt['histo_counts_max'].items(),key = lambda x: x[1])[::-1])\n",
    "                filt['histo_counts_avg'] =  OrderedDict(sorted(filt['histo_counts_avg'].items(),key = lambda x: x[1])[::-1])\n",
    "                \n",
    "    def compute_avgmax_imgs(self,verbose = False,compute_max=True,compute_avg=True):\n",
    "        \"\"\"\n",
    "        compute the average and max images for all the layers of the model_info such that each filter of each layer knows what are\n",
    "        its favourite images (write down the link to the avg/max images in the json)\n",
    "        \"\"\"\n",
    "        assert(compute_max or compute_avg)\n",
    "        self.__reset_histos()\n",
    "        for j,(datas,labels,paths) in enumerate(self.data_loader):\n",
    "            print(\"Progression update favimgs:{:.2f} %\".format(j/len(self.data_loader) * 100))\n",
    "            for i,lay_info in enumerate(self.model_info):\n",
    "                clear_output(wait=True)\n",
    "                if verbose:\n",
    "                    print(\"AvgMax update:{}/{}:{:.2f} %..\".format(i,len(self.model_info),100*j/ len(data_loader)))\n",
    "\n",
    "                #datas: Batchsize x Numberfilter x Nout x Nout\n",
    "                datas = lay_info['lay'](datas)\n",
    "                if (not isinstance(lay_info['lay'],nn.Conv2d) ):\n",
    "                    continue\n",
    "                if (i >=self.N_LAYERS_DEV and self.DEVELOPMENT):\n",
    "                    break\n",
    "\n",
    "                batch_size = datas.size(0)\n",
    "                filter_nb = datas.size(1)\n",
    "                width = datas.size(3)\n",
    "\n",
    "                #set_trace()\n",
    "                #spikes: Batchsize x Filternumber\n",
    "                max_spikes,max_pos = datas.view([batch_size,filter_nb,-1]).max(dim = 2)\n",
    "                max_rows = max_pos / width\n",
    "                max_cols = max_pos % width\n",
    "\n",
    "                avg_spikes = datas.view([batch_size,filter_nb,-1]).mean(dim = 2)\n",
    "                if compute_max:\n",
    "                    self.__update_filters_max_imgs(lay_info,max_spikes,paths,max_rows,max_cols,labels)\n",
    "                if compute_avg:\n",
    "                    self.__update_filters_avg_imgs(lay_info,avg_spikes,paths,labels)\n",
    "                #save the whole model\n",
    "        self.__normalize_histos()\n",
    "        self.__sort_filters_spikes()\n",
    "        self.__save_cropped()\n",
    "        self.save_to_json()\n",
    "\n",
    "    def __update_filters_max_imgs(self,lay_info,batch_spikes,paths,max_rows,max_cols,labels):\n",
    "        #as many spikes in batch_spikes as there are samples in batch\n",
    "        for spikes,path,label,rows,cols in zip(batch_spikes,paths,labels,max_rows,max_cols):\n",
    "            #at this stage there are as many spike in spikes as there are filters\n",
    "            for k,(filt,spike,row,col) in enumerate(zip(lay_info[\"filters\"],spikes.detach().numpy(),rows,cols)):\n",
    "                #compute the histogram with maximal values\n",
    "                filt[\"histo_counts_max\"][self.LAB2TITLE[label.item()]] += float(spike)\n",
    "                #compute the minimum spike for the filter\n",
    "                min_indx = np.argmin(filt[\"max_spikes\"])\n",
    "                min_spike = min(filt[\"max_spikes\"])\n",
    "                \n",
    "                if (spike > min_spike and not (path in filt[\"max_imgs\"])):\n",
    "                    ((x1,x2),(y1,y2)) = lay_info[\"deproj\"].chain(((row.item(),row.item()),(col.item(),col.item())))\n",
    "                    assert(isinstance(x1,int) and isinstance(x2,int) and isinstance(y1,int) and isinstance(y2,int))\n",
    "                    filt[\"max_slices\"][min_indx] = ((x1,x2),(y1,y2))\n",
    "                    filt[\"max_imgs\"][min_indx] = path\n",
    "                    filt[\"max_spikes\"][min_indx] = float(spike)\n",
    "                    \n",
    "    def __update_filters_avg_imgs(self,lay_info,batch_spikes,paths,labels):\n",
    "        #as many spikes in batch_spikes as there are samples in batch\n",
    "        for spikes,path,label in zip(batch_spikes,paths,labels):\n",
    "            #at this stage there are as many spike in spikes as there are filters\n",
    "            for k,(filt,spike) in enumerate(zip(lay_info[\"filters\"],spikes.detach().numpy())):\n",
    "                #compute the histogram with avg values\n",
    "                filt[\"histo_counts_avg\"][self.LAB2TITLE[label.item()]] += float(spike)\n",
    "                #compute the minimum spike for the filter\n",
    "                min_indx = np.argmin(filt[\"avg_spikes\"])\n",
    "                min_spike = min(filt[\"avg_spikes\"])\n",
    "                if (spike > min_spike and not (path in filt[\"avg_imgs\"])):\n",
    "                    filt[\"avg_imgs\"][min_indx] = path\n",
    "                    filt[\"avg_spikes\"][min_indx] = float(spike)\n",
    "                \n",
    "\n",
    "    def __save_cropped(self,grad = False,verbose=False):\n",
    "        \"\"\"\n",
    "        iterate on the model_info to save a cropped version of the images\n",
    "        Args:\n",
    "            grad(Bool): whether to save the gradients versions\n",
    "        \"\"\"\n",
    "        if grad:\n",
    "            filtrlist = \"max_imgs_grad\" \n",
    "            folder = \"max_act_grads_cropped\"\n",
    "        else:\n",
    "            filtrlist = \"max_imgs\"\n",
    "            folder = \"max_act_cropped\"\n",
    "\n",
    "        for i,lay_info in enumerate(self.conv_layinfos):\n",
    "            clear_output(wait=True)\n",
    "            if verbose:\n",
    "                print(\"Progression:{} %\".format(i/len(conv_layinfos)*100))\n",
    "            for filtr in lay_info['filters']:\n",
    "                for path,slices in zip(filtr[filtrlist],filtr['max_slices']):\n",
    "                    if (path == self.NUMB_PATH):\n",
    "                        continue\n",
    "                    cropped = ToTensor()(Image.open(path))\n",
    "                    ((x1,x2),(y1,y2)) = slices\n",
    "                    cropped = cropped[:,x1:x2+1,y1:y2+1]\n",
    "                    crop_path = self.__get_filt_path(folder,lay_info['name'],filtr['id'])\n",
    "                    file_name = path.split('/')[-1].lower()\n",
    "                    file_path = os.path.join(crop_path,file_name)\n",
    "                    ToPILImage()(cropped).save(file_path) \n",
    "                    \n",
    "    def compute_viz(self,num_imgs_per_class=None,ratio_imgs_per_class=None):\n",
    "        \"\"\"\n",
    "        Compute the filter visualization for all classes\n",
    "        Args:\n",
    "            num_imgs_per_class(int): number of filters to compute the visualization for for each class\n",
    "            ratio_imgs_per_class(float): ratio of filters to compute the visualization for for each class\n",
    "        \"\"\"\n",
    "        checks = [num_imgs_per_class is None , ratio_imgs_per_class is None]\n",
    "        assert(sum(checks)==1 or sum(checks)==0)\n",
    "        for lay_indx,lay_info in self.conv_layinfos:\n",
    "            print(\"Layer {}:\".format(lay_indx))\n",
    "            N = lay_info[\"lay\"].out_channels\n",
    "            indexes = np.arange(N)\n",
    "            np.random.shuffle(indexes)\n",
    "            if checks[0]:\n",
    "                indexes = indexes[:num_imgs_per_class]\n",
    "            elif checks[1]:\n",
    "                lim = int(ratio_imgs_per_class * N)\n",
    "                indexes = indexes[:lim]\n",
    "            self.compute_layer_viz(lay_indx,indexes)                \n",
    "\n",
    "    def compute_layer_viz(self,layer_indx,filter_indexes = None):\n",
    "        \"\"\"\n",
    "        compute  and save the filter maximal activation as an image. Compute it only for filters for which\n",
    "        it has not been computed yet: you need to delete the existing image if you wish for a refresh.\n",
    "        Args:\n",
    "            layer_indx(int): layer to compute the filter for\n",
    "            filter_indexes(list(int)):  list of filter to compute the visualization for\n",
    "        \"\"\"\n",
    "        lay_info = self.model_info[layer_indx]\n",
    "        if filter_indexes is None:\n",
    "            filter_indexes = range(lay_info[\"lay\"].out_channels)\n",
    "        else:\n",
    "            for i in filter_indexes:\n",
    "                if (i >= lay_info[\"lay\"].out_channels or i<0):\n",
    "                    raise IndexError(\"filter_indexes must have lower value than layer output number.\")\n",
    "        layer_name = lay_info[\"name\"]\n",
    "        pre_existing = []\n",
    "        for filt in lay_info[\"filters\"]:\n",
    "            name = \"{}_{}_max_activ.jpg\".format(lay_info['name'],filt['id'])\n",
    "            filt_path = self.__get_filt_path(\"filt_viz\",lay_info[\"name\"],filt[\"id\"])\n",
    "            filt_path = os.path.join(filt_path,name)\n",
    "            try:\n",
    "                f = open(filt_path)\n",
    "                filt[\"actmax_img\"] = filt_path\n",
    "                pre_existing.append(filt[\"id\"])\n",
    "                f.close()\n",
    "            except FileNotFoundError:\n",
    "                pass\n",
    "\n",
    "        filter_indexes = [i for i in filter_indexes if i not in pre_existing]\n",
    "\n",
    "        for j,filt_indx in enumerate(filter_indexes):\n",
    "            print(\"Filter {} / {}\".format(j+1,len(filter_indexes)))\n",
    "            filt = lay_info['filters'][filt_indx]\n",
    "            visualizer = CNNLayerVisualization(model.features, \n",
    "                                               selected_layer=int(lay_info['id']), \n",
    "                                               selected_filter=filt_indx,\n",
    "                                               side_size=self.side_size)\n",
    "            act_max_img = visualizer.visualise_layer_with_hooks()\n",
    "            filt_path = self.__get_filt_path(\"filt_viz\",lay_info['name'],filt['id'])\n",
    "            name = \"{}_{}_max_activ.jpg\".format(lay_info['name'],filt['id'])\n",
    "            filt_path = os.path.join(filt_path,name)\n",
    "            #save the image\n",
    "            ToPILImage()(act_max_img).save(filt_path)\n",
    "            print(\"Vis saved!\")\n",
    "            filt[\"actmax_img\"] = filt_path\n",
    "            self.save_to_json()\n",
    "        print(\"Visualization done!\")\n",
    "        \n",
    "\n",
    "    def compute_grads(self,verbose = False,compute_avg = True,compute_max = True):\n",
    "        \"\"\"\n",
    "        compute the gradients for the fav images of all filters of all layers for the model_info\n",
    "        Args:\n",
    "            model_info (dic): as described above\n",
    "            origin_path (str): path where to store the folders containing the gradient images\n",
    "        \"\"\"\n",
    "        gbp = GuidedBackprop(self.model)\n",
    "        for i,lay_info in enumerate(self.conv_layinfos):\n",
    "            if (i >= self.N_LAYERS_DEV and self.DEVELOPMENT):\n",
    "                break\n",
    "            for j,filt in enumerate(lay_info['filters']):\n",
    "                clear_output(wait=True)\n",
    "                if (self.DEVELOPMENT):\n",
    "                    print(\"Grads Progression:layer{}/{} {}%\".format(i+1,self.N_LAYERS_DEV,j/self.N_FILTERS_DEV*100))\n",
    "                    if (j >=self.N_FILTERS_DEV):\n",
    "                        break\n",
    "                else:\n",
    "                    print(\"Grads Progression:layer{}/{} {}%\".format(i+1,len(self.model_info),j/len(lay_info['filters'])*100))\n",
    "                if compute_avg:\n",
    "                    path = self.__get_filt_path(\"avg_act_grads\",lay_info['name'],filt[\"id\"])\n",
    "                    self.__compute_grads_filt(gbp,filt,path,lay_info['id'],\"avg_imgs\")\n",
    "                if compute_max:\n",
    "                    path = self.__get_filt_path(\"max_act_grads\",lay_info['name'],filt[\"id\"])\n",
    "                    self.__compute_grads_filt(gbp,filt,path,lay_info['id'],\"max_imgs\")\n",
    "                    self.__save_cropped(grad= True)\n",
    "        self.save_to_json()\n",
    "\n",
    "    def __compute_grads_filt(self,gbp,filt,path,lay_id,img_type):\n",
    "        \"\"\"\n",
    "        compute the gradients wrt to the favourite images of a filter filt.\n",
    "        Args:\n",
    "            gbp (GuidedBackprop): fitted on the model\n",
    "            filt (dic): filter from a layer\n",
    "            path (str): path to the folder where to store the gradient images\n",
    "            img_type (str): either \"avg_imgs\" or \"max_imgs\"\n",
    "        \"\"\"\n",
    "        grad_strindx = \"avg_imgs_grad\" if img_type == \"avg_imgs\" else \"max_imgs_grad\"\n",
    "\n",
    "        for i,img_path in enumerate(filt[img_type]):\n",
    "            if (img_path == self.NUMB_PATH):\n",
    "                continue   \n",
    "\n",
    "            #name of the image\n",
    "            img_name = self.__extract_name(img_path,\"_grad.jpg\")\n",
    "            #joined path and imagename\n",
    "            grad_path = os.path.join(path,img_name)\n",
    "\n",
    "            try:\n",
    "                f = open(grad_path)\n",
    "                filt[grad_strindx][i] = grad_path\n",
    "                f.close()\n",
    "                continue\n",
    "            except FileNotFoundError:\n",
    "                pass\n",
    "\n",
    "            image = Image.open(img_path)\n",
    "            image = self.preprocess(image).unsqueeze(0)\n",
    "            image.requires_grad = True\n",
    "            class_name = img_path.split(\"/\")[-1].split(\"_\")[0]\n",
    "            gradient = gbp.generate_gradients(image,self.CLASS2LAB[class_name],lay_id,filt['id'])\n",
    "            #normalization of the gradient\n",
    "            gradient = gradient - gradient.min()\n",
    "            gradient /= gradient.max()\n",
    "            im = ToPILImage()(gradient[0])\n",
    "            im.save(grad_path)\n",
    "            filt[grad_strindx][i] = grad_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg16(pretrained=True)\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.CenterCrop(224), \n",
    "    transforms.ToTensor()\n",
    "    ,transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ML] *",
   "language": "python",
   "name": "conda-env-ML-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
