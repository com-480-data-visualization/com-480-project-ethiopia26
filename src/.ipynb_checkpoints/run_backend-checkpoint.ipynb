{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Torchlurk import Lurk\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from misc_funcs import clean_bw_imgs,sample_imagenet,plot_hist,crop_imgs\n",
    "import jdc\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision.transforms import ToTensor,ToPILImage\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.utils import save_image\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from collections import OrderedDict\n",
    "import pathlib\n",
    "import dill\n",
    "\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "\n",
    "from ImageFolderWithPaths import ImageFolderWithPaths\n",
    "from Projector import Projector\n",
    "\n",
    "#libraries\n",
    "sys.path.insert(1, '../lib/pytorch-cnn-visualizations/src/')\n",
    "from cnn_layer_visualization import CNNLayerVisualization\n",
    "from layer_activation_with_guided_backprop import GuidedBackprop\n",
    "from misc_functions import save_gradient_images\n",
    "from misc_funcs import create_folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At that stage, Download the tinyimagenet dataset on [this link](https://www.kaggle.com/ifigotin/imagenetmini-1000#n01440764_10470.JPEG) and place it in the directory data (s.t the path looks like `data/tinyimagenet/rest_of_path`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the dataset is downloaded, we need to get rid of a few bw images: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progression:100.00%\n",
      "Cropped terminated successfully!\n"
     ]
    }
   ],
   "source": [
    "crop_imgs(\"../data/imagenet-mini/train/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progression:100.00%\n",
      "BW files found:\n",
      "../data/imagenet-mini/train/n03920288/n03920288_3315.JPEG\n",
      "../data/imagenet-mini/train/n03920288/n03920288_3629.JPEG\n",
      "../data/imagenet-mini/train/n03942813/n03942813_1800.JPEG\n",
      "../data/imagenet-mini/train/n02791270/n02791270_16505.JPEG\n",
      "../data/imagenet-mini/train/n02791270/n02791270_23048.JPEG\n",
      "../data/imagenet-mini/train/n02950826/n02950826_11905.JPEG\n",
      "../data/imagenet-mini/train/n02950826/n02950826_13787.JPEG\n",
      "../data/imagenet-mini/train/n02894605/n02894605_26115.JPEG\n",
      "../data/imagenet-mini/train/n03782006/n03782006_37777.JPEG\n",
      "../data/imagenet-mini/train/n04041544/n04041544_1401.JPEG\n",
      "../data/imagenet-mini/train/n02403003/n02403003_656.JPEG\n",
      "../data/imagenet-mini/train/n02109047/n02109047_1579.JPEG\n",
      "../data/imagenet-mini/train/n02109047/n02109047_6125.JPEG\n",
      "../data/imagenet-mini/train/n02787622/n02787622_5870.JPEG\n",
      "../data/imagenet-mini/train/n02787622/n02787622_9908.JPEG\n",
      "../data/imagenet-mini/train/n02102480/n02102480_6584.JPEG\n",
      "../data/imagenet-mini/train/n03063689/n03063689_5020.JPEG\n",
      "../data/imagenet-mini/train/n03063689/n03063689_4678.JPEG\n",
      "../data/imagenet-mini/train/n03063689/n03063689_14711.JPEG\n",
      "../data/imagenet-mini/train/n03063689/n03063689_15384.JPEG\n",
      "../data/imagenet-mini/train/n02110958/n02110958_15441.JPEG\n",
      "../data/imagenet-mini/train/n02124075/n02124075_12703.JPEG\n",
      "../data/imagenet-mini/train/n03271574/n03271574_14752.JPEG\n",
      "../data/imagenet-mini/train/n03271574/n03271574_9789.JPEG\n",
      "../data/imagenet-mini/train/n04067472/n04067472_17256.JPEG\n",
      "../data/imagenet-mini/train/n04067472/n04067472_2454.JPEG\n",
      "../data/imagenet-mini/train/n04099969/n04099969_2722.JPEG\n",
      "../data/imagenet-mini/train/n04099969/n04099969_330.JPEG\n",
      "../data/imagenet-mini/train/n04099969/n04099969_10503.JPEG\n",
      "../data/imagenet-mini/train/n04099969/n04099969_7966.JPEG\n",
      "../data/imagenet-mini/train/n02097298/n02097298_12964.JPEG\n",
      "../data/imagenet-mini/train/n03532672/n03532672_38571.JPEG\n",
      "../data/imagenet-mini/train/n03532672/n03532672_48344.JPEG\n",
      "../data/imagenet-mini/train/n03532672/n03532672_28536.JPEG\n",
      "../data/imagenet-mini/train/n01440764/n01440764_15560.JPEG\n",
      "../data/imagenet-mini/train/n01704323/n01704323_1431.JPEG\n",
      "../data/imagenet-mini/train/n01704323/n01704323_7030.JPEG\n",
      "../data/imagenet-mini/train/n01704323/n01704323_8354.JPEG\n",
      "../data/imagenet-mini/train/n01704323/n01704323_1968.JPEG\n",
      "../data/imagenet-mini/train/n03141823/n03141823_3933.JPEG\n",
      "../data/imagenet-mini/train/n02443484/n02443484_1796.JPEG\n",
      "../data/imagenet-mini/train/n02096585/n02096585_10795.JPEG\n",
      "../data/imagenet-mini/train/n02096585/n02096585_6466.JPEG\n",
      "../data/imagenet-mini/train/n02096585/n02096585_10516.JPEG\n",
      "../data/imagenet-mini/train/n02974003/n02974003_9231.JPEG\n",
      "../data/imagenet-mini/train/n03347037/n03347037_17993.JPEG\n",
      "../data/imagenet-mini/train/n02236044/n02236044_4695.JPEG\n",
      "../data/imagenet-mini/train/n02113712/n02113712_4748.JPEG\n",
      "../data/imagenet-mini/train/n02500267/n02500267_7635.JPEG\n",
      "../data/imagenet-mini/train/n03874293/n03874293_12186.JPEG\n",
      "../data/imagenet-mini/train/n03133878/n03133878_3882.JPEG\n",
      "../data/imagenet-mini/train/n03133878/n03133878_1222.JPEG\n",
      "../data/imagenet-mini/train/n03786901/n03786901_10914.JPEG\n",
      "../data/imagenet-mini/train/n04040759/n04040759_38253.JPEG\n",
      "../data/imagenet-mini/train/n04040759/n04040759_12579.JPEG\n",
      "../data/imagenet-mini/train/n03250847/n03250847_13526.JPEG\n",
      "../data/imagenet-mini/train/n03250847/n03250847_16601.JPEG\n",
      "../data/imagenet-mini/train/n03498962/n03498962_9124.JPEG\n",
      "../data/imagenet-mini/train/n03759954/n03759954_19880.JPEG\n",
      "../data/imagenet-mini/train/n02676566/n02676566_9407.JPEG\n",
      "../data/imagenet-mini/train/n03697007/n03697007_171.JPEG\n",
      "../data/imagenet-mini/train/n03388183/n03388183_13836.JPEG\n",
      "../data/imagenet-mini/train/n03950228/n03950228_11028.JPEG\n",
      "../data/imagenet-mini/train/n03950228/n03950228_11161.JPEG\n",
      "../data/imagenet-mini/train/n15075141/n15075141_10244.JPEG\n",
      "../data/imagenet-mini/train/n15075141/n15075141_3267.JPEG\n",
      "../data/imagenet-mini/train/n04366367/n04366367_3874.JPEG\n",
      "../data/imagenet-mini/train/n04366367/n04366367_11770.JPEG\n",
      "../data/imagenet-mini/train/n04366367/n04366367_34620.JPEG\n",
      "../data/imagenet-mini/train/n03832673/n03832673_220.JPEG\n",
      "../data/imagenet-mini/train/n03832673/n03832673_19442.JPEG\n",
      "../data/imagenet-mini/train/n03832673/n03832673_5334.JPEG\n",
      "../data/imagenet-mini/train/n03642806/n03642806_9700.JPEG\n",
      "../data/imagenet-mini/train/n03642806/n03642806_3515.JPEG\n",
      "../data/imagenet-mini/train/n02814860/n02814860_17864.JPEG\n",
      "../data/imagenet-mini/train/n02988304/n02988304_8210.JPEG\n",
      "../data/imagenet-mini/train/n02112137/n02112137_279.JPEG\n",
      "../data/imagenet-mini/train/n03887697/n03887697_4952.JPEG\n",
      "../data/imagenet-mini/train/n02965783/n02965783_4887.JPEG\n",
      "../data/imagenet-mini/train/n02823428/n02823428_3803.JPEG\n",
      "../data/imagenet-mini/train/n03255030/n03255030_11039.JPEG\n",
      "../data/imagenet-mini/train/n03255030/n03255030_8885.JPEG\n",
      "../data/imagenet-mini/train/n03255030/n03255030_9247.JPEG\n",
      "../data/imagenet-mini/train/n03255030/n03255030_11118.JPEG\n",
      "../data/imagenet-mini/train/n03933933/n03933933_6303.JPEG\n",
      "../data/imagenet-mini/train/n03933933/n03933933_24509.JPEG\n",
      "../data/imagenet-mini/train/n04428191/n04428191_43456.JPEG\n",
      "../data/imagenet-mini/train/n04428191/n04428191_2240.JPEG\n",
      "../data/imagenet-mini/train/n04428191/n04428191_6483.JPEG\n",
      "../data/imagenet-mini/train/n02091244/n02091244_8124.JPEG\n",
      "../data/imagenet-mini/train/n02808440/n02808440_55396.JPEG\n",
      "../data/imagenet-mini/train/n02808440/n02808440_47134.JPEG\n",
      "../data/imagenet-mini/train/n02966687/n02966687_3742.JPEG\n",
      "../data/imagenet-mini/train/n02091831/n02091831_3598.JPEG\n",
      "../data/imagenet-mini/train/n03976467/n03976467_3522.JPEG\n",
      "../data/imagenet-mini/train/n03976467/n03976467_16598.JPEG\n",
      "../data/imagenet-mini/train/n03976467/n03976467_20470.JPEG\n",
      "../data/imagenet-mini/train/n04347754/n04347754_32095.JPEG\n",
      "../data/imagenet-mini/train/n04347754/n04347754_3334.JPEG\n",
      "../data/imagenet-mini/train/n03404251/n03404251_9354.JPEG\n",
      "../data/imagenet-mini/train/n03733281/n03733281_23036.JPEG\n",
      "../data/imagenet-mini/train/n04074963/n04074963_19650.JPEG\n",
      "../data/imagenet-mini/train/n04074963/n04074963_6499.JPEG\n",
      "../data/imagenet-mini/train/n03916031/n03916031_41551.JPEG\n",
      "../data/imagenet-mini/train/n04392985/n04392985_2489.JPEG\n",
      "../data/imagenet-mini/train/n04392985/n04392985_4047.JPEG\n",
      "../data/imagenet-mini/train/n03998194/n03998194_6751.JPEG\n",
      "../data/imagenet-mini/train/n04515003/n04515003_32327.JPEG\n",
      "../data/imagenet-mini/train/n04515003/n04515003_10380.JPEG\n",
      "../data/imagenet-mini/train/n02071294/n02071294_6873.JPEG\n",
      "../data/imagenet-mini/train/n03794056/n03794056_13949.JPEG\n",
      "../data/imagenet-mini/train/n03794056/n03794056_10172.JPEG\n",
      "../data/imagenet-mini/train/n03794056/n03794056_10490.JPEG\n",
      "../data/imagenet-mini/train/n04507155/n04507155_14941.JPEG\n",
      "../data/imagenet-mini/train/n04090263/n04090263_15504.JPEG\n",
      "../data/imagenet-mini/train/n02002556/n02002556_5205.JPEG\n",
      "../data/imagenet-mini/train/n02088238/n02088238_1485.JPEG\n",
      "../data/imagenet-mini/train/n02092002/n02092002_12862.JPEG\n",
      "../data/imagenet-mini/train/n02883205/n02883205_60864.JPEG\n",
      "../data/imagenet-mini/train/n02883205/n02883205_2488.JPEG\n",
      "../data/imagenet-mini/train/n02883205/n02883205_16367.JPEG\n",
      "../data/imagenet-mini/train/n02883205/n02883205_16443.JPEG\n",
      "../data/imagenet-mini/train/n02883205/n02883205_23760.JPEG\n",
      "../data/imagenet-mini/train/n02795169/n02795169_11492.JPEG\n",
      "../data/imagenet-mini/train/n02795169/n02795169_7453.JPEG\n",
      "../data/imagenet-mini/train/n03773504/n03773504_23078.JPEG\n",
      "../data/imagenet-mini/train/n03773504/n03773504_25680.JPEG\n",
      "../data/imagenet-mini/train/n04482393/n04482393_3891.JPEG\n",
      "../data/imagenet-mini/train/n02930766/n02930766_20313.JPEG\n",
      "../data/imagenet-mini/train/n04296562/n04296562_18979.JPEG\n",
      "../data/imagenet-mini/train/n02108915/n02108915_6894.JPEG\n",
      "../data/imagenet-mini/train/n03085013/n03085013_5430.JPEG\n",
      "../data/imagenet-mini/train/n03085013/n03085013_20901.JPEG\n",
      "../data/imagenet-mini/train/n03085013/n03085013_22945.JPEG\n",
      "../data/imagenet-mini/train/n03085013/n03085013_12140.JPEG\n",
      "../data/imagenet-mini/train/n03085013/n03085013_21506.JPEG\n",
      "../data/imagenet-mini/train/n03085013/n03085013_23775.JPEG\n",
      "../data/imagenet-mini/train/n04591157/n04591157_576.JPEG\n",
      "../data/imagenet-mini/train/n02328150/n02328150_1797.JPEG\n",
      "../data/imagenet-mini/train/n02791124/n02791124_1928.JPEG\n",
      "../data/imagenet-mini/train/n02791124/n02791124_6387.JPEG\n",
      "../data/imagenet-mini/train/n04238763/n04238763_22437.JPEG\n",
      "../data/imagenet-mini/train/n03763968/n03763968_6975.JPEG\n",
      "../data/imagenet-mini/train/n03062245/n03062245_4527.JPEG\n",
      "../data/imagenet-mini/train/n04141076/n04141076_43949.JPEG\n",
      "../data/imagenet-mini/train/n04141076/n04141076_75558.JPEG\n",
      "../data/imagenet-mini/train/n04141076/n04141076_71154.JPEG\n",
      "../data/imagenet-mini/train/n04141076/n04141076_73894.JPEG\n",
      "../data/imagenet-mini/train/n04447861/n04447861_3339.JPEG\n",
      "../data/imagenet-mini/train/n03376595/n03376595_6525.JPEG\n",
      "../data/imagenet-mini/train/n04023962/n04023962_9274.JPEG\n",
      "../data/imagenet-mini/train/n04023962/n04023962_37636.JPEG\n",
      "../data/imagenet-mini/train/n04023962/n04023962_50943.JPEG\n",
      "../data/imagenet-mini/train/n03793489/n03793489_10431.JPEG\n",
      "../data/imagenet-mini/train/n04070727/n04070727_39231.JPEG\n",
      "../data/imagenet-mini/train/n04070727/n04070727_60011.JPEG\n",
      "../data/imagenet-mini/train/n02120505/n02120505_15958.JPEG\n",
      "../data/imagenet-mini/train/n02483362/n02483362_6436.JPEG\n",
      "../data/imagenet-mini/train/n04442312/n04442312_14092.JPEG\n",
      "../data/imagenet-mini/train/n04442312/n04442312_11526.JPEG\n",
      "../data/imagenet-mini/train/n03065424/n03065424_17272.JPEG\n",
      "../data/imagenet-mini/train/n03065424/n03065424_68951.JPEG\n",
      "../data/imagenet-mini/train/n03924679/n03924679_10873.JPEG\n",
      "../data/imagenet-mini/train/n02892767/n02892767_4201.JPEG\n",
      "../data/imagenet-mini/train/n02107312/n02107312_2048.JPEG\n",
      "../data/imagenet-mini/train/n04590129/n04590129_22609.JPEG\n",
      "../data/imagenet-mini/train/n04590129/n04590129_12864.JPEG\n",
      "../data/imagenet-mini/train/n04590129/n04590129_8578.JPEG\n",
      "../data/imagenet-mini/train/n04590129/n04590129_37963.JPEG\n",
      "../data/imagenet-mini/train/n07753592/n07753592_9565.JPEG\n",
      "../data/imagenet-mini/train/n02107142/n02107142_52349.JPEG\n",
      "../data/imagenet-mini/train/n02110627/n02110627_22516.JPEG\n",
      "../data/imagenet-mini/train/n02088466/n02088466_12216.JPEG\n",
      "../data/imagenet-mini/train/n02088466/n02088466_11132.JPEG\n",
      "../data/imagenet-mini/train/n03721384/n03721384_1709.JPEG\n",
      "../data/imagenet-mini/train/n03220513/n03220513_4782.JPEG\n",
      "../data/imagenet-mini/train/n02837789/n02837789_21447.JPEG\n",
      "../data/imagenet-mini/train/n02837789/n02837789_23422.JPEG\n",
      "../data/imagenet-mini/train/n02111500/n02111500_7146.JPEG\n",
      "../data/imagenet-mini/train/n02793495/n02793495_9539.JPEG\n",
      "../data/imagenet-mini/train/n02793495/n02793495_4609.JPEG\n",
      "../data/imagenet-mini/train/n03891251/n03891251_2898.JPEG\n",
      "../data/imagenet-mini/train/n03891251/n03891251_3947.JPEG\n",
      "../data/imagenet-mini/train/n03891251/n03891251_5637.JPEG\n",
      "../data/imagenet-mini/train/n03891251/n03891251_3383.JPEG\n",
      "../data/imagenet-mini/train/n04286575/n04286575_4871.JPEG\n",
      "../data/imagenet-mini/train/n02992529/n02992529_21092.JPEG\n",
      "../data/imagenet-mini/train/n02992529/n02992529_60654.JPEG\n",
      "../data/imagenet-mini/train/n02992529/n02992529_3308.JPEG\n",
      "../data/imagenet-mini/train/n04486054/n04486054_8908.JPEG\n",
      "../data/imagenet-mini/train/n03372029/n03372029_44161.JPEG\n",
      "../data/imagenet-mini/train/n03372029/n03372029_41945.JPEG\n",
      "../data/imagenet-mini/train/n04037443/n04037443_8697.JPEG\n",
      "../data/imagenet-mini/train/n04037443/n04037443_22059.JPEG\n",
      "../data/imagenet-mini/train/n03838899/n03838899_16491.JPEG\n",
      "../data/imagenet-mini/train/n03838899/n03838899_31104.JPEG\n",
      "../data/imagenet-mini/train/n04606251/n04606251_32516.JPEG\n",
      "../data/imagenet-mini/train/n03457902/n03457902_6713.JPEG\n",
      "../data/imagenet-mini/train/n07930864/n07930864_10538.JPEG\n",
      "../data/imagenet-mini/train/n07930864/n07930864_30821.JPEG\n",
      "../data/imagenet-mini/train/n03954731/n03954731_15587.JPEG\n",
      "../data/imagenet-mini/train/n01930112/n01930112_9652.JPEG\n",
      "../data/imagenet-mini/train/n01930112/n01930112_4440.JPEG\n",
      "../data/imagenet-mini/train/n01930112/n01930112_13988.JPEG\n",
      "../data/imagenet-mini/train/n01930112/n01930112_7379.JPEG\n",
      "../data/imagenet-mini/train/n01930112/n01930112_14916.JPEG\n",
      "../data/imagenet-mini/train/n04208210/n04208210_28386.JPEG\n",
      "../data/imagenet-mini/train/n04258138/n04258138_5172.JPEG\n",
      "../data/imagenet-mini/train/n04332243/n04332243_31816.JPEG\n",
      "../data/imagenet-mini/train/n02105056/n02105056_3683.JPEG\n",
      "../data/imagenet-mini/train/n02105056/n02105056_11069.JPEG\n",
      "../data/imagenet-mini/train/n02105056/n02105056_289.JPEG\n",
      "../data/imagenet-mini/train/n02692877/n02692877_32831.JPEG\n",
      "../data/imagenet-mini/train/n02692877/n02692877_18298.JPEG\n",
      "../data/imagenet-mini/train/n02692877/n02692877_5920.JPEG\n",
      "../data/imagenet-mini/train/n02692877/n02692877_5858.JPEG\n",
      "../data/imagenet-mini/train/n02692877/n02692877_6627.JPEG\n",
      "../data/imagenet-mini/train/n02692877/n02692877_6368.JPEG\n",
      "../data/imagenet-mini/train/n02692877/n02692877_3502.JPEG\n",
      "../data/imagenet-mini/train/n02692877/n02692877_3725.JPEG\n",
      "../data/imagenet-mini/train/n02692877/n02692877_25356.JPEG\n",
      "../data/imagenet-mini/train/n02093754/n02093754_6541.JPEG\n",
      "../data/imagenet-mini/train/n01491361/n01491361_5388.JPEG\n",
      "../data/imagenet-mini/train/n01491361/n01491361_4245.JPEG\n",
      "../data/imagenet-mini/train/n03538406/n03538406_3638.JPEG\n",
      "../data/imagenet-mini/train/n04467665/n04467665_7988.JPEG\n",
      "../data/imagenet-mini/train/n04553703/n04553703_18609.JPEG\n",
      "../data/imagenet-mini/train/n04553703/n04553703_34716.JPEG\n",
      "../data/imagenet-mini/train/n01795545/n01795545_13257.JPEG\n",
      "../data/imagenet-mini/train/n04612504/n04612504_364.JPEG\n",
      "../data/imagenet-mini/train/n03595614/n03595614_7821.JPEG\n",
      "../data/imagenet-mini/train/n03657121/n03657121_18041.JPEG\n",
      "../data/imagenet-mini/train/n03657121/n03657121_470.JPEG\n",
      "../data/imagenet-mini/train/n03657121/n03657121_7288.JPEG\n",
      "../data/imagenet-mini/train/n03657121/n03657121_41088.JPEG\n",
      "../data/imagenet-mini/train/n04081281/n04081281_4577.JPEG\n",
      "../data/imagenet-mini/train/n02095889/n02095889_9201.JPEG\n",
      "../data/imagenet-mini/train/n02095889/n02095889_5132.JPEG\n",
      "../data/imagenet-mini/train/n03895866/n03895866_127963.JPEG\n",
      "../data/imagenet-mini/train/n03895866/n03895866_94175.JPEG\n",
      "../data/imagenet-mini/train/n03895866/n03895866_137050.JPEG\n",
      "../data/imagenet-mini/train/n03110669/n03110669_162283.JPEG\n",
      "../data/imagenet-mini/train/n03110669/n03110669_85296.JPEG\n",
      "../data/imagenet-mini/train/n03110669/n03110669_72318.JPEG\n",
      "../data/imagenet-mini/train/n03110669/n03110669_112169.JPEG\n",
      "../data/imagenet-mini/train/n04153751/n04153751_3405.JPEG\n",
      "../data/imagenet-mini/train/n04153751/n04153751_10444.JPEG\n",
      "../data/imagenet-mini/train/n02669723/n02669723_2185.JPEG\n",
      "../data/imagenet-mini/train/n09428293/n09428293_46398.JPEG\n",
      "../data/imagenet-mini/train/n04532670/n04532670_15008.JPEG\n",
      "../data/imagenet-mini/train/n04532670/n04532670_10007.JPEG\n",
      "../data/imagenet-mini/train/n04532670/n04532670_32887.JPEG\n",
      "../data/imagenet-mini/train/n04532670/n04532670_18431.JPEG\n",
      "../data/imagenet-mini/train/n03908714/n03908714_105.JPEG\n",
      "../data/imagenet-mini/train/n03908714/n03908714_4058.JPEG\n",
      "../data/imagenet-mini/train/n03908714/n03908714_1861.JPEG\n",
      "../data/imagenet-mini/train/n03908714/n03908714_3926.JPEG\n",
      "../data/imagenet-mini/train/n03908714/n03908714_637.JPEG\n",
      "../data/imagenet-mini/train/n03443371/n03443371_11660.JPEG\n",
      "../data/imagenet-mini/train/n03961711/n03961711_1738.JPEG\n",
      "../data/imagenet-mini/train/n03891332/n03891332_483.JPEG\n",
      "../data/imagenet-mini/train/n03891332/n03891332_4026.JPEG\n",
      "../data/imagenet-mini/train/n03673027/n03673027_22831.JPEG\n",
      "../data/imagenet-mini/train/n02951585/n02951585_17058.JPEG\n",
      "../data/imagenet-mini/train/n02951585/n02951585_91.JPEG\n",
      "../data/imagenet-mini/train/n02110341/n02110341_14123.JPEG\n",
      "../data/imagenet-mini/train/n04330267/n04330267_16564.JPEG\n",
      "../data/imagenet-mini/train/n04330267/n04330267_18079.JPEG\n",
      "../data/imagenet-mini/train/n02092339/n02092339_6110.JPEG\n",
      "../data/imagenet-mini/train/n02092339/n02092339_5116.JPEG\n",
      "../data/imagenet-mini/train/n02092339/n02092339_6429.JPEG\n",
      "../data/imagenet-mini/train/n03476991/n03476991_29558.JPEG\n",
      "../data/imagenet-mini/train/n03476991/n03476991_27682.JPEG\n",
      "../data/imagenet-mini/train/n03452741/n03452741_11213.JPEG\n",
      "../data/imagenet-mini/train/n04204238/n04204238_7491.JPEG\n",
      "../data/imagenet-mini/train/n03874599/n03874599_2951.JPEG\n",
      "../data/imagenet-mini/train/n02097047/n02097047_2545.JPEG\n",
      "../data/imagenet-mini/train/n03180011/n03180011_10259.JPEG\n",
      "../data/imagenet-mini/train/n04465501/n04465501_1377.JPEG\n",
      "../data/imagenet-mini/train/n04465501/n04465501_3331.JPEG\n",
      "../data/imagenet-mini/train/n03884397/n03884397_8436.JPEG\n",
      "../data/imagenet-mini/train/n03884397/n03884397_5419.JPEG\n",
      "../data/imagenet-mini/train/n03630383/n03630383_3798.JPEG\n",
      "../data/imagenet-mini/train/n02093647/n02093647_8044.JPEG\n",
      "../data/imagenet-mini/train/n03394916/n03394916_7045.JPEG\n",
      "../data/imagenet-mini/train/n04589890/n04589890_2205.JPEG\n",
      "../data/imagenet-mini/train/n04589890/n04589890_9771.JPEG\n",
      "../data/imagenet-mini/train/n03124043/n03124043_2249.JPEG\n",
      "../data/imagenet-mini/train/n03017168/n03017168_18051.JPEG\n",
      "../data/imagenet-mini/train/n03017168/n03017168_38025.JPEG\n",
      "../data/imagenet-mini/train/n03017168/n03017168_33511.JPEG\n",
      "../data/imagenet-mini/train/n02408429/n02408429_11593.JPEG\n",
      "../data/imagenet-mini/train/n02859443/n02859443_18078.JPEG\n",
      "../data/imagenet-mini/train/n02085620/n02085620_4629.JPEG\n",
      "../data/imagenet-mini/train/n02085620/n02085620_4210.JPEG\n",
      "../data/imagenet-mini/train/n02085620/n02085620_1194.JPEG\n",
      "../data/imagenet-mini/train/n02112706/n02112706_2856.JPEG\n",
      "../data/imagenet-mini/train/n04370456/n04370456_11533.JPEG\n",
      "../data/imagenet-mini/train/n02979186/n02979186_1587.JPEG\n",
      "../data/imagenet-mini/train/n03445777/n03445777_8971.JPEG\n",
      "../data/imagenet-mini/train/n03445777/n03445777_5325.JPEG\n",
      "../data/imagenet-mini/train/n01990800/n01990800_16602.JPEG\n",
      "../data/imagenet-mini/train/n04548280/n04548280_5424.JPEG\n",
      "../data/imagenet-mini/train/n02128925/n02128925_3789.JPEG\n",
      "../data/imagenet-mini/train/n03958227/n03958227_4724.JPEG\n",
      "../data/imagenet-mini/train/n03109150/n03109150_5636.JPEG\n",
      "../data/imagenet-mini/train/n03109150/n03109150_25112.JPEG\n",
      "../data/imagenet-mini/train/n07802026/n07802026_152.JPEG\n",
      "../data/imagenet-mini/train/n07802026/n07802026_20020.JPEG\n",
      "../data/imagenet-mini/train/n07802026/n07802026_17453.JPEG\n",
      "../data/imagenet-mini/train/n04005630/n04005630_95489.JPEG\n",
      "../data/imagenet-mini/train/n03804744/n03804744_10763.JPEG\n",
      "../data/imagenet-mini/train/n02089078/n02089078_2638.JPEG\n",
      "../data/imagenet-mini/train/n02481823/n02481823_14519.JPEG\n",
      "../data/imagenet-mini/train/n02481823/n02481823_3990.JPEG\n",
      "../data/imagenet-mini/train/n02481823/n02481823_1191.JPEG\n",
      "../data/imagenet-mini/train/n02481823/n02481823_17637.JPEG\n",
      "../data/imagenet-mini/train/n04259630/n04259630_11609.JPEG\n",
      "../data/imagenet-mini/train/n02794156/n02794156_19363.JPEG\n",
      "../data/imagenet-mini/train/n02794156/n02794156_10156.JPEG\n",
      "../data/imagenet-mini/train/n02794156/n02794156_1916.JPEG\n",
      "../data/imagenet-mini/train/n04147183/n04147183_13979.JPEG\n",
      "../data/imagenet-mini/train/n02916936/n02916936_9535.JPEG\n",
      "../data/imagenet-mini/train/n02916936/n02916936_1445.JPEG\n",
      "../data/imagenet-mini/train/n03868863/n03868863_4734.JPEG\n",
      "../data/imagenet-mini/train/n03868863/n03868863_132.JPEG\n",
      "../data/imagenet-mini/train/n03868863/n03868863_6703.JPEG\n",
      "../data/imagenet-mini/train/n04204347/n04204347_7406.JPEG\n",
      "../data/imagenet-mini/train/n01514859/n01514859_9725.JPEG\n",
      "../data/imagenet-mini/train/n04443257/n04443257_41924.JPEG\n",
      "../data/imagenet-mini/train/n04443257/n04443257_20359.JPEG\n",
      "../data/imagenet-mini/train/n04009552/n04009552_2159.JPEG\n",
      "../data/imagenet-mini/train/n03873416/n03873416_4377.JPEG\n",
      "../data/imagenet-mini/train/n03272562/n03272562_7870.JPEG\n",
      "../data/imagenet-mini/train/n03127925/n03127925_3988.JPEG\n",
      "../data/imagenet-mini/train/n02105641/n02105641_3786.JPEG\n",
      "../data/imagenet-mini/train/n02111889/n02111889_3691.JPEG\n",
      "../data/imagenet-mini/train/n02708093/n02708093_304.JPEG\n",
      "../data/imagenet-mini/train/n02708093/n02708093_3206.JPEG\n",
      "../data/imagenet-mini/train/n04254680/n04254680_7339.JPEG\n",
      "../data/imagenet-mini/train/n03743016/n03743016_14769.JPEG\n",
      "../data/imagenet-mini/train/n03743016/n03743016_4320.JPEG\n",
      "../data/imagenet-mini/train/n04562935/n04562935_6426.JPEG\n",
      "../data/imagenet-mini/train/n04118776/n04118776_68075.JPEG\n",
      "../data/imagenet-mini/train/n04118776/n04118776_3546.JPEG\n",
      "../data/imagenet-mini/train/n02091134/n02091134_1526.JPEG\n",
      "../data/imagenet-mini/train/n04458633/n04458633_3571.JPEG\n",
      "../data/imagenet-mini/train/n04458633/n04458633_4746.JPEG\n",
      "../data/imagenet-mini/train/n03344393/n03344393_6191.JPEG\n",
      "../data/imagenet-mini/train/n02999410/n02999410_10081.JPEG\n",
      "../data/imagenet-mini/train/n02999410/n02999410_19414.JPEG\n",
      "../data/imagenet-mini/train/n02999410/n02999410_8597.JPEG\n",
      "../data/imagenet-mini/train/n02999410/n02999410_17559.JPEG\n",
      "../data/imagenet-mini/train/n02105505/n02105505_2467.JPEG\n",
      "../data/imagenet-mini/train/n02105505/n02105505_5898.JPEG\n",
      "../data/imagenet-mini/train/n04525305/n04525305_4072.JPEG\n",
      "../data/imagenet-mini/train/n03467068/n03467068_8691.JPEG\n",
      "../data/imagenet-mini/train/n03467068/n03467068_10035.JPEG\n",
      "../data/imagenet-mini/train/n03467068/n03467068_8800.JPEG\n",
      "../data/imagenet-mini/train/n04008634/n04008634_25354.JPEG\n",
      "../data/imagenet-mini/train/n04008634/n04008634_18231.JPEG\n",
      "../data/imagenet-mini/train/n04069434/n04069434_21934.JPEG\n",
      "../data/imagenet-mini/train/n04069434/n04069434_4001.JPEG\n",
      "../data/imagenet-mini/train/n04069434/n04069434_11503.JPEG\n",
      "../data/imagenet-mini/train/n02488291/n02488291_1558.JPEG\n",
      "../data/imagenet-mini/train/n02488291/n02488291_1510.JPEG\n",
      "../data/imagenet-mini/train/n04263257/n04263257_1946.JPEG\n",
      "../data/imagenet-mini/train/n03888605/n03888605_36989.JPEG\n",
      "../data/imagenet-mini/train/n04505470/n04505470_5154.JPEG\n",
      "../data/imagenet-mini/train/n04505470/n04505470_2769.JPEG\n",
      "../data/imagenet-mini/train/n03992509/n03992509_1708.JPEG\n",
      "../data/imagenet-mini/train/n03992509/n03992509_14593.JPEG\n",
      "../data/imagenet-mini/train/n03992509/n03992509_8228.JPEG\n",
      "../data/imagenet-mini/train/n03992509/n03992509_874.JPEG\n",
      "../data/imagenet-mini/train/n03658185/n03658185_4260.JPEG\n",
      "../data/imagenet-mini/train/n02860847/n02860847_6819.JPEG\n",
      "../data/imagenet-mini/train/n02860847/n02860847_29748.JPEG\n",
      "../data/imagenet-mini/train/n02099267/n02099267_512.JPEG\n",
      "../data/imagenet-mini/train/n03982430/n03982430_27117.JPEG\n",
      "../data/imagenet-mini/train/n04317175/n04317175_6652.JPEG\n",
      "../data/imagenet-mini/train/n04536866/n04536866_3282.JPEG\n",
      "../data/imagenet-mini/train/n04536866/n04536866_20544.JPEG\n",
      "../data/imagenet-mini/train/n04536866/n04536866_3629.JPEG\n",
      "../data/imagenet-mini/train/n04536866/n04536866_12210.JPEG\n",
      "../data/imagenet-mini/train/n04536866/n04536866_12630.JPEG\n",
      "../data/imagenet-mini/train/n02749479/n02749479_89.JPEG\n",
      "../data/imagenet-mini/train/n02749479/n02749479_29157.JPEG\n",
      "../data/imagenet-mini/train/n02749479/n02749479_4779.JPEG\n",
      "../data/imagenet-mini/train/n02749479/n02749479_932.JPEG\n",
      "../data/imagenet-mini/train/n03075370/n03075370_2458.JPEG\n",
      "../data/imagenet-mini/train/n03075370/n03075370_9413.JPEG\n",
      "../data/imagenet-mini/train/n03483316/n03483316_11347.JPEG\n",
      "../data/imagenet-mini/train/n03483316/n03483316_21775.JPEG\n",
      "../data/imagenet-mini/train/n04131690/n04131690_8589.JPEG\n",
      "../data/imagenet-mini/train/n02879718/n02879718_30188.JPEG\n",
      "../data/imagenet-mini/train/n03000134/n03000134_4747.JPEG\n",
      "../data/imagenet-mini/train/n03000134/n03000134_2546.JPEG\n",
      "../data/imagenet-mini/train/n03000134/n03000134_1753.JPEG\n",
      "../data/imagenet-mini/train/n03000134/n03000134_14.JPEG\n",
      "../data/imagenet-mini/train/n02895154/n02895154_9919.JPEG\n",
      "../data/imagenet-mini/train/n03902125/n03902125_21133.JPEG\n",
      "../data/imagenet-mini/train/n02093859/n02093859_4345.JPEG\n",
      "../data/imagenet-mini/train/n04200800/n04200800_38142.JPEG\n",
      "../data/imagenet-mini/train/n03661043/n03661043_7787.JPEG\n",
      "../data/imagenet-mini/train/n04209239/n04209239_11024.JPEG\n",
      "../data/imagenet-mini/train/n04209239/n04209239_8143.JPEG\n",
      "../data/imagenet-mini/train/n03424325/n03424325_23753.JPEG\n",
      "../data/imagenet-mini/train/n03424325/n03424325_5687.JPEG\n",
      "../data/imagenet-mini/train/n03602883/n03602883_11170.JPEG\n",
      "../data/imagenet-mini/train/n02091467/n02091467_4823.JPEG\n",
      "../data/imagenet-mini/train/n02091467/n02091467_12614.JPEG\n",
      "../data/imagenet-mini/train/n04127249/n04127249_2853.JPEG\n",
      "../data/imagenet-mini/train/n03495258/n03495258_9193.JPEG\n",
      "../data/imagenet-mini/train/n03495258/n03495258_16828.JPEG\n",
      "../data/imagenet-mini/train/n03495258/n03495258_25470.JPEG\n",
      "../data/imagenet-mini/train/n03970156/n03970156_28533.JPEG\n",
      "../data/imagenet-mini/train/n02391049/n02391049_1508.JPEG\n",
      "../data/imagenet-mini/train/n03930313/n03930313_474.JPEG\n",
      "../data/imagenet-mini/train/n02085936/n02085936_14974.JPEG\n",
      "../data/imagenet-mini/train/n03777754/n03777754_2785.JPEG\n",
      "../data/imagenet-mini/train/n02978881/n02978881_607.JPEG\n",
      "../data/imagenet-mini/train/n02978881/n02978881_43638.JPEG\n",
      "../data/imagenet-mini/train/n02978881/n02978881_12420.JPEG\n",
      "../data/imagenet-mini/train/n02978881/n02978881_12824.JPEG\n",
      "../data/imagenet-mini/train/n01494475/n01494475_4148.JPEG\n",
      "../data/imagenet-mini/train/n03825788/n03825788_6706.JPEG\n",
      "../data/imagenet-mini/train/n03494278/n03494278_38369.JPEG\n",
      "../data/imagenet-mini/train/n03494278/n03494278_34652.JPEG\n",
      "../data/imagenet-mini/train/n03633091/n03633091_12244.JPEG\n",
      "../data/imagenet-mini/train/n04509417/n04509417_4949.JPEG\n",
      "../data/imagenet-mini/train/n04509417/n04509417_6017.JPEG\n",
      "../data/imagenet-mini/train/n07920052/n07920052_599.JPEG\n",
      "../data/imagenet-mini/train/n01737021/n01737021_429.JPEG\n",
      "../data/imagenet-mini/train/n03599486/n03599486_13087.JPEG\n",
      "../data/imagenet-mini/train/n04554684/n04554684_4076.JPEG\n",
      "../data/imagenet-mini/train/n02939185/n02939185_21836.JPEG\n",
      "../data/imagenet-mini/train/n02104029/n02104029_7622.JPEG\n",
      "../data/imagenet-mini/train/n04328186/n04328186_48308.JPEG\n",
      "../data/imagenet-mini/train/n04328186/n04328186_4766.JPEG\n",
      "../data/imagenet-mini/train/n04328186/n04328186_8361.JPEG\n",
      "../data/imagenet-mini/train/n03692522/n03692522_12000.JPEG\n",
      "../data/imagenet-mini/train/n03692522/n03692522_4410.JPEG\n",
      "../data/imagenet-mini/train/n03692522/n03692522_11536.JPEG\n",
      "../data/imagenet-mini/train/n04019541/n04019541_8604.JPEG\n",
      "../data/imagenet-mini/train/n04356056/n04356056_60202.JPEG\n",
      "../data/imagenet-mini/train/n04356056/n04356056_2540.JPEG\n",
      "../data/imagenet-mini/train/n06785654/n06785654_3588.JPEG\n",
      "../data/imagenet-mini/train/n06785654/n06785654_11253.JPEG\n",
      "../data/imagenet-mini/train/n06785654/n06785654_12009.JPEG\n",
      "../data/imagenet-mini/train/n06785654/n06785654_3680.JPEG\n",
      "../data/imagenet-mini/train/n06785654/n06785654_3346.JPEG\n",
      "../data/imagenet-mini/train/n06785654/n06785654_2319.JPEG\n",
      "../data/imagenet-mini/train/n04336792/n04336792_19464.JPEG\n",
      "../data/imagenet-mini/train/n04336792/n04336792_42773.JPEG\n",
      "../data/imagenet-mini/train/n04336792/n04336792_18677.JPEG\n",
      "../data/imagenet-mini/train/n04162706/n04162706_46463.JPEG\n",
      "../data/imagenet-mini/train/n04162706/n04162706_18311.JPEG\n",
      "../data/imagenet-mini/train/n04162706/n04162706_10402.JPEG\n",
      "../data/imagenet-mini/train/n03903868/n03903868_50629.JPEG\n",
      "../data/imagenet-mini/train/n04141975/n04141975_35800.JPEG\n",
      "../data/imagenet-mini/train/n04141975/n04141975_15.JPEG\n",
      "../data/imagenet-mini/train/n04141975/n04141975_11858.JPEG\n",
      "../data/imagenet-mini/train/n04141975/n04141975_34852.JPEG\n",
      "../data/imagenet-mini/train/n04154565/n04154565_25237.JPEG\n",
      "../data/imagenet-mini/train/n04423845/n04423845_3482.JPEG\n",
      "../data/imagenet-mini/train/n04423845/n04423845_10470.JPEG\n",
      "../data/imagenet-mini/train/n04487081/n04487081_11484.JPEG\n",
      "../data/imagenet-mini/train/n04560804/n04560804_10316.JPEG\n",
      "../data/imagenet-mini/train/n04560804/n04560804_13629.JPEG\n",
      "../data/imagenet-mini/train/n04560804/n04560804_4935.JPEG\n",
      "../data/imagenet-mini/train/n04039381/n04039381_19558.JPEG\n",
      "../data/imagenet-mini/train/n02113624/n02113624_6418.JPEG\n",
      "../data/imagenet-mini/train/n02687172/n02687172_34236.JPEG\n",
      "../data/imagenet-mini/train/n02992211/n02992211_26518.JPEG\n",
      "../data/imagenet-mini/train/n02992211/n02992211_37588.JPEG\n",
      "../data/imagenet-mini/train/n02992211/n02992211_30118.JPEG\n",
      "../data/imagenet-mini/train/n02992211/n02992211_33045.JPEG\n",
      "../data/imagenet-mini/train/n02992211/n02992211_34104.JPEG\n",
      "../data/imagenet-mini/train/n02992211/n02992211_33025.JPEG\n",
      "../data/imagenet-mini/train/n02992211/n02992211_37010.JPEG\n",
      "../data/imagenet-mini/train/n03929660/n03929660_969.JPEG\n",
      "../data/imagenet-mini/train/n03929660/n03929660_20053.JPEG\n",
      "../data/imagenet-mini/train/n03929660/n03929660_2693.JPEG\n",
      "../data/imagenet-mini/train/n03929660/n03929660_56931.JPEG\n",
      "../data/imagenet-mini/train/n03929660/n03929660_13396.JPEG\n",
      "../data/imagenet-mini/train/n03297495/n03297495_628.JPEG\n",
      "../data/imagenet-mini/train/n04417672/n04417672_13599.JPEG\n",
      "../data/imagenet-mini/train/n03777568/n03777568_1037.JPEG\n",
      "../data/imagenet-mini/train/n03777568/n03777568_17270.JPEG\n",
      "../data/imagenet-mini/train/n04461696/n04461696_2394.JPEG\n",
      "../data/imagenet-mini/train/n04326547/n04326547_12133.JPEG\n",
      "../data/imagenet-mini/train/n02013706/n02013706_4625.JPEG\n",
      "../data/imagenet-mini/train/n04501370/n04501370_11469.JPEG\n",
      "../data/imagenet-mini/train/n03929855/n03929855_6199.JPEG\n",
      "../data/imagenet-mini/train/n02086240/n02086240_3799.JPEG\n",
      "../data/imagenet-mini/train/n02480855/n02480855_252.JPEG\n",
      "../data/imagenet-mini/train/n02480855/n02480855_17876.JPEG\n",
      "../data/imagenet-mini/train/n02480855/n02480855_15738.JPEG\n",
      "../data/imagenet-mini/train/n03379051/n03379051_7286.JPEG\n",
      "../data/imagenet-mini/train/n02977058/n02977058_22084.JPEG\n",
      "../data/imagenet-mini/train/n01773157/n01773157_9579.JPEG\n",
      "../data/imagenet-mini/train/n02088632/n02088632_4771.JPEG\n",
      "../data/imagenet-mini/train/n03709823/n03709823_1562.JPEG\n",
      "../data/imagenet-mini/train/n03530642/n03530642_46236.JPEG\n",
      "../data/imagenet-mini/train/n04579432/n04579432_18779.JPEG\n",
      "../data/imagenet-mini/train/n03976657/n03976657_8585.JPEG\n",
      "../data/imagenet-mini/train/n03841143/n03841143_2841.JPEG\n",
      "../data/imagenet-mini/train/n03995372/n03995372_14826.JPEG\n",
      "../data/imagenet-mini/train/n03995372/n03995372_3603.JPEG\n",
      "../data/imagenet-mini/train/n03325584/n03325584_10730.JPEG\n",
      "../data/imagenet-mini/train/n03216828/n03216828_28729.JPEG\n",
      "../data/imagenet-mini/train/n03216828/n03216828_60705.JPEG\n",
      "../data/imagenet-mini/train/n03216828/n03216828_984.JPEG\n",
      "../data/imagenet-mini/train/n03063599/n03063599_4132.JPEG\n",
      "../data/imagenet-mini/train/n04179913/n04179913_11903.JPEG\n",
      "../data/imagenet-mini/train/n04044716/n04044716_1626.JPEG\n",
      "../data/imagenet-mini/train/n04044716/n04044716_6855.JPEG\n",
      "../data/imagenet-mini/train/n02091032/n02091032_12363.JPEG\n",
      "../data/imagenet-mini/train/n03384352/n03384352_8614.JPEG\n",
      "../data/imagenet-mini/train/n03388549/n03388549_5594.JPEG\n",
      "../data/imagenet-mini/train/n04372370/n04372370_25321.JPEG\n",
      "../data/imagenet-mini/train/n04372370/n04372370_21436.JPEG\n",
      "../data/imagenet-mini/train/n04372370/n04372370_42250.JPEG\n",
      "../data/imagenet-mini/train/n03857828/n03857828_28253.JPEG\n",
      "../data/imagenet-mini/train/n03857828/n03857828_7955.JPEG\n",
      "../data/imagenet-mini/train/n04380533/n04380533_17646.JPEG\n",
      "../data/imagenet-mini/train/n04380533/n04380533_5780.JPEG\n",
      "../data/imagenet-mini/train/n04485082/n04485082_2236.JPEG\n",
      "../data/imagenet-mini/train/n04485082/n04485082_60909.JPEG\n",
      "../data/imagenet-mini/train/n04485082/n04485082_14560.JPEG\n",
      "../data/imagenet-mini/train/n03627232/n03627232_5560.JPEG\n",
      "../data/imagenet-mini/train/n04251144/n04251144_20993.JPEG\n",
      "../data/imagenet-mini/train/n04523525/n04523525_2111.JPEG\n",
      "BW cleaning terminated.\n"
     ]
    }
   ],
   "source": [
    "clean_bw_imgs(\"../data/imagenet-mini/train/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might want to work on a subset of tinyimagenet for computations reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progression:90.00%\n",
      "Sampling terminated.\n"
     ]
    }
   ],
   "source": [
    "sample_imagenet(\"../data/imagenet-mini/train/\",\"../data/trashos\",num_dir=10,img_num_per_dir=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg16(pretrained=True)\n",
    "# same preprocess used as vgg16\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.CenterCrop(224), \n",
    "    transforms.ToTensor()\n",
    "    ,transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this cell if you want to create the information for the first time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#watch out: once you chose a folder name for the computed images and a json name, the json name will point to that folder name exclusively.\n",
    "lurker = Lurk(model,preprocess,save_comp_img_path='../results/trash/'\n",
    "                              ,save_json_pathname='../saved_model/trash.json'\n",
    "                              ,img_path=\"../data/trashos/images/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wish to load a precomputed json, just add the `load_path` attribute. Watch out, it needs to be coherent with the folder name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading done!\n"
     ]
    }
   ],
   "source": [
    "lurker = Lurk(model,preprocess,save_comp_img_path='../results/03_04_20/'\n",
    "                              ,save_json_pathname='../saved_model/06_05_20.json',\n",
    "                               load_path = '../saved_model/03_04_20.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "lurker.compute_avgmax_imgs()\n",
    "lurker.compute_filter_actmax(layer_indx = 0,filter_indxes=[2,3])\n",
    "lurker.compute_filter_actmax(layer_indx=2,filter_indxes=[3,4])\n",
    "lurker.compute_grads()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torchlurk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "#watch out: once you chose a folder name for the computed images and a json name, the json name will point to that folder name exclusively.\n",
    "lurker = Lurk(model,preprocess,save_comp_img_path='../results/06_05_20/'\n",
    "                              ,save_json_pathname='../saved_model/06_05_20.json'\n",
    "                              ,img_path=\"../data/50classes/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ymentha/anaconda3/envs/ML/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving done!\n"
     ]
    }
   ],
   "source": [
    "lurker.save_to_dill(\"../trash.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading done!\n"
     ]
    }
   ],
   "source": [
    "lurker2 = Lurk.load_from_dill(\"../trash.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading done!\n"
     ]
    }
   ],
   "source": [
    "lurker3 = Lurk(model,preprocess,save_comp_img_path='../results/06_05_20/'\n",
    "                              ,save_json_pathname='../saved_model/06_05_20.json'\n",
    "                              ,img_path=\"../data/50classes/\",\n",
    "                              load_path='../saved_model/06_05_20.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current cursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(lurker,\"../trash.pickle\", pickle_module=dill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "lurker3 = torch.load(\"../trash.pickle\", pickle_module=dill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lurk():\n",
    "    def __init__(self,model,preprocess,save_comp_img_path,save_json_pathname,load_path=None,img_path = \"../data/exsmallimagenet/\"):\n",
    "        self.model = model\n",
    "        self.preprocess = preprocess\n",
    "        # allow to run reduced computations\n",
    "        self.SINGLE_LAYER = True\n",
    "        #number of layers we compute shit for\n",
    "        self.N_LAYERS = 0\n",
    "        #number of filters we compute images for\n",
    "        self.N_REDUCE = 22\n",
    "        #path to the numb image\n",
    "        self.NUMB_PATH = \"../data/tinyimagenet/numb.png\"\n",
    "        # how many top pictures we keep\n",
    "        self.TOP_AVG_SIGN = 4\n",
    "        #number of favourites images per filter\n",
    "        self.N_FAV = 4\n",
    "        # number of max spikes images per filter\n",
    "        self.N_FAV_MAX = 3\n",
    "        #where to save/load the saved models\n",
    "        self.ORIGIN_PATH = save_comp_img_path\n",
    "        #where to access the data\n",
    "        self.DATA_PATH = \"../data/\"\n",
    "        #where to access the tinyimagenet dataset\n",
    "        self.TINY_PATH = os.path.join(self.DATA_PATH,\"tinyimagenet/\")\n",
    "        #which folder to get the data from\n",
    "        #self.IMGS_PATH = os.path.join(self.DATA_PATH,\"exsmallimagenet\")\n",
    "        self.IMGS_PATH = img_path\n",
    "\n",
    "        #where to save the json\n",
    "        self.SAVE_PATHNAME_JSON = save_json_pathname\n",
    "        \n",
    "        self.my_dataset = ImageFolderWithPaths(self.IMGS_PATH,transform=self.preprocess)\n",
    "        self.CLASS2INDX = self.my_dataset.class_to_idx\n",
    "        \n",
    "        labels_infos = self.recreate_labels(self.my_dataset,str(Path(self.IMGS_PATH).parent.joinpath('labels2.txt')))\n",
    "        self.INDX2TITLE = labels_infos.set_index('label')['title'].to_dict()\n",
    "        assert(set(self.INDX2TITLE.keys())==(set(self.CLASS2INDX.values())))\n",
    "        assert(len(self.INDX2TITLE) == len(self.CLASS2INDX))\n",
    "        if load_path is not None:\n",
    "            self.load_from_json(load_path)\n",
    "        else:\n",
    "            self.build_model_info()\n",
    "        create_folders(self.ORIGIN_PATH,[\"avg_grads\",\"max_grads\",\"cropped\",\"cropped_grad\",\"max_activ\"],self.model_info)\n",
    "        \n",
    "        \n",
    "        self.data_loader = torch.utils.data.DataLoader(self.my_dataset, batch_size=1, shuffle=True)\n",
    "        self.title_counts = dict(zip(self.INDX2TITLE.values(),[0] *len(self.INDX2TITLE)))\n",
    "        #initiate the number of counts for \n",
    "        self.init_class_counts(self.INDX2TITLE, self.IMGS_PATH,self.title_counts)\n",
    "        \n",
    "    @staticmethod\n",
    "    def recreate_labels(dataset,output_path):\n",
    "        \"\"\"\n",
    "        recreate the label files wrt to a specific dataset with potentially less classes than the original one. \n",
    "        Useful for smaller computations\n",
    "        \"\"\"\n",
    "        infos = pd.read_csv(\"../data/labels.txt\",sep=\" \",header=None)\n",
    "        infos.columns = ['file_name','label','title']\n",
    "        infos.set_index('file_name',inplace=True,drop=False)\n",
    "        new_infos= infos.loc[dataset.class_to_idx.keys()].copy()\n",
    "        new_infos.label = new_infos.file_name.map(dataset.class_to_idx)\n",
    "        new_infos.drop(columns=['file_name']).to_csv(output_path,header=None,sep=\" \")\n",
    "        return new_infos\n",
    "    \n",
    "    def init_class_counts(self,indx_to_title,src_path,obj):\n",
    "        \"\"\"\n",
    "        create the dictionary which counts the number of images per classes in the dataset\n",
    "        \"\"\"\n",
    "        for subfold in os.listdir(src_path):\n",
    "            subfold_path = os.path.join(src_path,subfold)\n",
    "            count = len([name for name in os.listdir(subfold_path)])\n",
    "            title = indx_to_title[self.CLASS2INDX[subfold]]\n",
    "            obj[title] += count\n",
    "        \n",
    "    def save_to_json(self):\n",
    "        model_info2 = deepcopy(self.model_info)\n",
    "        for lay_info in model_info2:\n",
    "            if (isinstance(lay_info['lay'],nn.Conv2d)):\n",
    "                del lay_info['deproj']\n",
    "            del lay_info['lay']\n",
    "        with open(self.SAVE_PATHNAME_JSON, 'w') as fout:\n",
    "            json.dump(model_info2, fout, indent = 2)\n",
    "        print(\"saving done!\")\n",
    "        \n",
    "    def save_to_dill(self,path):\n",
    "        torch.save(self,path, pickle_module=dill)\n",
    "        print(\"saving done!\")\n",
    "        \n",
    "    def load_from_json(self,load_path):\n",
    "        layers = []\n",
    "        with open(load_path, 'r') as fin:\n",
    "            model_info = json.load(fin)\n",
    "        for lay_info,layer in zip(model_info,self.model.features):\n",
    "            lay_info['lay'] = layer\n",
    "            if (isinstance(layer,(nn.Conv2d,nn.MaxPool2d))):\n",
    "                layers.append(layer)\n",
    "            if (isinstance(layer,nn.Conv2d)):\n",
    "                lay_info['deproj'] = Projector(deepcopy(layers),224)\n",
    "        self.model_info = model_info\n",
    "        self.check_path_imgs()\n",
    "        print(\"Loading done!\") \n",
    "    \n",
    "    @staticmethod\n",
    "    def load_from_dill(load_path):\n",
    "        lurker = torch.load(load_path, pickle_module=dill)\n",
    "        lurker.check_path_imgs()\n",
    "        print(\"Loading done!\") \n",
    "        return lurker    \n",
    "    \n",
    "    def check_path_imgs(self): \n",
    "        try:\n",
    "            type_keys = [\"fav_imgs\",\"grad_path_avg\",\"max_imgs\",\"grad_path_max\"]\n",
    "            for lay_info in self.model_info:\n",
    "                if (isinstance(lay_info['lay'],nn.Conv2d)):\n",
    "                    for filtr in lay_info['filters']:\n",
    "                        for key in type_keys:\n",
    "                            for el in filtr[key]:\n",
    "                                Path(el).resolve(strict=True)\n",
    "                        Path(filtr[\"actmax_im\"]).resolve(strict=True)\n",
    "        except FileNotFoundError as e:\n",
    "            print(\"Non coherent path in the loaded object:{}\".format(e.filename))\n",
    "\n",
    "    \n",
    "    def build_model_info(self):\n",
    "        model_info = []\n",
    "        layers = []\n",
    "        #construct the data structure\n",
    "        for layer in list(self.model.features.named_children()):\n",
    "            lay_info = {'id':layer[0],\n",
    "                      'lay':layer[1],\n",
    "                      'name':str(layer[1]).split('(')[0] + \"_\" + str(layer[0]) \n",
    "                    }\n",
    "            if (isinstance(layer[1],(nn.Conv2d,nn.MaxPool2d))):\n",
    "                layers.append(layer[1])\n",
    "            if (isinstance(lay_info['lay'],nn.Conv2d)):     \n",
    "                n_input = lay_info['lay'].in_channels\n",
    "                n_output = lay_info['lay'].out_channels\n",
    "                lay_info['n_input'] = n_input\n",
    "                lay_info['n_output'] = n_output\n",
    "                lay_info['deproj'] = Projector(deepcopy(layers),224)\n",
    "                lay_info[\"filters\"] = []\n",
    "                for i in range(n_output):\n",
    "                    lay_info[\"filters\"].append({\n",
    "                        \"id\":i,\n",
    "                        \"spikes\":[0 for i in range(self.N_FAV)],\n",
    "                        \"fav_imgs\":[self.NUMB_PATH for i in range(self.N_FAV)],\n",
    "                        \"grad_path_avg\":[self.NUMB_PATH for i in range(self.N_FAV)],\n",
    "                        \"max_spikes\":[0 for i in range(self.N_FAV_MAX)],\n",
    "                        \"max_slices\":[[[0,0],[0,0]]for i in range(self.N_FAV_MAX)],\n",
    "                        \"max_imgs\":[self.NUMB_PATH for i in range(self.N_FAV_MAX)],\n",
    "                        \"grad_path_max\":[self.NUMB_PATH for i in range(self.N_FAV_MAX)],\n",
    "                        \"actmax_im\":self.NUMB_PATH,\n",
    "                        \"histo_counts_max\":OrderedDict(zip(self.INDX2TITLE.values(),[0] *len(self.INDX2TITLE))),\n",
    "                        \"histo_counts_avg\":OrderedDict(zip(self.INDX2TITLE.values(),[0] *len(self.INDX2TITLE)))\n",
    "                    })\n",
    "            elif (type(lay_info['lay']) == nn.Linear):\n",
    "                    n_input = lay_info['lay'].in_features\n",
    "                    n_output = lay_info['lay'].out_features\n",
    "                    lay_info['n_output'] = n_output\n",
    "                    #lay_info[\"filters\"] = [empty_filter.copy() for i in range(n_output)]\n",
    "            model_info.append(lay_info)\n",
    "            self.model_info = model_info\n",
    "            \n",
    "    def get_filt_string(self,dir_type,layer_name,filter_id):\n",
    "        \"\"\"\n",
    "        return the path to the appropriate folder\n",
    "        \"\"\"\n",
    "        return os.path.join(self.ORIGIN_PATH,dir_type,layer_name,str(filter_id))\n",
    "    \n",
    "    def extract_name(self,img_path,ext='.jpg'):\n",
    "        \"\"\"\n",
    "        extract the name of the imgpath and add the extension\n",
    "        \"\"\"\n",
    "        jpg_name = img_path.split(\"/\")[-1]\n",
    "        img_name = jpg_name.split(\".\")[0] + ext\n",
    "        return img_name\n",
    "    #Watch out which path you give for the IMGS_PATH\n",
    "\n",
    "    def sort_filters_spikes(self):\n",
    "        \"\"\"\n",
    "        sorts the spikes and respective paths of the filters inplace\n",
    "        \"\"\"\n",
    "        for lay_info in self.model_info:\n",
    "            if (isinstance(lay_info['lay'],nn.Conv2d)):\n",
    "                for filtr in lay_info['filters']:\n",
    "                    max_indx = np.argsort(filtr[\"max_spikes\"])[::-1]\n",
    "                    filtr[\"max_spikes\"] = np.array(filtr[\"max_spikes\"])[max_indx].tolist()\n",
    "                    filtr[\"max_imgs\"] = np.array(filtr[\"max_imgs\"])[max_indx].tolist()\n",
    "                    filtr[\"max_slices\"] = np.array(filtr[\"max_slices\"])[max_indx].tolist()\n",
    "\n",
    "                    avg_indx = np.argsort(filtr[\"spikes\"])[::-1]\n",
    "                    filtr[\"spikes\"] = np.array(filtr[\"spikes\"])[avg_indx].tolist()\n",
    "                    filtr[\"fav_imgs\"] = np.array(filtr[\"fav_imgs\"])[avg_indx].tolist()\n",
    "\n",
    "    def reset_histos(self):\n",
    "        \"\"\"\n",
    "        reset the counts for the histograms counts\n",
    "        \"\"\"\n",
    "        for lay_info in self.model_info:\n",
    "            if (not isinstance(lay_info['lay'],nn.Conv2d)):\n",
    "                continue\n",
    "            for filt in lay_info['filters']:\n",
    "                filt['histo_counts_max'] = dict(zip(self.INDX2TITLE.values(),[0] *len(self.INDX2TITLE)))\n",
    "                filt['histo_counts_avg'] = dict(zip(self.INDX2TITLE.values(),[0] *len(self.INDX2TITLE)))\n",
    "    def normalize_histos(self):\n",
    "        \"\"\"\n",
    "        average the counts of the histograms wrt to the number of samples in the classes of the dataset\n",
    "        \"\"\"\n",
    "        for lay_info in self.model_info:\n",
    "            if (not isinstance(lay_info['lay'],nn.Conv2d)):\n",
    "                continue\n",
    "            for filt in lay_info['filters']:\n",
    "                for key in filt['histo_counts_max'].keys():\n",
    "                    filt['histo_counts_max'][key] /= self.title_counts[key]\n",
    "                for key in filt['histo_counts_avg'].keys():\n",
    "                    filt['histo_counts_avg'][key] /= self.title_counts[key]\n",
    "                filt['histo_counts_max'] = OrderedDict(sorted(filt['histo_counts_max'].items(),key = lambda x: x[1])[::-1])\n",
    "                filt['histo_counts_avg'] =  OrderedDict(sorted(filt['histo_counts_avg'].items(),key = lambda x: x[1])[::-1])\n",
    "    def compute_avgmax_imgs(self,verbose = False):\n",
    "        \"\"\"\n",
    "        compute the average and max images for all the layers of the model_info such that each filter of each layer knows what are\n",
    "        its favourite images (write down the link to the avg/max images in the json)\n",
    "        \"\"\"\n",
    "        self.reset_histos()\n",
    "        for j,(datas,labels,paths) in enumerate(self.data_loader):\n",
    "            print(\"Progression update favimgs:{:.2f} %\".format(j/len(self.data_loader) * 100))\n",
    "            for i,lay_info in enumerate(self.model_info):\n",
    "                clear_output(wait=True)\n",
    "                if verbose:\n",
    "                    print(\"AvgMax update:{}/{}:{:.2f} %..\".format(i,len(self.model_info),100*j/ len(data_loader)))\n",
    "\n",
    "                #datas: Batchsize x Numberfilter x Nout x Nout\n",
    "                datas = lay_info['lay'](datas)\n",
    "                if (not isinstance(lay_info['lay'],nn.Conv2d) ):\n",
    "                    continue\n",
    "                if (i >self.N_LAYERS and self.SINGLE_LAYER):\n",
    "                    break\n",
    "\n",
    "                batch_size = datas.size(0)\n",
    "                filter_nb = datas.size(1)\n",
    "                width = datas.size(3)\n",
    "\n",
    "                #set_trace()\n",
    "                #spikes: Batchsize x Filternumber\n",
    "                max_spikes,max_pos = datas.view([batch_size,filter_nb,-1]).max(dim = 2)\n",
    "                max_rows = max_pos / width\n",
    "                max_cols = max_pos % width\n",
    "\n",
    "                avg_spikes = datas.view([batch_size,filter_nb,-1]).mean(dim = 2)\n",
    "                self.update_filters_maxim(lay_info,max_spikes,paths,max_rows,max_cols,labels)\n",
    "                self.update_filters_favim(lay_info,avg_spikes,paths,labels)\n",
    "                #save the whole model\n",
    "        self.normalize_histos()\n",
    "        self.sort_filters_spikes()\n",
    "        self.save_cropped()\n",
    "        self.save_to_json()\n",
    "\n",
    "    def update_filters_maxim(self,lay_info,batch_spikes,paths,max_rows,max_cols,labels):\n",
    "        #as many spikes in batch_spikes as there are samples in batch\n",
    "        for spikes,path,label,rows,cols in zip(batch_spikes,paths,labels,max_rows,max_cols):\n",
    "            #at this stage there are as many spike in spikes as there are filters\n",
    "            for k,(filt,spike,row,col) in enumerate(zip(lay_info[\"filters\"],spikes.detach().numpy(),rows,cols)):\n",
    "                #compute the histogram with maximal values\n",
    "                filt[\"histo_counts_max\"][self.INDX2TITLE[label.item()]] += float(spike)\n",
    "                #compute the minimum spike for the filter\n",
    "                min_indx = np.argmin(filt[\"max_spikes\"])\n",
    "                min_spike = min(filt[\"max_spikes\"])\n",
    "                \n",
    "                if (spike > min_spike and not (path in filt[\"max_imgs\"])):\n",
    "                    ((x1,x2),(y1,y2)) = lay_info[\"deproj\"].chain(((row.item(),row.item()),(col.item(),col.item())))\n",
    "                    assert(isinstance(x1,int) and isinstance(x2,int) and isinstance(y1,int) and isinstance(y2,int))\n",
    "                    filt[\"max_slices\"][min_indx] = ((x1,x2),(y1,y2))\n",
    "                    filt[\"max_imgs\"][min_indx] = path\n",
    "                    filt[\"max_spikes\"][min_indx] = float(spike)\n",
    "                    \n",
    "    def update_filters_favim(self,lay_info,batch_spikes,paths,labels):\n",
    "        #as many spikes in batch_spikes as there are samples in batch\n",
    "        for spikes,path,label in zip(batch_spikes,paths,labels):\n",
    "            #at this stage there are as many spike in spikes as there are filters\n",
    "            for k,(filt,spike) in enumerate(zip(lay_info[\"filters\"],spikes.detach().numpy())):\n",
    "                #compute the histogram with avg values\n",
    "                filt[\"histo_counts_avg\"][self.INDX2TITLE[label.item()]] += float(spike)\n",
    "                #compute the minimum spike for the filter\n",
    "                min_indx = np.argmin(filt[\"spikes\"])\n",
    "                min_spike = min(filt[\"spikes\"])\n",
    "                if (spike > min_spike and not (path in filt[\"fav_imgs\"])):\n",
    "                    filt[\"fav_imgs\"][min_indx] = path\n",
    "                    filt[\"spikes\"][min_indx] = float(spike)\n",
    "                \n",
    "\n",
    "    def save_cropped(self,grad = False,verbose=False):\n",
    "        \"\"\"\n",
    "        iterate on the model_info to save a cropped version of the images\n",
    "        Args:\n",
    "            grad(Bool): whether to save the gradients versions\n",
    "        \"\"\"\n",
    "        if grad:\n",
    "            filtrlist = \"grad_path_max\" \n",
    "            folder = \"cropped_grad\"\n",
    "        else:\n",
    "            filtrlist = \"max_imgs\"\n",
    "            folder = \"cropped\"\n",
    "\n",
    "        for i,lay_info in enumerate(self.model_info):\n",
    "            clear_output(wait=True)\n",
    "            if verbose:\n",
    "                print(\"Progression:{} %\".format(i/len(model_info)*100))\n",
    "            if (not isinstance(lay_info['lay'],nn.Conv2d)):\n",
    "                continue\n",
    "            for filtr in lay_info['filters']:\n",
    "                for path,slices in zip(filtr[filtrlist],filtr['max_slices']):\n",
    "                    if (path == self.NUMB_PATH):\n",
    "                        continue\n",
    "                    cropped = ToTensor()(Image.open(path))\n",
    "                    ((x1,x2),(y1,y2)) = slices\n",
    "                    cropped = cropped[:,x1:x2+1,y1:y2+1]\n",
    "                    crop_path = self.get_filt_string(folder,lay_info['name'],filtr['id'])\n",
    "                    file_name = path.split('/')[-1].lower()\n",
    "                    file_path = os.path.join(crop_path,file_name)\n",
    "                    ToPILImage()(cropped).save(file_path) \n",
    "            \n",
    "    def compute_filter_actmax(self,layer_indx,indexes = None):\n",
    "        \"\"\"\n",
    "        compute  and save the filter maximal activation as an image. Compute it only for filters for which\n",
    "        it has not been computed yet: you need to delete the existing image if you wish for a refresh.\n",
    "        \"\"\"\n",
    "        lay_info = self.model_info[layer_indx]\n",
    "        if indexes is None:\n",
    "            indexes = range(lay_info[\"lay\"].out_channels)\n",
    "        layer_name = lay_info[\"name\"]\n",
    "        pre_existing = []\n",
    "        for filt in lay_info[\"filters\"]:\n",
    "            name = \"{}_{}_max_activ.jpg\".format(lay_info['name'],filt['id'])\n",
    "            filt_path = self.get_filt_string(\"max_activ\",lay_info[\"name\"],filt[\"id\"])\n",
    "            filt_path = os.path.join(filt_path,name)\n",
    "            try:\n",
    "                f = open(filt_path)\n",
    "                filt[\"actmax_im\"] = filt_path\n",
    "                pre_existing.append(filt[\"id\"])\n",
    "                f.close()\n",
    "            except FileNotFoundError:\n",
    "                pass\n",
    "\n",
    "        indexes = [i for i in indexes if i not in pre_existing]\n",
    "\n",
    "        for filt_indx in indexes:\n",
    "            filt = lay_info['filters'][filt_indx]\n",
    "            visualizer = CNNLayerVisualization(model.features, \n",
    "                                               selected_layer=int(lay_info['id']), \n",
    "                                               selected_filter=filt_indx)\n",
    "            act_max_img = visualizer.visualise_layer_with_hooks()\n",
    "            filt_path = self.get_filt_string(\"max_activ\",lay_info['name'],filt['id'])\n",
    "            name = \"{}_{}_max_activ.jpg\".format(lay_info['name'],filt['id'])\n",
    "            filt_path = os.path.join(filt_path,name)\n",
    "            #save the image\n",
    "            ToPILImage()(act_max_img).save(filt_path)\n",
    "            filt[\"actmax_im\"] = filt_path\n",
    "        print(\"Actmax done!\")\n",
    "        \n",
    "    def compute_grads(self,verbose = False,compute_avg = True,compute_max = True):\n",
    "        \"\"\"\n",
    "        compute the gradients for the fav images of all filters of all layers for the model_info\n",
    "        Args:\n",
    "            gbp (GuidedBackprop): fitted on the model\n",
    "            model_info (dic): as described above\n",
    "            origin_path (str): path where to store the folders containing the gradient images\n",
    "        \"\"\"\n",
    "        gbp = GuidedBackprop(self.model)\n",
    "        for i,lay_info in enumerate(self.model_info):\n",
    "            if (i > self.N_LAYERS and self.SINGLE_LAYER):\n",
    "                break\n",
    "            if (isinstance(lay_info['lay'],nn.Conv2d)):\n",
    "                for j,filt in enumerate(lay_info['filters']):\n",
    "                    clear_output(wait=True)\n",
    "                    print(\"Grads Progression:layer{}/{} {}%\".format(i,len(self.model_info),j/len(lay_info['filters'])*100))\n",
    "                    if compute_avg:\n",
    "                        path = self.get_filt_string(\"avg_grads\",lay_info['name'],filt[\"id\"])\n",
    "                        self.compute_grads_filt(gbp,filt,path,lay_info['id'],\"fav_imgs\")\n",
    "                    if compute_max:\n",
    "                        path = self.get_filt_string(\"max_grads\",lay_info['name'],filt[\"id\"])\n",
    "                        self.compute_grads_filt(gbp,filt,path,lay_info['id'],\"max_imgs\")\n",
    "                        self.save_cropped(grad= True)\n",
    "        self.save_to_json()\n",
    "\n",
    "    def compute_grads_filt(self,gbp,filt,path,lay_id,img_type):\n",
    "        \"\"\"\n",
    "        compute the gradients wrt to the favourite images of a filter filt.\n",
    "        Args:\n",
    "            gbp (GuidedBackprop): fitted on the model\n",
    "            filt (dic): filter from a layer\n",
    "            path (str): path to the folder where to store the gradient images\n",
    "            img_type (str): either \"fav_imgs\" or \"max_imgs\"\n",
    "        \"\"\"\n",
    "        grad_strindx = \"grad_path_avg\" if img_type == \"fav_imgs\" else \"grad_path_max\"\n",
    "\n",
    "        for i,img_path in enumerate(filt[img_type]):\n",
    "            if (img_path == self.NUMB_PATH):\n",
    "                continue   \n",
    "\n",
    "            #name of the image\n",
    "            img_name = self.extract_name(img_path,\"_grad.jpg\")\n",
    "            #joined path and imagename\n",
    "            grad_path = os.path.join(path,img_name)\n",
    "\n",
    "            try:\n",
    "                f = open(grad_path)\n",
    "                filt[grad_strindx][i] = grad_path\n",
    "                f.close()\n",
    "                continue\n",
    "            except FileNotFoundError:\n",
    "                pass\n",
    "\n",
    "            image = Image.open(img_path)\n",
    "            image = self.preprocess(image).unsqueeze(0)\n",
    "            image.requires_grad = True\n",
    "            class_name = img_path.split(\"/\")[-1].split(\"_\")[0]\n",
    "            gradient = gbp.generate_gradients(image,self.CLASS2INDX[class_name],lay_id,filt['id'])\n",
    "            #normalization of the gradient\n",
    "            gradient = gradient - gradient.min()\n",
    "            gradient /= gradient.max()\n",
    "            im = ToPILImage()(gradient[0])\n",
    "            im.save(grad_path)\n",
    "            filt[grad_strindx][i] = grad_path\n",
    "        \n",
    "\n",
    "model = models.vgg16(pretrained=True)\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.CenterCrop(224), \n",
    "    transforms.ToTensor()\n",
    "    ,transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ML] *",
   "language": "python",
   "name": "conda-env-ML-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
